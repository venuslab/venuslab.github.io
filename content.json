{"meta":{"title":"Spring Cloud中国社区博客","subtitle":"Spring Cloud中国社区博客","description":"Spring Cloud中国社区官方博客，投稿请联系QQ:2508203324,邮箱:Software_King@qq.com。","author":"Spring Cloud中国社区","url":"http://blog.springcloud.cn"},"pages":[{"title":"404 找不到该页面！","date":"2017-06-17T02:42:04.000Z","updated":"2017-04-03T06:03:42.000Z","comments":false,"path":"/404.html","permalink":"http://blog.springcloud.cn//404.html","excerpt":"","text":"对不起，您要找的内容本站不存在，可以在本站听一会音乐，休息一下！无法访本页的原因是：你使用的URL可能拼写错误或者它只是临时脱机所访问的页面不存在或被管理员已删除 请尝试以下操作： 1、尝试按F5进行页面刷新 2、重新键入URL地址进入访问 3、或返回 网站首页"},{"title":"加入Spring Cloud中国社区","date":"2016-10-03T06:00:00.000Z","updated":"2017-06-17T04:10:24.000Z","comments":true,"path":"joinus/index.html","permalink":"http://blog.springcloud.cn/joinus/index.html","excerpt":"","text":"一.加入QQ群或微信群1.1 QQ群 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 1.2 微信群加微信Software_King，或者扫二维码入群 二.捐赠社区发展2.1 捐赠社区 如果你觉得，Spring Cloud中国社区还可以，为了更好的发展，你可以捐赠社区，点击下面的打赏捐赠，捐赠的钱将用于社区发展和线下meeting up。"},{"title":"关于SpringCloud中国社区以及国内使用情况","date":"2016-10-03T06:00:00.000Z","updated":"2017-06-17T03:28:09.000Z","comments":true,"path":"about/index.html","permalink":"http://blog.springcloud.cn/about/index.html","excerpt":"Spring Cloud中国社区起源 其实当Spring Cloud项目刚在github上出现的时候，我就一直在关注其项目发展，到了2015年8月，由于个人兴趣研究Spring Cloud项目，由于国内相关文档较少，当时就想建立一个中国社区，于是就先把域名注册了，选中域名为springcloud.cn。 为什么要发起Spring Cloud中国社区 Spring Cloud发展到2016年，国内关注的人越来越多，但是相应学习交流的平台和材料比较分散，不利于学习交流，因此Spring Cloud中国社区应运而生。 Spring Cloud中国社区是国内首个Spring Cloud构建微服务架构的交流社区。我们致力于为Spring Boot或Spring Cloud技术人员提供分享和交流的平台，推动Spring Cloud在中国的普及和应用。 欢迎CTO、架构师、开发者等，在这里学习与交流使用Spring Cloud的实战经验。 目前QQ群人数:7000+,微信群:2000+. 扫描下面二维码或者微信搜索SpringCloud，关注社区公众号 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 Spring Cloud中国社区官网:http://springcloud.cn Spring Cloud中国社区论坛:http://springcloud.cn Spring Cloud中国社区文档:http://docs.springcloud.cn spring cloud目前国内使用情况 中国联通子公司http://flp.baidu.com/feedland/video/?entry=box_searchbox_feed&amp;id=144115189637730162&amp;from=timeline&amp;isappinstalled=0","text":"Spring Cloud中国社区起源 其实当Spring Cloud项目刚在github上出现的时候，我就一直在关注其项目发展，到了2015年8月，由于个人兴趣研究Spring Cloud项目，由于国内相关文档较少，当时就想建立一个中国社区，于是就先把域名注册了，选中域名为springcloud.cn。 为什么要发起Spring Cloud中国社区 Spring Cloud发展到2016年，国内关注的人越来越多，但是相应学习交流的平台和材料比较分散，不利于学习交流，因此Spring Cloud中国社区应运而生。 Spring Cloud中国社区是国内首个Spring Cloud构建微服务架构的交流社区。我们致力于为Spring Boot或Spring Cloud技术人员提供分享和交流的平台，推动Spring Cloud在中国的普及和应用。 欢迎CTO、架构师、开发者等，在这里学习与交流使用Spring Cloud的实战经验。 目前QQ群人数:7000+,微信群:2000+. 扫描下面二维码或者微信搜索SpringCloud，关注社区公众号 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 Spring Cloud中国社区官网:http://springcloud.cn Spring Cloud中国社区论坛:http://springcloud.cn Spring Cloud中国社区文档:http://docs.springcloud.cn spring cloud目前国内使用情况 中国联通子公司http://flp.baidu.com/feedland/video/?entry=box_searchbox_feed&amp;id=144115189637730162&amp;from=timeline&amp;isappinstalled=0 上海米么金服 指点无限（北京）科技有限公司 易保软件 目前在定制开发中 http://www.ebaotech.com/cn/ 广州简法网络 深圳睿云智合科技有限公司 持续交付产品基于Spring Cloud研发 http://www.wise2c.com 猪八戒网 上海云首科技有限公司 华为 整合netty进来用rpc 包括nerflix那套东西 需要注意的是sleuth traceid的传递需要自己写。tps在物理机上能突破20w 东软 南京云帐房网络科技有限公司 四众互联(北京)网络科技有限公司 深圳摩令技术科技有限公司 广州万表网 视觉中国 上海秦苍信息科技有限公司-买单侠 爱油科技(大连)有限公司爱油科技基于SpringCloud的微服务实践 广发银行 卖货郎(http://www.51mhl.com/） 拍拍贷 甘肃电信 新浪商品部 春秋航空 冰鉴科技 万达网络科技集团-共享商业平台-共享供应链中心 网易乐得技术团队 饿了么某技术团队 高阳捷迅信息科技–话费中心业务平台–凭证查询及收单系统数据在统计之中，会一直持续更新，敬请期待！ 捐赠社区发展捐赠社区 如果你觉得，Spring Cloud中国社区还可以，为了更好的发展，你可以捐赠社区，点击下面的打赏捐赠，捐赠的钱将用于社区发展和线下meeting up。"},{"title":"标签","date":"2017-06-17T03:33:08.000Z","updated":"2017-06-17T03:33:08.000Z","comments":false,"path":"tags/index.html","permalink":"http://blog.springcloud.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"hystrix在spring mvc的使用","slug":"sc/sc-wy-hystrix","date":"2017-06-21T16:00:00.000Z","updated":"2017-06-24T02:49:09.000Z","comments":true,"path":"sc/sc-wy-hystrix/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-wy-hystrix/","excerpt":"","text":"一个大型服务不可避免的需要依赖其他服务，并且有可能需要通过网络请求依赖第三方客户端。这样就有可能因为单个依赖服务延迟而导致整个服务器上的资源被阻塞。更糟糕的是，倘若两个服务相互依赖，有一个服务对另一个服务响应延时就有可能造成雪崩效应，导致两个服务一起崩溃。 现如今微服务架构十分流行，其解决依赖隔离方案hystrix也被大家所认知。但目前还有很多服务还是停留在Spring mvc框架，无法直接使用Spring Cloud集成的hystrix方案。本文先简单介绍hystrix的基本知识，然后介绍hystrix在Spring mvc的使用，最后简单介绍下如何实现项目的hystrix信息监控。 一、简介1、为什么要使用Hystrix在复杂的分布式结构中，每个应用都可能会依赖很多其他的服务，并且这些服务都不可避免地有失效的可能。倘若没有对依赖失败进行隔离，那整个服务可能就会有被拖垮的风险。 例如，一个应用依赖了 30 个服务，并且每个服务能保证 99.99% 的可用率，下面是一些计算结果： 可用率：99.99%^30=99.7% 1亿次请求*0.3%=300,000次失效 换算成时间大约每个月2个小时服务不稳定。 然而，现实更加残酷，如果你没有针对整个系统做快速恢复，即使所有依赖只有 0.01% 的不可用率，累积起来每个月给系统带来的不可用时间也有数小时之多。 当所有依赖都正常，一个请求的拓扑结构如下所示： 当一个依赖服务有延迟，它将会阻塞整个用户请求： 在高QPS的环境下，一个依赖服务的延迟会导致整个服务器上资源都被阻塞。 应用中每一个网络请求或者间接通过客户端库发出的网络请求都是潜在的导致应用失效的原因。更严重的是，这些应用可能被其他服务依赖，由于每个服务都有诸如请求队列，线程池，或者其他系统资源等，一旦某个服务失效或者延迟增高，会导致更严重的级联失效。 hystrix被设计用来： 在通过第三方客户端访问（通常是通过网络）依赖服务出现高延迟或者失败时，为系统提供保护和控制 在分布式系统中防止级联失败 可以进行快速失败（不需要等待）和快速恢复（当依赖服务失效后又恢复正常，其对应的线程池会被清理干净，即剩下的都是未使用的线程，相对于整个 Tomcat 容器的线程池被占满需要耗费更长时间以恢复可用来说，此时系统可以快速恢复） 提供失败回退（Fallback）和优雅的服务降级机制 提供近实时的监控、报警和运维控制手段 2、Hystrix如何解决依赖隔离 将所有请求外部系统（或者叫依赖服务）的逻辑封装到 HystrixCommand 或者 HystrixObservableCommand 对象中，这些逻辑将会在独立的线程中被执行（利用了设计模式中的 Command模式） 对那些耗时超过设置的阈值的请求，Hystrix 采取自动超时的策略。该策略默认对所有 Command 都有效，当然，你也可以通过设置 Command 的配置以自定义超时时间，以使你的依赖服务在引入 Hystrix 之后能达到 99.5% 的性能 为每一个依赖服务维护一个线程池（或者信号量），当线程池占满，该依赖服务将会立即拒绝服务而不是排队等待 划分出成功、失败（抛出异常）、超时或者线程池占满四种请求依赖服务时可能出现的状态 引入『熔断器』机制，在依赖服务失效比例超过阈值时，手动或者自动地切断服务一段时间 当请求依赖服务时出现拒绝服务、超时或者短路（多个依赖服务顺序请求，前面的依赖服务请求失败，则后面的请求不会发出）时，执行该依赖服务的失败回退逻辑 近实时地提供监控和配置变更 当使用 Hystrix 包装了你的所有依赖服务的请求后，拓扑图如下 3、hystrix如何执行hystrix执行分为三种模式，分别为同步执行、异步执行、Reactive模式执行。 同步执行：若原方法返回参数非Future对象且非Observable对象则会构建该模式。使用command.execute()，阻塞，当依赖服务响应（或者抛出异常/超时）时，返回结果； 异步执行：若原方法返回参数为Future对象时构建该模式。使用command.queue()，返回Future对象，通过该对象异步得到返回结果； Reactive模式执行：若原方法返回参数为Observable对象时构建该模式。该模式又分observe()命令和toObservable()命令。observe()命令会立即发出请求，在依赖服务响应（或者抛出异常/超时）时，通过注册的 Subscriber得到返回结果。toObservable()命令只有在订阅该对象时，才会发出请求，然后在依赖服务响应（或者抛出异常/超时）时，通过注册的Subscriber得到返回结果。 在内部实现中，execute()是同步调用，内部会调用queue().get()方法。queue()内部会调用toObservable().toBlocking().toFuture()。也就是说，HystrixCommand 内部均通过一个Observable的实现来执行请求，即使这些命令本来是用来执行同步返回回应这样的简单逻辑。 构建HystrixCommand或者HystrixObservableCommand对象； 执行命令（execute()、queue()、observe()、toObservable()）； 如果请求结果缓存这个特性被启用，并且缓存命中，则缓存的回应会立即通过一个Observable对象的形式返回； 检查熔断器状态，确定请求线路是否是开路，如果请求线路是开路，Hystrix将不会执行这个命令，而是直接使用『失败回退逻辑』（即不会执行run()，直接执行getFallback()）； 如果和当前需要执行的命令相关联的线程池和请求队列（或者信号量，如果不使用线程池）满了，Hystrix 将不会执行这个命令，而是直接使用『失败回退逻辑』（即不会执行run()，直接执行getFallback()）； 执行HystrixCommand.run()或HystrixObservableCommand.construct()，如果这两个方法执行超时或者执行失败，则执行getFallback()；如果正常结束，Hystrix 在添加一些日志和监控数据采集之后，直接返回回应； Hystrix 会将请求成功，失败，被拒绝或超时信息报告给熔断器，熔断器维护一些用于统计数据用的计数器。 这些计数器产生的统计数据使得熔断器在特定的时刻，能短路某个依赖服务的后续请求，直到恢复期结束，若恢复期结束根据统计数据熔断器判定线路仍然未恢复健康，熔断器会再次关闭线路。 4、hystrix基本配置hystrix基本配置可以通过四种方式进行设置。 hystrix本身代码默认。这种是在以下三种都没有自定义的情况下使用，默认设置在hystrix-core下的HystrixCommandProperties和HystrixThreadPoolProperties 自定义默认配置。可以使用配置文件进行全局默认配置。例如：hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds 通过代码构造实例设置。 动态实例配置。根据实例的key值（commandKey或者threadPollKey）通过配置文件给特定实例进行配置。例如，一个实例的commandKey为commandTest，则为hystrix.command.commandTest.execution.isolation.thread.timeoutInMilliseconds 本文只介绍hystrix常用的command和ThreadPool配置，其余配置可以查看官网 command配置 execution.isolation.strategy：执行隔离策略. Thread是默认推荐的选择。THREAD为每次在一个线程中执行，并发请求数限制于线程池的线程数。SEMAPHORE为在调用线程中执行，并发请求数限制于semaphore信号量的值。 execution.isolation.thread.timeoutInMilliseconds：超时时间，默认1000ms。 execution.timeout.enabled：是否开启超时，默认true。 execution.isolation.thread.interruptOnTimeout：当超时的时候是否中断(interrupt) HystrixCommand.run()执行，默认：true。 fallback.enabled：是否开启fallback，默认：true。 circuitBreaker.enabled：是否开启熔断，默认true。 circuitBreaker.requestVolumeThreshold：设置一个滑动窗口内触发熔断的最少请求量，默认20。例如，如果这个值是20，一个滑动窗口内只有19个请求时，即使19个请求都失败了也不会触发熔断。 circuitBreaker.sleepWindowInMilliseconds：设置触发熔断后，拒绝请求后多长时间开始尝试再次执行。默认5000ms。 circuitBreaker.errorThresholdPercentage：设置触发熔断的错误比例。默认50，即50%。 metrics.rollingStats.timeInMilliseconds：设置滑动窗口的统计时间。熔断器使用这个时间。默认10s metrics.rollingStats.numBuckets：设置滑动统计的桶数量。默认10。metrics.rollingStats.timeInMilliseconds必须能被这个值整除。 threadPool配置 coreSize：设置线程池的core size,这是最大的并发执行数量。默认10。 maximumSize：设置线程池数量极大值，这是可以支持的最大并发量，一般情况下和coreSize是相等的。默认10。该值只有在allowMaximumSizeToDivergeFromCoreSize被设置时才能有效。 maxQueueSize：最大队列长度。设置BlockingQueue的最大长度。默认-1。 如果设置成-1，就会使用SynchronizeQueue。 如果其他正整数就会使用LinkedBlockingQueue。 queueSizeRejectionThreshold：设置拒绝请求的临界值。只有maxQueueSize为-1时才有效。设置设个值的原因是maxQueueSize值运行时不能改变，我们可以通过修改这个变量动态修改允许排队的长度。默认5。（注意：hystrix为每一个依赖服务维护一个线程池或者信号量，当线程池占满+queueSizeRejectionThreshold占满，该依赖服务将会立即拒绝服务而不是排队等待） keepAliveTimeMinutes：设置keep-live时间。默认1分钟。当coreSize==maximumSize时线程池是固定的。只有allowMaximumSizeToDivergeFromCoreSize值设置为true，coreSize和maximumSize才能分成两个部分。当coreSize &lt; maximumSize，该值控制一个线程多久没使用才被释放。 allowMaximumSizeToDivergeFromCoreSize：该值确认maximumSize是否起作用。默认false。 metrics.rollingStats.timeInMilliseconds：和command配置含义一样。 metrics.rollingStats.numBuckets：和command配置含义一样。 倘若使用配置文件进行配置，两种配置可以根据key的字符串进行区分。command都是hystrix.command.commandKey(or default).属性名，threadpool都是hystrix.threadpool.threadpoolKey(groupKey or default).属性名。 二、hystrix在spring mvc的使用hystrix在Spring cloud的使用非常简单，网上也有很多文档，在此就不多讲了。 为使熔断控制和现有代码解耦，hystrix官方采用了Aspect方式。现在介绍hystrix在spring mvc的使用。 1、添加依赖使用maven引入hystrix依赖： &lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-javanica&lt;/artifactId&gt; &lt;version&gt;1.5.12&lt;/version&gt; &lt;/dependency&gt; 2、添加配置新建hystrix.properties文件（名字随意定，里面将定义项目所有hystrix配置信息） 新建一个类HystrixConfig public class HystrixConfig { public void init() { Properties prop = new Properties(); InputStream in = null; try { in = HystrixConfig.class.getClassLoader().getResourceAsStream(&quot;hystrix.properties&quot;); prop.load(in); in.close(); System.setProperties(prop); } catch (Exception e) { e.printStackTrace(); } } } 在spring的配置文件添加内容： &lt;!-- 添加了就不用加了 --&gt; &lt;aop:aspectj-autoproxy proxy-target-class=&quot;true&quot; /&gt; &lt;bean name=&quot;hystrixCommandAspect&quot; class=&quot;com.netflix.hystrix.contrib.javanica.aop.aspectj.HystrixCommandAspect&quot;/&gt; &lt;bean id=&quot;hystrixConfig&quot; class=&quot;包名.HystrixConfig&quot; init-method=&quot;init&quot;/&gt; 新建hystrixConfig bean主要是因为使用spring自带的context:property-placeholder配置加载器，hystrix无法读取。目前我只想到了通过System.setProperties的方式，若有其他方式欢迎指导。 3、hystrixCommand使用举个简单的例子(写成接口方式是方便测试，普通的方法效果是一样的)： @ResponseBody @RequestMapping(&quot;/test.html&quot;) @HystrixCommand public String test(int s) { logger.info(&quot;test.html start,s:{}&quot;, s); try { Thread.sleep(s * 1000); } catch (Exception e) { logger.error(&quot;test.html error.&quot;, e); } return &quot;OK&quot;; } 根据例子，我们可以看到和其他方法相比就添加了个@HystrixCommand注解，方法执行后会被HystrixCommandAspect拦截，拦截后会根据方法的基本属性（所在类、方法名、返回类型等）和HystrixCommand属性生成HystrixInvokable，最后执行。例子中，因为HystrixCommand属性为空，所以其groupKey默认为类名，commandKey为方法名。 通过HystrixCommand源码来看下可以设置的属性： @Target({ElementType.METHOD}) @Retention(RetentionPolicy.RUNTIME) @Inherited @Documented public @interface HystrixCommand { String groupKey() default &quot;&quot;; String commandKey() default &quot;&quot;; String threadPoolKey() default &quot;&quot;; String fallbackMethod() default &quot;&quot;; HystrixProperty[] commandProperties() default {}; HystrixProperty[] threadPoolProperties() default {}; Class&lt;? extends Throwable&gt;[] ignoreExceptions() default {}; ObservableExecutionMode observableExecutionMode() default ObservableExecutionMode.EAGER; HystrixException[] raiseHystrixExceptions() default {}; String defaultFallback() default &quot;&quot;; } 其中比较重要的是groupKey、commandKey、fallbackMethod（Fallback时调用的方法，一定要在同一个类中，且传参和返参要一致）。threadPoolKey一般可以不定义，线程池名会默认定义为groupKey。 再来看下HystrixCommandAspect是如何实现拦截的： @Pointcut(&quot;@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCommand)&quot;) public void hystrixCommandAnnotationPointcut() { } @Pointcut(&quot;@annotation(com.netflix.hystrix.contrib.javanica.annotation.HystrixCollapser)&quot;) public void hystrixCollapserAnnotationPointcut() { } @Around(&quot;hystrixCommandAnnotationPointcut() || hystrixCollapserAnnotationPointcut()&quot;) public Object methodsAnnotatedWithHystrixCommand(final ProceedingJoinPoint joinPoint) throws Throwable { Method method = getMethodFromTarget(joinPoint);//见步骤1 Validate.notNull(method, &quot;failed to get method from joinPoint: %s&quot;, joinPoint); if (method.isAnnotationPresent(HystrixCommand.class) &amp;&amp; method.isAnnotationPresent(HystrixCollapser.class)) { throw new IllegalStateException(&quot;method cannot be annotated with HystrixCommand and HystrixCollapser &quot; + &quot;annotations at the same time&quot;); } MetaHolderFactory metaHolderFactory = META_HOLDER_FACTORY_MAP.get(HystrixPointcutType.of(method));//见步骤2 MetaHolder metaHolder = metaHolderFactory.create(joinPoint);//见步骤3 HystrixInvokable invokable = HystrixCommandFactory.getInstance().create(metaHolder);//见步骤4 ExecutionType executionType = metaHolder.isCollapserAnnotationPresent() ? metaHolder.getCollapserExecutionType() : metaHolder.getExecutionType(); Object result; try { if (!metaHolder.isObservable()) { result = CommandExecutor.execute(invokable, executionType, metaHolder); } else { result = executeObservable(invokable, executionType, metaHolder);//见步骤5 } } catch (HystrixBadRequestException e) { throw e.getCause() != null ? e.getCause() : e; } catch (HystrixRuntimeException e) { throw hystrixRuntimeExceptionToThrowable(metaHolder, e); } return result; } 步骤1：获取切入点方法； 步骤2：根据方法的注解HystrixCommand或者HystrixCollapser生成相应的CommandMetaHolderFactory或者CollapserMetaHolderFactory类。 步骤3：将原方法的属性set进metaHolder中； 步骤4：根据metaHolder生成相应的HystrixCommand，包含加载hystrix配置信息。commandProperties加载的优先级为前缀hystrix.command.commandKey &gt; hystrix.command.default &gt; defaultValue(原代码默认)；threadPool配置加载的优先级为 前缀hystrix.threadpool.groupKey.&gt; hystrix.threadpool.default.&gt; defaultValue(原代码默认). 步骤5：执行命令。 倘若需要给该方法指定groupKey和commandKey定义其fallback方法，则可通过添加注解属性来实现。如： @ResponseBody @RequestMapping(&quot;/test.html&quot;) @HystrixCommand(groupKey = &quot;groupTest&quot;, commandKey = &quot;commandTest&quot;, fallbackMethod = &quot;back&quot;) public String test(int s) { try { Thread.sleep(s * 1000); } catch (Exception e) { } logger.info(&quot;test.html start&quot;); return &quot;OK&quot;; } private String back(int s) { return &quot;back&quot;; } groupKey=”groupTest”是将该hystrix操作的组名定义为groupTest，该属性在读取threadPoolProperties时需要用到。读取的策略是先读取已groupTest为键值的配置缓存；若没有则读取已hystrix.threadpool.groupTest.为前缀的配置；若没有则读取hystrix.threadpool.为前缀的配置，最后才读取代码默认的值。 commandKey=”commandTest”是将hystrix操作的命令名定义为commandTest，该属性在读取commandProperties时需要用到。读取的策略与上面的一致，只是前缀由hystrix.threadpool变为hystrix.command。 fallbackMethod=”back”是给该hystrix操作定义一个回退方法，值为回退方法的方法名，并且要与回退方法在同一个类下、相同的参入参数和返回参数。fallbackMethod可级联。 如果要给该方法指定一些hystrix属性，可通过在hystrix.properties中添加一些配置来实现。如给上述方法添加一些hystrix属性，示例如下： #定义commandKey为commandTest的过期时间为3s hystrix.command.commandTest.execution.isolation.thread.timeoutInMilliseconds=3000 #定义所有的默认过期时间为5s，不再是默认是1s。优先级小于上面配置 hystrix.command.default.execution.isolation.thread.timeoutInMilliseconds=5000 #定义threadPoolKey为groupTest的线程池大小为15 hystrix.threadpool.groupTest.coreSize=15 #定义所有的线程池大小为为5，不再是默认是10。优先级小于上面配置 hystrix.threadpool.default.coreSize=5 其余的配置方式与例子中的相似，就不一一列举了。 至此，spring mvc就可以为每一个依赖随心添加依赖隔离了。 三、监控hystrix除了隔离依赖服务的调用外，Hystrix还提供了近乎实时的监控，Hystrix会实时的，累加的记录所有关于HystrixCommand的执行信息，包括执行了每秒执行了多少请求，多少成功，多少失败等等。更多指标可以查看官网。 1、添加监控添加依赖使用maven引入hystrix-metrics-event-stream依赖： &lt;dependency&gt; &lt;groupId&gt;com.netflix.hystrix&lt;/groupId&gt; &lt;artifactId&gt;hystrix-metrics-event-stream&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;/dependency&gt; 修改web.xml在web.xml中添加代码： &lt;servlet&gt; &lt;description&gt;&lt;/description&gt; &lt;display-name&gt;HystrixMetricsStreamServlet&lt;/display-name&gt; &lt;servlet-name&gt;HystrixMetricsStreamServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.netflix.hystrix.contrib.metrics.eventstream.HystrixMetricsStreamServlet&lt;/servlet-class&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;HystrixMetricsStreamServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/hystrix.stream&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; 查看效果配置好后，重新启动应用，访问http://ip:port/appname/hystrix.stream，系统会不断刷新以获取实时的数据。 2、Dashboard可以看出，单纯使用字符输出的方式可读性太差，运维人员很难从中就看出系统的当前状态，于是Netflix又开发了一个开源项目dashboard来可视化这些数据，帮助运维人员更直观的了解系统的当前状态，Dashboard使用起来非常方便，其就是一个Web项目，你只需要把hystrix-dashboard.war包下载下来，放到一个Web容器（Tomcat,Jetty等）中即可。 启动容器，访问http://ip:port/hystrix-dashboard/#,就可以看到如下的界面： 按照上述操作点击monitor Streams,就可以查看该服务的hystrix监控了。监控界面如下： 可以看出，Dashboard主要展示了两类信息，一是HystrixCommand的执行情况，即circuit部分；二是线程池的状态，包括线程池名，大小，当前活跃线程说，最大活跃线程数，排队队列大小等，即Thread Pools部分。 然而，在复杂的分布式环境中，需要监控的不是单一一个ip的服务，可能需要监控一个集群甚至几个集群，而每个集群又可能有多个服务器，并且要可以扩展。倘若使用这种方案，运维人员需要添加N多监控路径。为解决该问题，Netflix又提供了一个开源项目Turbine来提供把多个hystrix.stream的内容聚合为一个数据源供Dashboard展示。 3、Turbine部署turbine操作： 下载turbine-web-1.0.0.war，并将war放入web容器中； 在容器下路径为turbine-web-1.0.0/WEB-INF/classes下新建config.properties文件； 根据实际情况配置相应参数，相应配置可以参考官网)： 调用http://ip:port/turbine-web/turbine.stream?cluster=${clusterConfigName}，查看是否有数据； 打开http://ip:port/hystrix-dashboard/#添加相应的turbine Stream。 配置详情主要包括三个方面： cluster配置：turbine一般会针对每一个cluster进行commandKeyThreadpoolcommandGroupKey数据聚合，其key名称为turbine.aggregator.clusterConfig，值为服务名称以逗号隔开； instances配置：每个服务对应的ip，其key名称为turbine.ConfigPropertyBasedDiscovery.${clusterConfigName}.instances，${clusterConfigName}为服务名，值为ip以逗号分隔； instanceUrlSuffix：hystrix监控url后缀，，其key名称为turbine.instanceUrlSuffix.${clusterConfigName}，值为端口+路径，其路径一般为/hystrix.stream。 三者之间的关系是，先定义clusterConfigName，然后根据instances和instanceUrlSuffix拼接出相应url，多个instances会将其metrics统计在一起，然后在http://turbineIP:turbinePORT/turbine-web/turbine.stream?cluster=${clusterConfigName}下进行展示。 示例如下图： Dashboard操作如图： 展示界面如图： 至此，hystrix在spring mvc的应用及其监控操作全部完成。 四、参考链接https://github.com/Netflix/Hystrix/tree/master/hystrix-contrib/hystrix-javanica https://github.com/Netflix/Hystrix/wiki https://github.com/Netflix/Hystrix/wiki/Dashboard https://github.com/Netflix/Turbine/wiki https://github.com/Netflix/Turbine/wiki/Configuration-(1.x)) http://youdang.github.io/categories/%E7%BF%BB%E8%AF%91/ http://www.cnblogs.com/java-zhao/p/5521233.html 转载请标明出处：http://blog.springcloud.cnhttp://tech.lede.com/2017/06/15/rd/server/hystrix/本文出自网易乐得技术团队-投稿于Spring Cloud中国社区","categories":[{"name":"后端","slug":"后端","permalink":"http://blog.springcloud.cn/categories/后端/"}],"tags":[{"name":"Netflix Hystrix","slug":"Netflix-Hystrix","permalink":"http://blog.springcloud.cn/tags/Netflix-Hystrix/"},{"name":"Spring mvc","slug":"Spring-mvc","permalink":"http://blog.springcloud.cn/tags/Spring-mvc/"},{"name":"dashboard","slug":"dashboard","permalink":"http://blog.springcloud.cn/tags/dashboard/"},{"name":"turbine","slug":"turbine","permalink":"http://blog.springcloud.cn/tags/turbine/"}]},{"title":"Spring Cloud之深入理解Eureka之源码解析","slug":"sc/sc-w-eureka","date":"2017-06-16T06:00:00.000Z","updated":"2017-06-20T13:03:39.000Z","comments":true,"path":"sc/sc-w-eureka/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-w-eureka/","excerpt":"","text":"上一篇：Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题 Eureka的一些概念 Register：服务注册当Eureka客户端向Eureka Server注册时，它提供自身的元数据，比如IP地址、端口，运行状况指示符URL，主页等。 Renew：服务续约Eureka客户会每隔30秒发送一次心跳来续约。 通过续约来告知Eureka Server该Eureka客户仍然存在，没有出现问题。 正常情况下，如果Eureka Server在90秒没有收到Eureka客户的续约，它会将实例从其注册表中删除。 建议不要更改续约间隔。 Fetch Registries：获取注册列表信息Eureka客户端从服务器获取注册表信息，并将其缓存在本地。客户端会使用该信息查找其他服务，从而进行远程调用。该注册列表信息定期（每30秒钟）更新一次。每次返回注册列表信息可能与Eureka客户端的缓存信息不同， Eureka客户端自动处理。如果由于某种原因导致注册列表信息不能及时匹配，Eureka客户端则会重新获取整个注册表信息。 Eureka服务器缓存注册列表信息，整个注册表以及每个应用程序的信息进行了压缩，压缩内容和没有压缩的内容完全相同。Eureka客户端和Eureka 服务器可以使用JSON / XML格式进行通讯。在默认的情况下Eureka客户端使用压缩JSON格式来获取注册列表的信息。 Cancel：服务下线Eureka客户端在程序关闭时向Eureka服务器发送取消请求。 发送请求后，该客户端实例信息将从服务器的实例注册表中删除。该下线请求不会自动完成，它需要调用以下内容：DiscoveryManager.getInstance().shutdownComponent()； Eviction 服务剔除在默认的情况下，当Eureka客户端连续90秒没有向Eureka服务器发送服务续约，即心跳，Eureka服务器会将该服务实例从服务注册列表删除，即服务剔除。 Eureka的高可用架构如图为Eureka的高级架构图，该图片来自于Eureka开源代码的文档，地址为https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance 。 从图可以看出在这个体系中，有2个角色，即Eureka Server和Eureka Client。而Eureka Client又分为Applicaton Service和Application Client，即服务提供者何服务消费者。 每个区域有一个Eureka集群，并且每个区域至少有一个eureka服务器可以处理区域故障，以防服务器瘫痪。 Eureka Client向Eureka Serve注册，并将自己的一些客户端信息发送Eureka Serve。然后，Eureka Client通过向Eureka Serve发送心跳（每30秒）来续约服务的。 如果客户端持续不能续约，那么，它将在大约90秒内从服务器注册表中删除。 注册信息和续订被复制到集群中的Eureka Serve所有节点。 来自任何区域的Eureka Client都可以查找注册表信息（每30秒发生一次）。根据这些注册表信息，Application Client可以远程调用Applicaton Service来消费服务。 Register服务注册服务注册，即Eureka Client向Eureka Server提交自己的服务信息，包括IP地址、端口、service ID等信息。如果Eureka Client没有写service ID，则默认为 ${spring.application.name}。 服务注册其实很简单，在Eureka Client启动的时候，将自身的服务的信息发送到Eureka Server。现在来简单的阅读下源码。在Maven的依赖包下，找到eureka-client-1.6.2.jar包。在com.netflix.discovery包下有个DiscoveryClient类，该类包含了Eureka Client向Eureka Server的相关方法。其中DiscoveryClient实现了EurekaClient接口，并且它是一个单例模式，而EurekaClient继承了LookupService接口。它们之间的关系如图所示。 在DiscoveryClient类有一个服务注册的方法register()，该方法是通过Http请求向Eureka Client注册。其代码如下： 1234567891011121314boolean register() throws Throwable &#123; logger.info(PREFIX + appPathIdentifier + &quot;: registering service...&quot;); EurekaHttpResponse&lt;Void&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.register(instanceInfo); &#125; catch (Exception e) &#123; logger.warn(&quot;&#123;&#125; - registration failed &#123;&#125;&quot;, PREFIX + appPathIdentifier, e.getMessage(), e); throw e; &#125; if (logger.isInfoEnabled()) &#123; logger.info(&quot;&#123;&#125; - registration status: &#123;&#125;&quot;, PREFIX + appPathIdentifier, httpResponse.getStatusCode()); &#125; return httpResponse.getStatusCode() == 204; &#125; 在DiscoveryClient类继续追踪register()方法，它被InstanceInfoReplicator 类的run()方法调用，其中InstanceInfoReplicator实现了Runnable接口，run()方法代码如下： 12345678910111213141516public void run() &#123; try &#123; discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) &#123; discoveryClient.register(); instanceInfo.unsetIsDirty(dirtyTimestamp); &#125; &#125; catch (Throwable t) &#123; logger.warn(&quot;There was a problem with the instance info replicator&quot;, t); &#125; finally &#123; Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); &#125; &#125; 而InstanceInfoReplicator类是在DiscoveryClient初始化过程中使用的，其中有一个initScheduledTasks()方法。该方法主要开启了获取服务注册列表的信息，如果需要向Eureka Server注册，则开启注册，同时开启了定时向Eureka Server服务续约的定时任务，具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738private void initScheduledTasks() &#123; ...//省略了任务调度获取注册列表的代码 if (clientConfig.shouldRegisterWithEureka()) &#123; ... // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( &quot;heartbeat&quot;, scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); // InstanceInfo replicator instanceInfoReplicator = new InstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); // burstSize statusChangeListener = new ApplicationInfoManager.StatusChangeListener() &#123; @Override public String getId() &#123; return &quot;statusChangeListener&quot;; &#125; @Override public void notify(StatusChangeEvent statusChangeEvent) &#123; instanceInfoReplicator.onDemandUpdate(); &#125; &#125;; ... &#125; 然后在来看Eureka server端的代码，在Maven的eureka-core:1.6.2的jar包下。打开com.netflix.eureka包，很轻松的就发现了又一个EurekaBootStrap的类，BootStrapContext具有最先初始化的权限，所以先看这个类。 1234567891011121314151617181920212223protected void initEurekaServerContext() throws Exception &#123; ...//省略代码 PeerAwareInstanceRegistry registry; if (isAws(applicationInfoManager.getInfo())) &#123; ...//省略代码，如果是AWS的代码 &#125; else &#123; registry = new PeerAwareInstanceRegistryImpl( eurekaServerConfig, eurekaClient.getEurekaClientConfig(), serverCodecs, eurekaClient ); &#125; PeerEurekaNodes peerEurekaNodes = getPeerEurekaNodes( registry, eurekaServerConfig, eurekaClient.getEurekaClientConfig(), serverCodecs, applicationInfoManager ); &#125; 其中PeerAwareInstanceRegistryImpl和PeerEurekaNodes两个类看其命名，应该和服务注册以及Eureka Server高可用有关。先追踪PeerAwareInstanceRegistryImpl类，在该类有个register()方法，该方法提供了注册，并且将注册后信息同步到其他的Eureka Server服务。代码如下： 12345678public void register(final InstanceInfo info, final boolean isReplication) &#123; int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) &#123; leaseDuration = info.getLeaseInfo().getDurationInSecs(); &#125; super.register(info, leaseDuration, isReplication); replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication); &#125; 其中 super.register(info, leaseDuration, isReplication)方法，点击进去到子类AbstractInstanceRegistry可以发现更多细节，其中注册列表的信息被保存在一个Map中。replicateToPeers()方法，即同步到其他Eureka Server的其他Peers节点，追踪代码，发现它会遍历循环向所有的Peers节点注册，最终执行类PeerEurekaNodes的register()方法，该方法通过执行一个任务向其他节点同步该注册信息，代码如下： 123456789101112public void register(final InstanceInfo info) throws Exception &#123; long expiryTime = System.currentTimeMillis() + getLeaseRenewalOf(info); batchingDispatcher.process( taskId(&quot;register&quot;, info), new InstanceReplicationTask(targetHost, Action.Register, info, null, true) &#123; public EurekaHttpResponse&lt;Void&gt; execute() &#123; return replicationClient.register(info); &#125; &#125;, expiryTime ); &#125; 经过一系列的源码追踪，可以发现PeerAwareInstanceRegistryImpl的register()方法实现了服务的注册，并且向其他Eureka Server的Peer节点同步了该注册信息，那么register()方法被谁调用了呢？之前在Eureka Client的分析可以知道，Eureka Client是通过 http来向Eureka Server注册的，那么Eureka Server肯定会提供一个注册的接口给Eureka Client调用，那么PeerAwareInstanceRegistryImpl的register()方法肯定最终会被暴露的Http接口所调用。在Idea开发工具，按住alt+鼠标左键，可以很快定位到ApplicationResource类的addInstance ()方法，即服务注册的接口，其代码如下： 12345678910@POST @Consumes(&#123;&quot;application/json&quot;, &quot;application/xml&quot;&#125;) public Response addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) &#123; ...//省略代码 registry.register(info, &quot;true&quot;.equals(isReplication)); return Response.status(204).build(); // 204 to be backwards compatible &#125; Renew服务续约服务续约和服务注册非常类似，通过之前的分析可以知道，服务注册在Eureka Client程序启动之后开启，并同时开启服务续约的定时任务。在eureka-client-1.6.2.jar的DiscoveryClient的类下有renew()方法，其代码如下： 12345678910111213141516171819/** * Renew with the eureka service by making the appropriate REST call */ boolean renew() &#123; EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(&quot;&#123;&#125; - Heartbeat status: &#123;&#125;&quot;, PREFIX + appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == 404) &#123; REREGISTER_COUNTER.increment(); logger.info(&quot;&#123;&#125; - Re-registering apps/&#123;&#125;&quot;, PREFIX + appPathIdentifier, instanceInfo.getAppName()); return register(); &#125; return httpResponse.getStatusCode() == 200; &#125; catch (Throwable e) &#123; logger.error(&quot;&#123;&#125; - was unable to send heartbeat!&quot;, PREFIX + appPathIdentifier, e); return false; &#125; &#125; 另外服务端的续约接口在eureka-core:1.6.2.jar的 com.netflix.eureka包下的InstanceResource类下，接口方法为renewLease()，它是REST接口。为了减少类篇幅，省略了大部分代码的展示。其中有个registry.renew()方法，即服务续约，代码如下: 123456@PUTpublic Response renewLease(...参数省略）&#123; ... 代码省略 boolean isSuccess=registry.renew(app.getName(),id, isFromReplicaNode); ... 代码省略 &#125; 读者可以跟踪registry.renew的代码一直深入研究。在这里就不再多讲述。另外服务续约有2个参数是可以配置，即Eureka Client发送续约心跳的时间参数和Eureka Server在多长时间内没有收到心跳将实例剔除的时间参数，在默认的情况下这两个参数分别为30秒和90秒，官方给的建议是不要修改，如果有特殊要求还是可以调整的，只需要分别在Eureka Client和Eureka Server修改以下参数： 12eureka.instance.leaseRenewalIntervalInSecondseureka.instance.leaseExpirationDurationInSeconds 最后，服务注册列表的获取、服务下线和服务剔除就不在这里进行源码跟踪解读，因为和服务注册和续约类似，有兴趣的朋友可以自己看下源码，深入理解。总的来说，通过读源码，可以发现，整体架构与前面小节的eureka 的高可用架构图完全一致。 Eureka Client注册一个实例为什么这么慢 Eureka Client一启动（不是启动完成），不是立即向Eureka Server注册，它有一个延迟向服务端注册的时间，通过跟踪源码，可以发现默认的延迟时间为40秒，源码在eureka-client-1.6.2.jar的DefaultEurekaClientConfig类下，代码如下： 1234public int getInitialInstanceInfoReplicationIntervalSeconds() &#123; return configInstance.getIntProperty( namespace + INITIAL_REGISTRATION_REPLICATION_DELAY_KEY, 40).get(); &#125; Eureka Server的响应缓存Eureka Server维护每30秒更新的响应缓存,可通过更改配置eureka.server.responseCacheUpdateIntervalMs来修改。 所以即使实例刚刚注册，它也不会出现在调用/ eureka / apps REST端点的结果中。 Eureka Server刷新缓存Eureka客户端保留注册表信息的缓存。 该缓存每30秒更新一次（如前所述）。 因 此，客户端决定刷新其本地缓存并发现其他新注册的实例可能需要30秒。 LoadBalancer RefreshRibbon的负载平衡器从本地的Eureka Client获取服务注册列表信息。Ribbon本身还维护本地缓存，以避免为每个请求调用本地客户端。 此缓存每30秒刷新一次（可由ribbon.ServerListRefreshInterval配置）。 所以，可能需要30多秒才能使用新注册的实例。 综上几个因素，一个新注册的实例，特别是启动较快的实例（默认延迟40秒注册），不能马上被Eureka Server发现。另外，刚注册的Eureka Client也不能立即被其他服务调用，因为调用方因为各种缓存没有及时的获取到新的注册列表。 Eureka 的自我保护模式当一个新的Eureka Server出现时，它尝试从相邻节点获取所有实例注册表信息。如果从Peer节点获取信息时出现问题，Eureka Serve会尝试其他的Peer节点。如果服务器能够成功获取所有实例，则根据该信息设置应该接收的更新阈值。如果有任何时间，Eureka Serve接收到的续约低于为该值配置的百分比（默认为15分钟内低于85％），则服务器开启自我保护模式，即不再剔除注册列表的信息。 这样做的好处就是，如果是Eureka Server自身的网络问题，导致Eureka Client的续约不上，Eureka Client的注册列表信息不再被删除，也就是Eureka Client还可以被其他服务消费。 转载请标明出处：http://blog.csdn.net/forezp/article/details/73017664本文出自方志朋的博客 参考资料http://cloud.spring.io/spring-cloud-static/Dalston.RELEASE/#netflix-eureka-client-starter https://github.com/Netflix/eureka/wiki https://github.com/Netflix/eureka/wiki/Understanding-Eureka-Peer-to-Peer-Communication http://xujin.org/sc/sc-eureka-register/ http://blog.abhijitsarkar.org/technical/netflix-eureka/ http://nobodyiam.com/2016/06/25/dive-into-eureka/","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"}]},{"title":"Spring Cloud之深入理解Feign之源码解析","slug":"sc/sc-w-feign","date":"2017-06-16T06:00:00.000Z","updated":"2017-06-20T13:03:49.000Z","comments":true,"path":"sc/sc-w-feign/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-w-feign/","excerpt":"","text":"上一篇：深入理解Eureka 什么是FeignFeign是受到Retrofit，JAXRS-2.0和WebSocket的影响，它是一个jav的到http客户端绑定的开源项目。 Feign的主要目标是将Java Http 客户端变得简单。Feign的源码地址：https://github.com/OpenFeign/feign 写一个Feign在我之前的博文有写到如何用Feign去消费服务，文章地址：http://blog.csdn.net/forezp/article/details/69808079 。 现在来简单的实现一个Feign客户端，首先通过@FeignClient，客户端，其中value为调用其他服务的名称，FeignConfig.class为FeignClient的配置文件，代码如下： 123456@FeignClient(value = &quot;service-hi&quot;,configuration = FeignConfig.class)public interface SchedualServiceHi &#123; @GetMapping(value = &quot;/hi&quot;) String sayHiFromClientOne(@RequestParam(value = &quot;name&quot;) String name);&#125; 其自定义配置文件如下，当然也可以不写配置文件，用默认的即可： 123456789@Configurationpublic class FeignConfig &#123; @Bean public Retryer feignRetryer() &#123; return new Retryer.Default(100, SECONDS.toMillis(1), 5); &#125; &#125; 查看FeignClient注解的源码，其代码如下： 1234567891011121314151617181920212223242526@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface FeignClient &#123;@AliasFor(&quot;name&quot;)String value() default &quot;&quot;; @AliasFor(&quot;value&quot;)String name() default &quot;&quot;; @AliasFor(&quot;value&quot;)String name() default &quot;&quot;;String url() default &quot;&quot;;boolean decode404() default false;Class&lt;?&gt;[] configuration() default &#123;&#125;;Class&lt;?&gt; fallback() default void.class;Class&lt;?&gt; fallbackFactory() default void.class;&#125;String path() default &quot;&quot;;boolean primary() default true; FeignClient注解被@Target(ElementType.TYPE)修饰，表示FeignClient注解的作用目标在接口上；@Retention(RetentionPolicy.RUNTIME)，注解会在class字节码文件中存在，在运行时可以通过反射获取到；@Documented表示该注解将被包含在javadoc中。 feign 用于声明具有该接口的REST客户端的接口的注释应该是创建（例如用于自动连接到另一个组件。 如果功能区可用，那将是用于负载平衡后端请求，并且可以配置负载平衡器使用与伪装客户端相同名称（即值）@RibbonClient 。 其中value()和name()一样，是被调用的 service的名称。url(),直接填写硬编码的url,decode404()即404是否被解码，还是抛异常；configuration()，标明FeignClient的配置类，默认的配置类为FeignClientsConfiguration类，可以覆盖Decoder、Encoder和Contract等信息，进行自定义配置。fallback(),填写熔断器的信息类。 FeignClient的配置默认的配置类为FeignClientsConfiguration，这个类在spring-cloud-netflix-core的jar包下，打开这个类，可以发现它是一个配置类，注入了很多的相关配置的bean，包括feignRetryer、FeignLoggerFactory、FormattingConversionService等,其中还包括了Decoder、Encoder、Contract，如果这三个bean在没有注入的情况下，会自动注入默认的配置。 Decoder feignDecoder: ResponseEntityDecoder(这是对SpringDecoder的封装) Encoder feignEncoder: SpringEncoder Logger feignLogger: Slf4jLogger Contract feignContract: SpringMvcContract Feign.Builder feignBuilder: HystrixFeign.Builder 代码如下： 12345678910111213141516171819202122232425@Configurationpublic class FeignClientsConfiguration &#123;...//省略代码@Bean @ConditionalOnMissingBean public Decoder feignDecoder() &#123; return new ResponseEntityDecoder(new SpringDecoder(this.messageConverters)); &#125; @Bean @ConditionalOnMissingBean public Encoder feignEncoder() &#123; return new SpringEncoder(this.messageConverters); &#125; @Bean @ConditionalOnMissingBean public Contract feignContract(ConversionService feignConversionService) &#123; return new SpringMvcContract(this.parameterProcessors, feignConversionService); &#125;...//省略代码&#125; 重写配置： 你可以重写FeignClientsConfiguration中的bean，从而达到自定义配置的目的，比如FeignClientsConfiguration的默认重试次数为Retryer.NEVER_RETRY，即不重试，那么希望做到重写，写个配置文件，注入feignRetryer的bean,代码如下： 123456789@Configurationpublic class FeignConfig &#123; @Bean public Retryer feignRetryer() &#123; return new Retryer.Default(100, SECONDS.toMillis(1), 5); &#125;&#125; 在上述代码更改了该FeignClient的重试次数，重试间隔为100ms，最大重试时间为1s,重试次数为5次。 Feign的工作原理feign是一个伪客户端，即它不做任何的请求处理。Feign通过处理注解生成request，从而实现简化HTTP API开发的目的，即开发人员可以使用注解的方式定制request api模板，在发送http request请求之前，feign通过处理注解的方式替换掉request模板中的参数，这种实现方式显得更为直接、可理解。 通过包扫描注入FeignClient的bean，该源码在FeignClientsRegistrar类：首先在启动配置上检查是否有@EnableFeignClients注解，如果有该注解，则开启包扫描，扫描被@FeignClient注解接口。代码如下： 1234567891011121314151617private void registerDefaultConfiguration(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; Map&lt;String, Object&gt; defaultAttrs = metadata .getAnnotationAttributes(EnableFeignClients.class.getName(), true); if (defaultAttrs != null &amp;&amp; defaultAttrs.containsKey(&quot;defaultConfiguration&quot;)) &#123; String name; if (metadata.hasEnclosingClass()) &#123; name = &quot;default.&quot; + metadata.getEnclosingClassName(); &#125; else &#123; name = &quot;default.&quot; + metadata.getClassName(); &#125; registerClientConfiguration(registry, name, defaultAttrs.get(&quot;defaultConfiguration&quot;)); &#125; &#125; 程序启动后通过包扫描，当类有@FeignClient注解，将注解的信息取出，连同类名一起取出，赋给BeanDefinitionBuilder，然后根据BeanDefinitionBuilder得到beanDefinition，最后beanDefinition式注入到ioc容器中，源码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public void registerFeignClients(AnnotationMetadata metadata, BeanDefinitionRegistry registry) &#123; ClassPathScanningCandidateComponentProvider scanner = getScanner(); scanner.setResourceLoader(this.resourceLoader); Set&lt;String&gt; basePackages; Map&lt;String, Object&gt; attrs = metadata .getAnnotationAttributes(EnableFeignClients.class.getName()); AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter( FeignClient.class); final Class&lt;?&gt;[] clients = attrs == null ? null : (Class&lt;?&gt;[]) attrs.get(&quot;clients&quot;); if (clients == null || clients.length == 0) &#123; scanner.addIncludeFilter(annotationTypeFilter); basePackages = getBasePackages(metadata); &#125; else &#123; final Set&lt;String&gt; clientClasses = new HashSet&lt;&gt;(); basePackages = new HashSet&lt;&gt;(); for (Class&lt;?&gt; clazz : clients) &#123; basePackages.add(ClassUtils.getPackageName(clazz)); clientClasses.add(clazz.getCanonicalName()); &#125; AbstractClassTestingTypeFilter filter = new AbstractClassTestingTypeFilter() &#123; @Override protected boolean match(ClassMetadata metadata) &#123; String cleaned = metadata.getClassName().replaceAll(&quot;\\\\$&quot;, &quot;.&quot;); return clientClasses.contains(cleaned); &#125; &#125;; scanner.addIncludeFilter( new AllTypeFilter(Arrays.asList(filter, annotationTypeFilter))); &#125; for (String basePackage : basePackages) &#123; Set&lt;BeanDefinition&gt; candidateComponents = scanner .findCandidateComponents(basePackage); for (BeanDefinition candidateComponent : candidateComponents) &#123; if (candidateComponent instanceof AnnotatedBeanDefinition) &#123; // verify annotated class is an interface AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent; AnnotationMetadata annotationMetadata = beanDefinition.getMetadata(); Assert.isTrue(annotationMetadata.isInterface(), &quot;@FeignClient can only be specified on an interface&quot;); Map&lt;String, Object&gt; attributes = annotationMetadata .getAnnotationAttributes( FeignClient.class.getCanonicalName()); String name = getClientName(attributes); registerClientConfiguration(registry, name, attributes.get(&quot;configuration&quot;)); registerFeignClient(registry, annotationMetadata, attributes); &#125; &#125; &#125; &#125;private void registerFeignClient(BeanDefinitionRegistry registry, AnnotationMetadata annotationMetadata, Map&lt;String, Object&gt; attributes) &#123; String className = annotationMetadata.getClassName(); BeanDefinitionBuilder definition = BeanDefinitionBuilder .genericBeanDefinition(FeignClientFactoryBean.class); validate(attributes); definition.addPropertyValue(&quot;url&quot;, getUrl(attributes)); definition.addPropertyValue(&quot;path&quot;, getPath(attributes)); String name = getName(attributes); definition.addPropertyValue(&quot;name&quot;, name); definition.addPropertyValue(&quot;type&quot;, className); definition.addPropertyValue(&quot;decode404&quot;, attributes.get(&quot;decode404&quot;)); definition.addPropertyValue(&quot;fallback&quot;, attributes.get(&quot;fallback&quot;)); definition.addPropertyValue(&quot;fallbackFactory&quot;, attributes.get(&quot;fallbackFactory&quot;)); definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE); String alias = name + &quot;FeignClient&quot;; AbstractBeanDefinition beanDefinition = definition.getBeanDefinition(); boolean primary = (Boolean)attributes.get(&quot;primary&quot;); // has a default, won&apos;t be null beanDefinition.setPrimary(primary); String qualifier = getQualifier(attributes); if (StringUtils.hasText(qualifier)) &#123; alias = qualifier; &#125; BeanDefinitionHolder holder = new BeanDefinitionHolder(beanDefinition, className, new String[] &#123; alias &#125;); BeanDefinitionReaderUtils.registerBeanDefinition(holder, registry); &#125; 注入bean之后，通过jdk的代理，当请求Feign Client的方法时会被拦截，代码在ReflectiveFeign类，代码如下： 123456789101112131415161718192021222324public &lt;T&gt; T newInstance(Target&lt;T&gt; target) &#123; Map&lt;String, MethodHandler&gt; nameToHandler = targetToHandlersByName.apply(target); Map&lt;Method, MethodHandler&gt; methodToHandler = new LinkedHashMap&lt;Method, MethodHandler&gt;(); List&lt;DefaultMethodHandler&gt; defaultMethodHandlers = new LinkedList&lt;DefaultMethodHandler&gt;(); for (Method method : target.type().getMethods()) &#123; if (method.getDeclaringClass() == Object.class) &#123; continue; &#125; else if(Util.isDefault(method)) &#123; DefaultMethodHandler handler = new DefaultMethodHandler(method); defaultMethodHandlers.add(handler); methodToHandler.put(method, handler); &#125; else &#123; methodToHandler.put(method, nameToHandler.get(Feign.configKey(target.type(), method))); &#125; &#125; InvocationHandler handler = factory.create(target, methodToHandler); T proxy = (T) Proxy.newProxyInstance(target.type().getClassLoader(), new Class&lt;?&gt;[]&#123;target.type()&#125;, handler); for(DefaultMethodHandler defaultMethodHandler : defaultMethodHandlers) &#123; defaultMethodHandler.bindTo(proxy); &#125; return proxy; &#125; 在SynchronousMethodHandler类进行拦截处理，当被FeignClient的方法被拦截会根据参数生成RequestTemplate对象，该对象就是http请求的模板，代码如下： 12345678910111213141516@Override public Object invoke(Object[] argv) throws Throwable &#123; RequestTemplate template = buildTemplateFromArgs.create(argv); Retryer retryer = this.retryer.clone(); while (true) &#123; try &#123; return executeAndDecode(template); &#125; catch (RetryableException e) &#123; retryer.continueOrPropagate(e); if (logLevel != Logger.Level.NONE) &#123; logger.logRetry(metadata.configKey(), logLevel); &#125; continue; &#125; &#125; &#125; 其中有个executeAndDecode()方法，该方法是通RequestTemplate生成Request请求对象，然后根据用client获取response。 1234567 Object executeAndDecode(RequestTemplate template) throws Throwable &#123; Request request = targetRequest(template); ...//省略代码 response = client.execute(request, options); ...//省略代码&#125; Client组件其中Client组件是一个非常重要的组件，Feign最终发送request请求以及接收response响应，都是由Client组件完成的，其中Client的实现类，只要有Client.Default，该类由HttpURLConnnection实现网络请求，另外还支持HttpClient、Okhttp. 首先来看以下在FeignRibbonClient的自动配置类，FeignRibbonClientAutoConfiguration ，主要在工程启动的时候注入一些bean,其代码如下： 1234567891011121314@ConditionalOnClass(&#123; ILoadBalancer.class, Feign.class &#125;)@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignRibbonClientAutoConfiguration &#123;@Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; return new LoadBalancerFeignClient(new Client.Default(null, null), cachingFactory, clientFactory); &#125;&#125; 在缺失配置feignClient的情况下，会自动注入new Client.Default(),跟踪Client.Default()源码，它使用的网络请求框架为HttpURLConnection，代码如下： 12345@Override public Response execute(Request request, Options options) throws IOException &#123; HttpURLConnection connection = convertAndSend(request, options); return convertResponse(connection).toBuilder().request(request).build(); &#125; 怎么在feign中使用HttpClient，查看FeignRibbonClientAutoConfiguration的源码 12345678910111213141516171819202122232425262728293031@ConditionalOnClass(&#123; ILoadBalancer.class, Feign.class &#125;)@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignRibbonClientAutoConfiguration &#123;...//省略代码@Configuration @ConditionalOnClass(ApacheHttpClient.class) @ConditionalOnProperty(value = &quot;feign.httpclient.enabled&quot;, matchIfMissing = true) protected static class HttpClientFeignLoadBalancedConfiguration &#123; @Autowired(required = false) private HttpClient httpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; ApacheHttpClient delegate; if (this.httpClient != null) &#123; delegate = new ApacheHttpClient(this.httpClient); &#125; else &#123; delegate = new ApacheHttpClient(); &#125; return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); &#125; &#125;...//省略代码&#125; 从代码@ConditionalOnClass(ApacheHttpClient.class)注解可知道，只需要在pom文件加上HttpClient的classpath就行了，另外需要在配置文件上加上feign.httpclient.enabled为true，从 @ConditionalOnProperty注解可知，这个可以不写，在默认的情况下就为true. 在pom文件加上： 123456&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt; 同理，如果想要feign使用Okhttp，则只需要在pom文件上加上feign-okhttp的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;RELEASE&lt;/version&gt;&lt;/dependency&gt; feign的负载均衡是怎么样实现的呢？通过上述的FeignRibbonClientAutoConfiguration类配置Client的类型(httpurlconnection，okhttp和httpclient)时候，可知最终向容器注入的是LoadBalancerFeignClient，即负载均衡客户端。现在来看下LoadBalancerFeignClient的代码： 123456789101112131415161718192021@Overridepublic Response execute(Request request, Request.Options options) throws IOException &#123; try &#123; URI asUri = URI.create(request.url()); String clientName = asUri.getHost(); URI uriWithoutHost = cleanUrl(request.url(), clientName); FeignLoadBalancer.RibbonRequest ribbonRequest = new FeignLoadBalancer.RibbonRequest( this.delegate, request, uriWithoutHost); IClientConfig requestConfig = getClientConfig(options, clientName); return lbClient(clientName).executeWithLoadBalancer(ribbonRequest, requestConfig).toResponse(); &#125; catch (ClientException e) &#123; IOException io = findIOException(e); if (io != null) &#123; throw io; &#125; throw new RuntimeException(e); &#125;&#125; 其中有个executeWithLoadBalancer()方法，即通过负载均衡的方式请求。 1234567891011121314151617181920212223242526272829303132333435public T executeWithLoadBalancer(final S request, final IClientConfig requestConfig) throws ClientException &#123; RequestSpecificRetryHandler handler = getRequestSpecificRetryHandler(request, requestConfig); LoadBalancerCommand&lt;T&gt; command = LoadBalancerCommand.&lt;T&gt;builder() .withLoadBalancerContext(this) .withRetryHandler(handler) .withLoadBalancerURI(request.getUri()) .build(); try &#123; return command.submit( new ServerOperation&lt;T&gt;() &#123; @Override public Observable&lt;T&gt; call(Server server) &#123; URI finalUri = reconstructURIWithServer(server, request.getUri()); S requestForServer = (S) request.replaceUri(finalUri); try &#123; return Observable.just(AbstractLoadBalancerAwareClient.this.execute(requestForServer, requestConfig)); &#125; catch (Exception e) &#123; return Observable.error(e); &#125; &#125; &#125;) .toBlocking() .single(); &#125; catch (Exception e) &#123; Throwable t = e.getCause(); if (t instanceof ClientException) &#123; throw (ClientException) t; &#125; else &#123; throw new ClientException(e); &#125; &#125; &#125; 其中服务在submit()方法上，点击submit进入具体的方法,这个方法是LoadBalancerCommand的方法： 123456789Observable&lt;T&gt; o = (server == null ? selectServer() : Observable.just(server)) .concatMap(new Func1&lt;Server, Observable&lt;T&gt;&gt;() &#123; @Override // Called for each server being selected public Observable&lt;T&gt; call(Server server) &#123; context.setServer(server); &#125;&#125; 上述代码中有个selectServe()，该方法是选择服务的进行负载均衡的方法，代码如下： 1234567891011121314private Observable&lt;Server&gt; selectServer() &#123; return Observable.create(new OnSubscribe&lt;Server&gt;() &#123; @Override public void call(Subscriber&lt;? super Server&gt; next) &#123; try &#123; Server server = loadBalancerContext.getServerFromLoadBalancer(loadBalancerURI, loadBalancerKey); next.onNext(server); next.onCompleted(); &#125; catch (Exception e) &#123; next.onError(e); &#125; &#125; &#125;);&#125; 最终负载均衡交给loadBalancerContext来处理，即之前讲述的Ribbon，在这里不再重复。 总结总到来说，Feign的源码实现的过程如下： 首先通过@EnableFeignCleints注解开启FeignCleint 根据Feign的规则实现接口，并加@FeignCleint注解 程序启动后，会进行包扫描，扫描所有的@ FeignCleint的注解的类，并将这些信息注入到ioc容器中。 当接口的方法被调用，通过jdk的代理，来生成具体的RequesTemplate RequesTemplate在生成Request Request交给Client去处理，其中Client可以是HttpUrlConnection、HttpClient也可以是Okhttp 最后Client被封装到LoadBalanceClient类，这个类结合类Ribbon做到了负载均衡。 转载请标明出处：http://blog.csdn.net/forezp/article/details/73480304本文出自方志朋的博客 参考资料https://github.com/OpenFeign/feign https://blog.de-swaef.eu/the-netflix-stack-using-spring-boot-part-3-feign/","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Feign","slug":"Spring-Cloud-Feign","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Feign/"}]},{"title":"Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题","slug":"sc/sc-feign-4xx","date":"2017-06-16T06:00:00.000Z","updated":"2017-06-17T07:38:15.000Z","comments":true,"path":"sc/sc-feign-4xx/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-feign-4xx/","excerpt":"上一篇：在Spring Cloud中实现降级之权重路由和标签路由 前言 最近好几个小伙伴，问Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题。这个问题如果没有自定义异常自定义Code或者系统中没有自定义code为401或407的code，基本很少能碰到。刚好Spring Cloud中国社区的VIP会员任聪博客原文也遇到这个，经过和他交流之后。整理出这篇文章希望能帮助更多的人快速定位问题。","text":"上一篇：在Spring Cloud中实现降级之权重路由和标签路由 前言 最近好几个小伙伴，问Spring Cloud项目中通过Feign进行内部服务调用发生401\\407错误无返回信息的问题。这个问题如果没有自定义异常自定义Code或者系统中没有自定义code为401或407的code，基本很少能碰到。刚好Spring Cloud中国社区的VIP会员任聪博客原文也遇到这个，经过和他交流之后。整理出这篇文章希望能帮助更多的人快速定位问题。 问题描述最近在使用Spring Cloud改造现有服务的工作中，在内部服务的调用方式上选择了Feign组件，由于服务与服务之间有权限控制，发现通过Feign来进行调用时如果发生了401、407错误时，调用方不能够取回被调用方返回的错误信息。 产生原因分析产生原因Feign默认使用java.net.HttpURLConnection进行通信，通过查看其子类sun.net.www.protocol.http.HttpURLConnection源码发现代码中在进行通信时单独对错误码为401\\407的错误请求做了处理，当请求的错误码为401\\407时，会关闭请求流，由于此时还并没有将返回的错误信息写入响应流中，所以接收的返回信息中仅仅能获取到response.status()，而response.body()为null。HttpURLConnection相关信息的源码链接 问题源代码示例1234567if (respCode == HTTP_UNAUTHORIZED) &#123; if (streaming()) &#123; disconnectInternal(); throw new HttpRetryException (RETRY_MSG2, HTTP_UNAUTHORIZED); &#125; //其余代码省略&#125; java.net.HttpURLConnection中的HTTP_UNAUTHORIZED的定义如下: 1public static final int HTTP_UNAUTHORIZED = 401; 解决思路关于此问题产生的原因已经很明显了，就是feign.Client实现通信的方式选用了我们不想使用的HttpURLConnection。想到通常在Spring的代码中OCP都是运用得很好的，所以基本上有解决此问题的信心了，最不济就是自己扩展Feign，实现一个自己想要的feign.Client，当然这种事情Spring Cloud基本都会自己搞定，这也是Spring Cloud强大完善的一个地方。通过这个思路查看源码，果然看到了Spring Cloud在使用Feign提前内置了三种通信方式（feign.Client.Default，feign.httpclient.ApacheHttpClient，feign.okhttp.OkHttpClient），其中缺省的情况使用的就是feign.Client.Default，这个就是使用HttpURLConnection通信的方式。 源码解析在Spring Cloud项目中使用了Ribbon的组件，其会帮助我们管理使用Feign，查看org.springframework.cloud.netflix.feign.ribbon.FeignRibbonClientAutoConfiguration源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859@ConditionalOnClass(&#123; ILoadBalancer.class, Feign.class &#125;)@Configuration@AutoConfigureBefore(FeignAutoConfiguration.class)public class FeignRibbonClientAutoConfiguration &#123; @Bean @ConditionalOnMissingBean public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; return new LoadBalancerFeignClient(new Client.Default(null, null), cachingFactory, clientFactory); &#125; @Configuration @ConditionalOnClass(ApacheHttpClient.class) @ConditionalOnProperty(value = \"feign.httpclient.enabled\", matchIfMissing = true) protected static class HttpClientFeignLoadBalancedConfiguration &#123; @Autowired(required = false) private HttpClient httpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; ApacheHttpClient delegate; if (this.httpClient != null) &#123; delegate = new ApacheHttpClient(this.httpClient); &#125; else &#123; delegate = new ApacheHttpClient(); &#125; return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); &#125; &#125; @Configuration @ConditionalOnClass(OkHttpClient.class) @ConditionalOnProperty(value = \"feign.okhttp.enabled\", matchIfMissing = true) protected static class OkHttpFeignLoadBalancedConfiguration &#123; @Autowired(required = false) private okhttp3.OkHttpClient okHttpClient; @Bean @ConditionalOnMissingBean(Client.class) public Client feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) &#123; OkHttpClient delegate; if (this.okHttpClient != null) &#123; delegate = new OkHttpClient(this.okHttpClient); &#125; else &#123; delegate = new OkHttpClient(); &#125; return new LoadBalancerFeignClient(delegate, cachingFactory, clientFactory); &#125; &#125;&#125; 从feignClient(CachingSpringLoadBalancerFactory cachingFactory, SpringClientFactory clientFactory) 方法结合其上注解我们可以很清楚的知道，当没有feign.ClientBean的时候会默认生成feign.Client.Default来进行通信，这就是之前说的缺省通信方式 从HttpClientFeignLoadBalancedConfiguration、OkHttpFeignLoadBalancedConfiguration，我们可以看到其生效的条件，当classpath中有feign.httpclient.ApacheHttpClient并且配置feign.httpclient.enabled=true（缺省为true）、feign.okhttp.OkHttpClient并且配置feign.okhttp.enabled=true（缺省为true） 当使用ApacheHttpClient或者OkHttpClient进行通信时就不会导致发生401\\407错误时，取不到返回的错误信息了 解决方法通过其上的分析，解决方法已经显而易见了替换默认的Client pom.xml文件中新增依赖替换为默认为okhttp Client 增加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-okhttp&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt; &lt;/dependency&gt; 2.在application.properties增加配置如下: 1feign.okhttp.enabled=true 如何把默认的Client替换为okhttp在这里不做过多阐述，可以参考： 替换为httpclient 增加依赖 12345&lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.18.0&lt;/version&gt; &lt;/dependency&gt; 2.在application.properties增加配置如下: 1feign.httpclient.enabled=true 可以参考更换Feign默认使用的HTTP Client 总结 由于新增的依赖没有被start管理，并且缺省不会导致程序启动异常，并且返回响应为null与此依赖没有直接关系，因此不方便定位到问题，特此记录下来，希望能帮助到遇到同样问题的人，如对文章有不同的看法，望给予指正。 本文建立在已经搭建完成Feign的调用基础之上，没有讲述Feign的使用，因为此类文章很多，在此就不重复了，更多的信息可以参考如下文章。 快速使用Spring Cloud Feign作为客户端调用服务提供者spring cloud feign使用okhttp3","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Feign","slug":"Spring-Cloud-Feign","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Feign/"}]},{"title":"在Spring Cloud中实现降级之权重路由和标签路由","slug":"sc/sc-ribbon-demoted","date":"2017-06-03T06:00:00.000Z","updated":"2017-06-17T05:06:55.000Z","comments":true,"path":"sc/sc-ribbon-demoted/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-ribbon-demoted/","excerpt":"前言 限流、降级、灰度是服务治理的一个很重要的功能。本文参考Spring Cloud中国社区的VIP会员-何鹰的博客-整理Dubbo自带服务降级、限流功能，spring cloud并没有提供此功能，只能由我们自行实现。这里的限流、降级、灰度都是针对服务实例级别，并不是整个服务级别，整个服务级别可以通过实例部署数量来实现。 限流降级设计场景服务A，部署了3个实例A1、A2、A3。spring cloud默认客户端负载均衡策略是采用轮询方式，A1、A2、A3三个实例流量均分，各1/3。如果这个时候需要将服务A由1.0版升级至2.0版，我们需要做的步骤是：将A1的流量降为0，柔性下线，关闭A1实例并升级到2.0，将A1流量提升为10%观察2.0线上运行情况，如果情况稳定，则逐步开放流量至不限制及1/3。依次在A2，A3上执行上述操作。在上述步骤中，我们想让特别的人使用2.0，其他人还是使用1.0版，稳定后再全员开放。","text":"前言 限流、降级、灰度是服务治理的一个很重要的功能。本文参考Spring Cloud中国社区的VIP会员-何鹰的博客-整理Dubbo自带服务降级、限流功能，spring cloud并没有提供此功能，只能由我们自行实现。这里的限流、降级、灰度都是针对服务实例级别，并不是整个服务级别，整个服务级别可以通过实例部署数量来实现。 限流降级设计场景服务A，部署了3个实例A1、A2、A3。spring cloud默认客户端负载均衡策略是采用轮询方式，A1、A2、A3三个实例流量均分，各1/3。如果这个时候需要将服务A由1.0版升级至2.0版，我们需要做的步骤是：将A1的流量降为0，柔性下线，关闭A1实例并升级到2.0，将A1流量提升为10%观察2.0线上运行情况，如果情况稳定，则逐步开放流量至不限制及1/3。依次在A2，A3上执行上述操作。在上述步骤中，我们想让特别的人使用2.0，其他人还是使用1.0版，稳定后再全员开放。 思路分析，服务A的流量产生有两个方面，一个是外部流量，外网通过zuul过来的流量，一个是内部流量，服务间调用，服务B调用服务A的这类流量。不管是zuul还是内部服务来的，都是要通过ribbon做客户端负载均衡，我们可以修改ribbon负载均衡策略来实现上述限流、降级、灰度功能。 要实现这些想法，我们需要对spring-cloud的各个组件、数据流非常熟悉，这样才能知道该在哪里做扩展。一个典型的调用：外网-》Zuul网关-》服务A-》服务B。。。 spring-cloud跟dubbo一样都是客户端负载均衡，所有调用均由Ribbon来做负载均衡选择服务器，所有调用前后会套一层hystrix做隔离、熔断。服务间调用均用带LoadBalanced注解的RestTemplate发出。RestTemplate-》Ribbon-》hystrix 通过上述分析我们可以看到，我们的扩展点就在Ribbon，Ribbon根据我们的规则，选择正确的服务器即可。 我们先来一个dubbo自带的功能：基于权重的流量控制。dubbo自带的控制台可以设置服务实例粒度的半权，倍权。其实就是在客户端负载均衡时，选择服务器带上权重即可，spring-cloud默认是ZoneAvoidanceRule，优先选择相同Zone下的实例，实例间采用轮询方式做负载均衡。我们的想把基于轮询改为基于权重即可。接下来的问题是，每个实例的权重信息保存在哪里？从哪里取？dubbo放在zookeeper中，spring-cloud放在eureka中。我们只需从eureka拿每个实例的权重信息，然后根据权重来选择服务器即可。具体代码LabelAndWeightMetadataRule（先忽略里面的优先匹配label相关代码）。 工程案例演示 https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-ribbon-demoted 项目结构 config 配置中心端口：8888，方便起见直接读取配置文件，生产环境可以读取git。application-dev.properties为全局配置。先启动配置中心，所有服务的配置（包括注册中心的地址）均从配置中心读取。 consumer 服务消费者端口：18090，调用服务提供者，为了演示header传递。 core 框架核心包核心jar包，所有微服务均引用该包，使用AutoConfig实现免配置，模拟生产环境下spring-cloud的使用。 eureka 注册中心端口：8761，/metadata端点实现metadata信息配置。 provider 服务提供者端口：18090，服务提供者，无特殊逻辑。 zuul 网关端口：8080，演示解析token获得label并放入header往后传递 案例具体实现基于权重的实现思路LabelAndWeightMetadataRule写好了，那么我们如何使用它，使之生效呢？有3种方式。 1）写个AutoConfig将LabelAndWeightMetadataRule声明成@Bean，用来替换默认的ZoneAvoidanceRule。这种方式在技术验证、开发测试阶段使用短平快。但是这种方式是强制全局设置，无法个性化。 2）由于spring-cloud的Ribbon并没有实现netflix Ribbon的所有配置项。netflix配置全局rule方式为：ribbon.NFLoadBalancerRuleClassName=package.YourRule，spring-cloud并不支持，spring-cloud直接到服务粒度，只支持SERVICE_ID.ribbon.NFLoadBalancerRuleClassName=package.YourRule。 我们可以扩展org.springframework.cloud.netflix.ribbon.PropertiesFactory修正spring cloud ribbon未能完全支持netflix ribbon配置的问题。这样我们可以将全局配置写到配置中心的application-dev.properties全局配置中，然后各个微服务还可以根据自身情况做个性化定制。但是PropertiesFactory属性均为私有，应该是spring cloud不建议在此扩展。参见https://github.com/spring-cloud/spring-cloud-netflix/issues/1741。 3）使用spring cloud官方建议的@RibbonClient方式。该方式仅存在于spring-cloud单元测试中（在我提问后，现在还存在于spring-cloud issue list）。具体代码参见DefaultRibbonConfiguration.java、CoreAutoConfiguration.java。 目前采用第三种方式处理 基于权重的路由测试依次开启 config eureka provide（开两个实例，通过启动参数server.port指定不同端口区分） consumer zuul访问 http://localhost:8761/metadata.html 这是我手写的一个简单的metadata管理界面，分别设置两个provider实例的weight值（设置完需要一段2分钟才能生效），然后访问 http://localhost:8080/provider/user 多刷几次来测试zuul是否按权重发送请求，也可以访问 http://localhost:8080/consumer/test 多刷几次来测试consumer是否按权重来调用provide服务。 基于标签的路由处理基于权重的搞定之后，接下来才是重头戏：基于标签的路由。入口请求含有各种标签，然后我们可以根据标签幻化出各种各样的路由规则。例如只有标注为粉丝的用户才使用新版本（灰度、AB、金丝雀），例如标注为中国的用户请求必须发送到中国的服务器（全球部署），例如标注为写的请求必须发送到专门的写服务实例（读写分离），等等等等，唯一限制你的就是你的想象力。 基于标签的路由实现思路根据标签的控制，我们当然放到之前写的Ribbon的rule中，每个实例配置的不同规则也是跟之前一样放到注册中心的metadata中。需要解决以下几个问题: Q:关键是标签数据如何传过来? A:权重随机的实现思路里面有答案，请求都通过zuul进来，因此我们可以在zuul里面给请求打标签，基于用户，IP或其他看你的需求，然后将标签信息放入ThreadLocal中，然后在Ribbon Rule中从ThreadLocal拿出来使用就可以了。 然而，按照这个方式去实验时，发现有问题，拿不到ThreadLocal。原因是有hystrix这个东西，回忆下hystrix的原理，为了做到故障隔离，hystrix启用了自己的线程，不在同一个线程ThreadLocal失效。 那么还有什么办法能够将标签信息一传到底呢，想想之前有没有人实现过类似的东西，没错sleuth，它的链路跟踪就能够将span传递下去，翻翻sleuth源码，找找其他资料，发现可以使用HystrixRequestVariableDefault，这里不建议直接使用HystrixConcurrencyStrategy，会和sleuth的strategy冲突。代码参见CoreHeaderInterceptor.java。现在可以测试zuul里面的rule，看能否拿到标签内容了。 标签传到HystrixRequestVariableDefault这里的，如果项目中没有使用Hystrix就用不了了,这个时候需要做一个判断在restTemple里面做个判断，没有hystrix就直接threadlocal取。 Q:这里还不是终点，解决了zuul的路由，服务A调服务B这里的路由怎么处理呢？zuul算出来的标签如何往后面依次传递下去呢? 我们还是抄sleuth：把标签放入header，服务A调服务B时，将服务A header里面的标签放到服务B的header里，依次传递下去。这里的关键点就是：内部的微服务在接收到发来的请求时(zuul-&gt;A，A-&gt;B）我们将请求放入ThreadLocal，哦，不对，是HystrixRequestVariableDefault，还记得上面说的原因么：）。 这个容易处理，写一个spring mvc拦截器即可，代码参见CoreHeaderInterceptor。然后发送请求时自动带上这个里面保存的标签信息，参见RestTemplate的拦截器CoreHttpRequestInterceptor。到此为止，技术上全部走通实现。 总结一下：zuul依据用户或IP等计算标签，并将标签放入header里向后传递，后续的微服务通过拦截器，将header里的标签放入RestTemplate请求的header里继续向后接力传递。标签的内容通过放入类似于ThreadLocal的全局变量（HystrixRequestVariableDefault），使Ribbon Rule可以使用。 基于标签路由的测试参见PreFilter源码，模拟了几个用户的标签，参见LabelAndWeightMetadataRule源码，模拟了OR AND两种标签处理策略。依次开启 config eureka provide（开两个实例，通过启动参数server.port指定不同端口区分） consumer zuul. 访问 http://localhost:8761/metadata.html 设置第一个provide 实例 orLabel为 CN,Test 发送请求头带入Authorization: emt 访问http://localhost:8080/provider/user 多刷几次，可以看到zuul所有请求均路由给了第一个实例。访问http://localhost:8080/consumer/test 多刷几次，可以看到，consumer调用均路由给了第一个实例。 设置第二个provide 实例 andLabel为 EN,Male 发送请求头带入Authorization: em 访问http://localhost:8080/provider/user 多刷几次，可以看到zuul所有请求均路由给了第二个实例。访问http://localhost:8080/consumer/test 多刷几次，可以看到，consumer调用均路由给了第二个实例。 Authorization头还可以设置为PreFilter里面的模拟token来做测试，至此所有内容讲解完毕，技术路线拉通，剩下的就是根据需求来完善你自己的路由策略啦。 伪代码分析实现流程伪代码示例Ribbon默认采用ZoneAvoidanceRule，优先选择同zone下的实例。我们继承这个rule并扩展我们自己的限流功能，仔细阅读ZoneAvoidanceRule及其父类源码。 1234567891011121314151617181920212223242526272829303132333435363738394041424344public class WeightedMetadataRule extends ZoneAvoidanceRule &#123;public static final String META_DATA_KEY_WEIGHT = \"weight\";@Overridepublic Server choose(Object key) &#123; List&lt;Server&gt; serverList = this.getPredicate().getEligibleServers(this.getLoadBalancer().getAllServers(), key); if (CollectionUtils.isEmpty(serverList)) &#123; return null; &#125; // 计算总值并剔除0权重节点 int sum = 0; Map&lt;Server, Integer&gt; serverWeightMap = new HashMap&lt;&gt;(); for (Server server : serverList) &#123; String strWeight = ((DiscoveryEnabledServer) server).getInstanceInfo().getMetadata().get(META_DATA_KEY_WEIGHT); int weight = 100; try &#123; weight = Integer.parseInt(strWeight); &#125; catch (Exception e) &#123; // 无需处理 &#125; if (weight &lt;= 0) &#123; continue; &#125; serverWeightMap.put(server, weight); sum += weight; &#125; // 权重随机 int random = (int) (Math.random() * sum); int current = 0; for (Map.Entry&lt;Server, Integer&gt; entry : serverWeightMap.entrySet()) &#123; current += entry.getValue(); if (random &lt; current) &#123; return entry.getKey(); &#125; &#125; return null;&#125;&#125; 使上述代码生效，在zuul网关中加入 1234@Beanpublic IRule weightedMetadataRule()&#123; return new WeightedMetadataRule();&#125; 代码示例测试打断点测试是否进入WeightedMetadataRule，开启多个服务A实例，通过zuul访问服务A。成功进入断点，代码生效后，我们再来看如何指定metadata。访问eureka restful API （我的eureka服务器端口为8100，修改为你自己的eureka端口）Get http://localhost:8100/eureka/apps这个api可以看到所有服务Get http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME这个api可以看到你的服务信息，包括部署了哪些实例Get http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME/INSTANCE_ID这个api可以看到服务实例的信息，注意其中的metadata节点，目前为emptyPut http://localhost:8100/eureka/apps/YOUR_SERVICE_NAME/INSTANCE_ID/metadata?weight=10通过put方式可以修改metadata的内容，放入weight，设为10 然后稍等两分钟，让zuul更新注册中心中的信息，接着重新访问，调试就可以看到metadata的内容了，并且也是按照权重随机来进行流量限制的，至此hello world搞定。 生产上使用WeightedMetadataRule接下来，在生产环境中，我们如何应用这个WeightedMetadataRule呢，有如下几种方式： 手动指定服务策略，spring cloud ribbon并没有完整实现netflix ribbon的所有配置功能，负载策略默认只能配置微服务级别，无法配置全局默认值。例如：只能配置 SOME_SERVICE_ID.ribbon.NFLoadBalancerRuleClassName=package.WeightedMetadataRule而不支持配置全局默认值 ribbon.NFLoadBalancerRuleClassName=package.WeightedMetadataRule这种方案明显不符合我们的要求。 通过声明Irule spring bean配置全局负载策略1234@Beanpublic IRule weightedMetadataRule()&#123; return new WeightedMetadataRule();&#125; 这种方式也就是我们上面用的hello world方式，配置后强制所有微服务使用该策略，没有例外，微服务无法个性化定制策略，符合目前需求，但不适于长期规划。 继承重写PropertiesFactory继承重写org.springframework.cloud.netflix.ribbon.PropertiesFactory类，修正spring cloud ribbon未能完全支持netflix ribbon的问题。但是PropertiesFactory属性均为私有，应该是spring cloud不建议在此扩展。参见https://github.com/spring-cloud/spring-cloud-netflix/issues/1741 使用spring cloud官方建议的@RibbonClient方式1234567891011121314151617181920212223242526272829@Configuration@RibbonClients(defaultConfiguration = DefaultRibbonConfiguration.class)public class DefaultRibbonConfiguration &#123; @Value(\"$&#123;ribbon.client.name:#&#123;null&#125;&#125;\") private String name; @Autowired(required = false) private IClientConfig config; @Autowired private PropertiesFactory propertiesFactory; @Bean public IRule ribbonRule() &#123; if (StringUtils.isEmpty(name)) &#123; return null; &#125; if (this.propertiesFactory.isSet(IRule.class, name)) &#123; return this.propertiesFactory.get(IRule.class, config, name); &#125; // 默认配置 WeightedMetadataRule rule = new WeightedMetadataRule(); rule.initWithNiwsConfig(config); return rule; &#125;&#125; 总结关于权重随机的性能，上述代码用的数组分段查找法，还可以采用TreeMap二分查找法。可以将权重数组或权重TreeMap缓存起来。根据测试，在实例数量为50个时 缓存权重数组和权重TreeMap，数组分段查找百万次耗时78-125ms，TreeMap二分耗时50-80ms。 这篇文章只是把技术打通，至于如何根据服务器负载情况，自动降级，限流等需求，只需要监控服务器状况，调用eureka接口设置metadata即可（其实我个人建议这方面需求通过docker的自动扩容缩容完成，只是有朋友问到如何通过spring cloud实现）。 下一篇会写基于标签的流量控制。如何控制部分用户使用服务A2.0，其他用户使用服务A1.0。 参考文章江南白衣-服务化之－路由SpringCloud Ribbon 降级、限流、灰度发布","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Ribbon","slug":"Spring-Cloud-Ribbon","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Ribbon/"}]},{"title":"快速使用Spring Cloud Feign作为客户端调用服务提供者","slug":"sc/sc-fegin01","date":"2017-05-13T06:00:00.000Z","updated":"2017-06-17T03:00:05.000Z","comments":true,"path":"sc/sc-fegin01/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-fegin01/","excerpt":"Feign简介Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 可以做到使用HTTP请求远程服务时能就像调用本地方法一样的体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。Feign的Github网址,比如：Feign具有如下特性： 可插拔的注解支持，包括Feign注解和JAX-RS注解 支持可插拔的HTTP编码器和解码器 支持Hystrix和它的Fallback 支持Ribbon的负载均衡 支持HTTP请求和响应的压缩","text":"Feign简介Feign是一种声明式、模板化的HTTP客户端。在Spring Cloud中使用Feign, 可以做到使用HTTP请求远程服务时能就像调用本地方法一样的体验，开发者完全感知不到这是远程方法，更感知不到这是个HTTP请求。Feign的Github网址,比如：Feign具有如下特性： 可插拔的注解支持，包括Feign注解和JAX-RS注解 支持可插拔的HTTP编码器和解码器 支持Hystrix和它的Fallback 支持Ribbon的负载均衡 支持HTTP请求和响应的压缩 Feign是一个声明式的Web Service客户端，它的目的就是让Web Service调用更加简单。它整合了Ribbon和Hystrix，从而不再需要显式地使用这两个组件。Feign还提供了HTTP请求的模板，通过编写简单的接口和注解，就可以定义好HTTP请求的参数、格式、地址等信息。接下来，Feign会完全代理HTTP的请求，我们只需要像调用方法一样调用它就可以完成服务请求。Feign 示例工程 链接：https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-feign-first 本文最终修改时间：2017-05-20 18:47:23，为了解决问题1和2最终使用版本:Spring Boot的版本为1.5.3.RELEASE，Spring Cloud版本为Dalston.RELEASE 服务消费者中sc-feign-first-consumer的Feign的定义为了让Feign知道在调用方法时应该向哪个地址发请求以及请求需要带哪些参数，我们需要定义一个接口： 123456789101112131415package org.xujin.sc.feign.user.service;import org.springframework.cloud.netflix.feign.FeignClient;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.xujin.sc.feign.user.model.OrderModel;@FeignClient(name = \"sc-feign-first-provider\")//【A】public interface UserFeignService &#123;@RequestMapping(value = \"/sc/order/&#123;id&#125;\", method = RequestMethod.GET)//【B】public OrderModel findOrderById(@PathVariable(\"id\") Long id); //【C】&#125; A: @FeignClient用于通知Feign组件对该接口进行代理(不需要编写接口实现)，使用者可直接通过@Autowired注入，如下代码所示。 123 // 注入服务提供者,远程的Http服务@Autowiredprivate UserFeignService userFeignService; B: @RequestMapping表示在调用该方法时需要向/sc/order/{id}发送GET请求。 C: @PathVariable与SpringMVC中对应注解含义相同 服务消费者中Feign的使用123456789101112131415161718192021222324252627282930package org.xujin.sc.feign.user.controller;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RestController;import org.xujin.sc.feign.user.model.OrderModel;import org.xujin.sc.feign.user.service.UserFeignService;/** * UserController * @author xujin */@RestControllerpublic class UserController &#123; private static final Logger logger = LoggerFactory.getLogger(UserController.class); // 注入服务提供者,远程的Http服务 @Autowired private UserFeignService userFeignService; // 服务消费者对位提供的服务 @GetMapping(\"/sc/user/&#123;id&#125;\") public OrderModel findByIdByEurekaServer(@PathVariable Long id) &#123; return userFeignService.findOrderById(id); &#125;&#125; 如上代码所示，通过@Autowired将声明的Feign依赖注入即可，调用userFeignService.findOrderById(id)使用。开发者通过userFeignService.findOrderById()就能完成发送HTTP请求和解码HTTP返回结果并封装成对象的过程。 启动测试依次按顺序启动如下工程注册中心: sc-fegin-first-server服务提供者1:sc-fegin-first-provider01服务提供者2:sc-fegin-first-provider02以上工程能正常启动work，但是当启动服务消费者: sc-fegin-first-consumer报错如下。 使用的示例工程的Spring Boot的版本为1.5.2.RELEASE，Spring Cloud版本为Dalston.RELEASE会出现以下错误。 12345678910111213141516171819&lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; 访问http://localhost:8010/sc/user/1 ,出现以下错误即：【问题一】feign/Feign$BuilderCaused by: java.lang.NoClassDefFoundError: feign/Feign$Builder12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273java.lang.IllegalStateException: ApplicationEventMulticaster not initialized - call &apos;refresh&apos; before multicasting events via the context: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@2d140a7: startup date [Sun May 14 22:44:43 CST 2017]; parent: org.springframework.context.annotation.AnnotationConfigApplicationContext@4bf48f6 at org.springframework.context.support.AbstractApplicationContext.getApplicationEventMulticaster(AbstractApplicationContext.java:404) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.ApplicationListenerDetector.postProcessBeforeDestruction(ApplicationListenerDetector.java:97) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DisposableBeanAdapter.destroy(DisposableBeanAdapter.java:253) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroyBean(DefaultSingletonBeanRegistry.java:578) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingleton(DefaultSingletonBeanRegistry.java:554) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingleton(DefaultListableBeanFactory.java:961) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.destroySingletons(DefaultSingletonBeanRegistry.java:523) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.destroySingletons(DefaultListableBeanFactory.java:968) [spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.destroyBeans(AbstractApplicationContext.java:1033) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:555) [spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.xujin.sc.feign.user.UserConsumerApplication.main(UserConsumerApplication.java:15) [classes/:na]2017-05-14 22:44:44.079 ERROR 2372 --- [ main] o.s.boot.SpringApplication : Application startup failedorg.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name &apos;methodValidationPostProcessor&apos; defined in class path resource [org/springframework/boot/autoconfigure/validation/ValidationAutoConfiguration.class]: Unsatisfied dependency expressed through method &apos;methodValidationPostProcessor&apos; parameter 0; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;org.xujin.sc.feign.user.service.UserFeignService&apos;: Failed to introspect bean class [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] for lookup method metadata: could not find class that it depends on; nested exception is java.lang.NoClassDefFoundError: feign/Feign$Builder at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:749) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.instantiateUsingFactoryMethod(ConstructorResolver.java:467) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateUsingFactoryMethod(AbstractAutowireCapableBeanFactory.java:1173) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1067) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:513) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:483) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:306) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:302) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:202) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.PostProcessorRegistrationDelegate.registerBeanPostProcessors(PostProcessorRegistrationDelegate.java:223) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.registerBeanPostProcessors(AbstractApplicationContext.java:702) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:527) ~[spring-context-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.boot.context.embedded.EmbeddedWebApplicationContext.refresh(EmbeddedWebApplicationContext.java:122) ~[spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refresh(SpringApplication.java:737) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:370) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:314) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1162) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.springframework.boot.SpringApplication.run(SpringApplication.java:1151) [spring-boot-1.5.2.RELEASE.jar:1.5.2.RELEASE] at org.xujin.sc.feign.user.UserConsumerApplication.main(UserConsumerApplication.java:15) [classes/:na]Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;org.xujin.sc.feign.user.service.UserFeignService&apos;: Failed to introspect bean class [org.springframework.cloud.netflix.feign.FeignClientFactoryBean] for lookup method metadata: could not find class that it depends on; nested exception is java.lang.NoClassDefFoundError: feign/Feign$Builder at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:269) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.determineConstructorsFromBeanPostProcessors(AbstractAutowireCapableBeanFactory.java:1118) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1091) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getSingletonFactoryBeanForTypeCheck(AbstractAutowireCapableBeanFactory.java:923) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:804) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:558) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:432) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:395) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.BeanFactoryUtils.beanNamesForTypeIncludingAncestors(BeanFactoryUtils.java:220) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.findAutowireCandidates(DefaultListableBeanFactory.java:1260) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1101) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1066) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.resolveAutowiredArgument(ConstructorResolver.java:835) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.support.ConstructorResolver.createArgumentArray(ConstructorResolver.java:741) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] ... 19 common frames omittedCaused by: java.lang.NoClassDefFoundError: feign/Feign$Builder at java.lang.Class.getDeclaredMethods0(Native Method) ~[na:1.8.0_112] at java.lang.Class.privateGetDeclaredMethods(Class.java:2701) ~[na:1.8.0_112] at java.lang.Class.getDeclaredMethods(Class.java:1975) ~[na:1.8.0_112] at org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:613) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:524) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.util.ReflectionUtils.doWithMethods(ReflectionUtils.java:510) ~[spring-core-4.3.7.RELEASE.jar:4.3.7.RELEASE] at org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor.determineCandidateConstructors(AutowiredAnnotationBeanPostProcessor.java:247) ~[spring-beans-4.3.7.RELEASE.jar:4.3.7.RELEASE] ... 32 common frames omittedCaused by: java.lang.ClassNotFoundException: feign.Feign$Builder at java.net.URLClassLoader.findClass(URLClassLoader.java:381) ~[na:1.8.0_112] at java.lang.ClassLoader.loadClass(ClassLoader.java:424) ~[na:1.8.0_112] at sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:331) ~[na:1.8.0_112] at java.lang.ClassLoader.loadClass(ClassLoader.java:357) ~[na:1.8.0_112] ... 39 common frames omitted 经查找解决问题2天查看无果(捂脸，后面写源码分析定位)，因此决定将Spring Boot的版本改变为1.4.3.RELEASE，Spring Cloud版本为Camden.SR5之后,按上面的顺序启动，之后测试http://localhost:8010/sc/user/1 ,可以正常work。 Fegin的work原理Spring Cloud应用在启动时，Feign会扫描标有@FeignClient注解的接口，生成代理，并注册到Spring容器中。生成代理时Feign会为每个接口方法创建一个RequetTemplate对象，该对象封装了HTTP请求需要的全部信息，请求参数名、请求方法等信息都是在这个过程中确定的，Feign的模板化就体现在这里。在本例中，我们将Feign与Eureka和Ribbon组合使用，@FeignClient(name = “sc-feign-first-provider”)意为通知Feign在调用该接口方法时要向Eureka中查询名为ea的服务，从而得到服务URL。 Fegin的常见应用Feign的Encoder、Decoder和ErrorDecoderFeign将方法签名中方法参数对象序列化为请求参数放到HTTP请求中的过程，是由编码器(Encoder)完成的。同理，将HTTP响应数据反序列化为java对象是由解码器(Decoder)完成的。 默认情况下，Feign会将标有@RequestParam注解的参数转换成字符串添加到URL中，将没有注解的参数通过Jackson转换成json放到请求体中。 注意，如果在@RequetMapping中的method将请求方式指定为GET，那么所有未标注解的参数将会被忽略，例如： 12@RequestMapping(value = \"/group/&#123;groupId&#125;\", method = RequestMethod.GET)void update(@PathVariable(\"groupId\") Integer groupId, @RequestParam(\"groupName\") String groupName, DataObject obj); 此时因为声明的是GET请求没有请求体，所以obj参数就会被忽略。 在Spring Cloud环境下，Feign的Encoder只会用来编码没有添加注解的参数。如果你自定义了Encoder, 那么只有在编码obj参数时才会调用你的Encoder。 对于Decoder, 默认会委托给SpringMVC中的MappingJackson2HttpMessageConverter类进行解码。只有当状态码不在200 ~ 300之间时ErrorDecoder才会被调用。 ErrorDecoder的作用是可以根据HTTP响应信息返回一个异常，该异常可以在调用Feign接口的地方被捕获到。我们目前就通过ErrorDecoder来使Feign接口抛出业务异常以供调用者处理。 更换Feign默认使用的HTTP ClientFeign在默认情况下使用的是JDK原生的URLConnection发送HTTP请求，没有连接池，但是对每个地址会保持一个长连接，即利用HTTP的persistence connection 。我们可以用Apache的HTTP Client替换Feign原始的http client, 从而获取连接池、超时时间等与性能息息相关的控制能力。Spring Cloud从Brixtion.SR5版本开始支持这种替换，首先在项目中声明Apache HTTP Client和feign-httpclient依赖： 12345678910&lt;!-- 使用Apache HttpClient替换Feign原生httpclient --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.netflix.feign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt; &lt;version&gt;8.17.0&lt;/version&gt; &lt;/dependency&gt; 然后在application.yml中添加如下：123feign: httpclient: enabled: true spring cloud feign使用okhttp3参考 spring cloud feign常见问题参数不会自动传递服务消费者端调用1234@RequestMapping(value = \"/test\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age) &#123; return userFeignService.hello(name, age); &#125; 服务提供者Controller对外服务1234@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age) &#123; return name + age; &#125; Fegin客户端定义调用12@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(String name, @RequestParam(\"age\") int age); 启动的时候sc-fegin-first-consumer工程不报错。但是当访问http://localhost:8010/test?name=xujin&amp;age=25 ,报错如下123feign.FeignException: status 405 reading UserFeignService#hello(String,int); content:&#123;&quot;timestamp&quot;:1494856464666,&quot;status&quot;:405,&quot;error&quot;:&quot;Method Not Allowed&quot;,&quot;exception&quot;:&quot;org.springframework.web.HttpRequestMethodNotSupportedException&quot;,&quot;message&quot;:&quot;Request method &apos;POST&apos; not supported&quot;,&quot;path&quot;:&quot;/hello&quot;&#125; at feign.FeignException.errorStatus(FeignException.java:62) ~[feign-core-9.3.1.jar:na] Fegin客户端定义修改如下OK，原因是name被自动放到request body。只要有body，就会被feign认为是post请求，所以整个hello是被当作带有request parameter和body的post请求发送出去了，因此出现上面的错误提示。 12@RequestMapping(value = \"/hello\", method = RequestMethod.GET) public String hello(@RequestParam(\"name\") String name, @RequestParam(\"age\") int age); POST多参数调用 POST多参数 Feign端定义： 12@RequestMapping(value = \"/test/post\", method = RequestMethod.POST)public OrderModel post(OrderModel orderModel); 12@RequestMapping(value = \"/test/post\", method = RequestMethod.POST)public OrderModel post(@RequestBody OrderModel orderModel); 以上两种定义方式等价 服务提供者的定义 12345@PostMapping(\"/test/post\")public OrderModel testPost(@RequestBody OrderModel orderModel) &#123; orderModel.setOrderNo(2222222L); return orderModel;&#125; 修改订单号返回证明，服务提供者接到从Feign POST请求过来的数据。 服务消费者端的使用 1234@PostMapping(\"/test/post\")public OrderModel testPost(@RequestBody OrderModel orderModel) &#123; return userFeignService.post(orderModel);&#125; 测试当修改了Feign默认的http Client之后，出现如下错误，具体出错原因还在排查之中，本文会随时更改。【问题二】更换了Feign默认的Client出现HystrixRuntimeException12345678&#123; \"timestamp\": 1494947172990, \"status\": 500, \"error\": \"Internal Server Error\", \"exception\": \"com.netflix.hystrix.exception.HystrixRuntimeException\", \"message\": \"UserFeignService#post(OrderModel) failed and no fallback available.\", \"path\": \"/test/post\"&#125; 1234567java.lang.IllegalArgumentException: MIME type may not contain reserved characters at org.apache.http.util.Args.check(Args.java:36) ~[httpcore-4.4.5.jar:4.4.5] at org.apache.http.entity.ContentType.create(ContentType.java:182) ~[httpcore-4.4.5.jar:4.4.5] at feign.httpclient.ApacheHttpClient.getContentType(ApacheHttpClient.java:159) ~[feign-httpclient-8.17.0.jar:8.17.0] at feign.httpclient.ApacheHttpClient.toHttpUriRequest(ApacheHttpClient.java:140) ~[feign-httpclient-8.17.0.jar:8.17.0] at feign.httpclient.ApacheHttpClient.execute(ApacheHttpClient.java:83) ~[feign-httpclient-8.17.0.jar:8.17.0] 当关闭之后，访问正常如下所示，醉了同样的代码(PS:捂脸) 123feign: httpclient: enabled: false 1&#123;\"createTime\":1494944311023,\"orderNo\":33333,\"payTime\":1494944311023&#125; GET多参数调用当服务之间GET调用为多参数时，可以使用Map来构建参数传递Feign接口中的示例定义12@RequestMapping(value = \"/test/get\", method = RequestMethod.GET)public String testGet(@RequestParam Map&lt;String, Object&gt; map); 服务消费者的调用 12345678@GetMapping(\"/test/get\")public String testGet() &#123; HashMap&lt;String, Object&gt; map = Maps.newHashMap(); map.put(\"orderNo\", \"1\"); map.put(\"createTime\", new Date()); map.put(\"payTime\", new Date()); return userFeignService.testGet(map);&#125; 个人看来，如果是GET的多参数通过Map进行传递，当参数比较多时，个人建议使用面向对象的思维，通过POST的方式传递对象相对较好。 服务提供者的使用 1234@RequestMapping(value = \"/test/get\", method = RequestMethod.GET)public String testGet(@RequestParam Map&lt;String, Object&gt; map) &#123; return String.valueOf(map);&#125; 访问URL:http://localhost:8010/test/get ,测试OK. 1&#123;orderNo=1, createTime=Sat May 20 19:47:38 CST 2017, payTime=Sat May 20 19:47:38 CST 2017&#125; 总结 本文主要介绍了Feign的基本的定义，以及Feign的work原理和使用Feign的注意事项和常见问题。最后介绍了一下更换Feign默认使用的HTTP Client。主要是遇到一个奇葩的问题，最终没解决更换版本。在下一篇文章中将介绍Feign的其它的使用，例如Feign的继承，日志级别，以及Feign源码分析等 参考文献希望Feign能够支持参数请求使用POJO的Issue建议使用Feign原生的注解的Issue建议增强Feign的功能建议支持可选的Request Body（目前Feign当POST一个null时，会报异常）","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Fegin","slug":"Spring-Cloud-Fegin","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Fegin/"}]},{"title":"API GateWay(网关)那些儿事","slug":"sc/sc-zuul","date":"2017-05-10T06:00:00.000Z","updated":"2017-06-17T05:07:30.000Z","comments":true,"path":"sc/sc-zuul/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-zuul/","excerpt":"为什么需要API Gateway 简化客户端调用复杂度 在微服务架构模式下后端服务的实例数一般是动态的，对于客户端而言如何发现这些动态改变的服务实例的访问地址信息？因此在基于微服务的项目中为了简化前端的调用逻辑，通常会引入API Gateway作为轻量级网关，同时API Gateway中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。","text":"为什么需要API Gateway 简化客户端调用复杂度 在微服务架构模式下后端服务的实例数一般是动态的，对于客户端而言如何发现这些动态改变的服务实例的访问地址信息？因此在基于微服务的项目中为了简化前端的调用逻辑，通常会引入API Gateway作为轻量级网关，同时API Gateway中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。 数据裁剪以及聚合 通常而言多余不同的客户端对于显示时对于数据的需求是不一致的，比如手机端或者Web端又或者在低延迟的网络环境或者高延迟的网络环境。 因此为了优化客户端的使用体验，API Gateway可以对通用性的响应数据进行裁剪以适应不同客户端的使用需求。同时还可以将多个API调用逻辑进行聚合，从而减少客户端的请求数，优化客户端用户体验 多渠道支持 当然我们还可以针对不同的渠道和客户端提供不同的API Gateway,对于该模式的使用由另外一个大家熟知的方式叫Backend for front-end, 在Backend for front-end模式当中，我们可以针对不同的客户端分别创建其BFF 遗留系统的微服务化改造 对于系统系统而言进行微服务改造通常是由于原有的系统存在或多或少的问题，比如技术债务，代码质量，可维护性，可扩展性等等。API Gateway的模式同样适用于这一类遗留系统的改造，通过微服务化的改造逐步实现对原有系统中的问题的修复，从而提升对于原有业务响应力的提升。通过引入抽象层，逐步使用新的实现替换旧的实现。 使用Zuul实现API网关Spring Cloud的Zuul组件提供了轻量级网关的功能支持，通过定义路由规则可以快速实现一个轻量级的API网关 123456789101112131415zuul: ignoredPatterns: /api/auth sensitive-headers: &quot;*&quot; ignoreLocalService: true retryable: false host: max-total-connections: 500 routes: service01: path: /service01/** serviceId: service01 stripPrefix: true thirdpart: pateh: /thirdpart/** url: http://thirdpart.api.com 同时除了通过serviceId关联已经注册到Consul的服务实例以外，我们也可以通过zuul直接定义实现对已有服务的直接集成。 这里我们就不过多介绍Zuul的细节，在实际使用中我们会发现直接使用Zuul会存在诸多问题，包括： 性能问题：当存在大量请求超时后会造成Zuul阻塞，目前只能通过横向扩展Zuul实例实现对高并发的支持； WebSocket的支持问题： Zuul中并不直接提供对WebSocket的支持，需要添加额外的过滤器实现对WebSocket的支持；为了解决以上问题，可以通过在Zuul前端部署Nginx实现对Zuul实例的反向代理，同时适当的通过添加Cache以及请求压缩减少对后端Zuul实例的压力。 实现Nginx的动态代理通过Nginx我们可以实现对多实例Zuul的请求代理，同时通过添加适当的缓存以及请求压缩配置可以提升前端UI的请求响应时间。这里需要解决的问题是Nginx如何动态发现Zuul实例信息并且将请求转发到Zuul当中。 consul-template可以帮助我们解决以上问题,consul-template是一个命令行工具，结合consul实现配置文件的动态生成并且支持在配置文件发生变化后触发用户自定义命令。 我们使用了如下的Dockerfile用于构建我们的Nginx服务 1234567891011121314151617181920FROM nginx:1.11.10ADD consul-template /usr/local/binRUN mkdir /etc/consul-templates# 模板文件ADD nginx.tpl /etc/consul-templates/nginx.tplENV CT_FILE /etc/consul-templates/nginx.tplENV NX_FILE /etc/nginx/conf.d/default.conf # 目标文件ENV SERVICE identity # 注册在Consul的服务名COPY dist /usr/share/nginx/htmlRUN mkdir -p /data/cacheCMD /usr/sbin/nginx -c /etc/nginx/nginx.conf \\ &amp; CONSUL_TEMPLATE_LOG=debug \\ consul-template -consul-addr=$CONSUL -template &quot;$CT_FILE:$NX_FILE:/usr/sbin/nginx -s reload&quot;; Nginx配置模板文件 123456789101112131415161718192021# nginx.tplupstream api_server &#123; least_conn; &#123;&#123;range service &quot;identity&quot;&#125;&#125; server &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;; &#123;&#123;else&#125;&#125;server 127.0.0.1:9191;&#123;&#123;end&#125;&#125;&#125;server &#123; listen 80; server_name localhost; location / &#123; root /usr/share/nginx/html; index index.html index.htm; &#125; location /api &#123; proxy_pass http://api_server; &#125;&#125; 其中 123456upstream api_server &#123; least_conn; &#123;&#123;range service &quot;identity&quot;&#125;&#125; server &#123;&#123;.Address&#125;&#125;:&#123;&#123;.Port&#125;&#125;; &#123;&#123;else&#125;&#125;server 127.0.0.1:9191;&#123;&#123;end&#125;&#125;&#125; 会根据当前consul中注册的所有identity服务实例进行模板渲染，并且当配置文件内容发生变化后调用nginx -s reload重新加载Nginx配置从而实现对于后端服务实例的动态代理。 123CMD /usr/sbin/nginx -c /etc/nginx/nginx.conf \\ &amp; CONSUL_TEMPLATE_LOG=debug \\ consul-template -consul-addr=$CONSUL -template &quot;$CT_FILE:$NX_FILE:/usr/sbin/nginx -s reload&quot;; 其它的一些优化建议启用Nginx的Gzip可以对服务器端响应内容进行压缩从而减少一定的客户端响应时间 12345gzip on;gzip_min_length 1k;gzip_buffers 4 32k;gzip_types text/plain application/x-javascript application/javascript text/xml text/css;gzip_vary on; 缓存图片以及其它静态资源可以减少对Zuul实例的请求量 12345678910111213proxy_buffering on;proxy_cache_valid any 10m;proxy_cache_path /data/cache levels=1:2 keys_zone=my-cache:8m max_size=1000m inactive=600m;proxy_temp_path /data/temp;proxy_buffer_size 4k;proxy_buffers 100 8k;location ~* (images) &#123; proxy_pass http://api_server; # cache setting proxy_cache my-cache; proxy_cache_valid 200;&#125; 如果需要通过Nginx实现对Websocket的代理可以添加一下配置 12345678910111213141516171819location /sockjs &#123; proxy_pass http://api_server; proxy_set_header X-Real-IP $remote_addr; proxy_set_header Host $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; # WebSocket support (nginx 1.4) proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; proxy_connect_timeout 90; proxy_send_timeout 90; proxy_read_timeout 90; # !!!Support Spring Boot proxy_pass_header X-XSRF-TOKEN; proxy_set_header Origin &quot;http://localhost:4000&quot;; &#125;","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Zuul","slug":"Spring-Cloud-Zuul","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Zuul/"}]},{"title":"Spring  Cloud Zuul的URL转发和路由规则","slug":"sc/sc-zuul-01","date":"2017-04-30T06:00:00.000Z","updated":"2017-06-17T03:15:15.000Z","comments":true,"path":"sc/sc-zuul-01/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-zuul-01/","excerpt":"摘要:最近开了《跟我学Spring Cloud》系列教程,由于最近比较忙，因此更新较慢。由于自己最近在研究基于Netty名为Janus的网关中间件分为janus-Server端和janus-console管控端，纳管Spring Cloud实现市面上网关85%以上的功能，将在2017年5月6号Spring Cloud中国社区北京技术沙龙分享。顺便抽时间把Spring Cloud Zuul相关的东西整理比较。在本篇文章中Spring Cloud的版本更换为Dalston.RELEASE，Spring Boot的版本为1.5.2.RELEASE。 Spring Cloud Zuul Spring Cloud Zuul 通过与 Spring Cloud Eureka 进行整合，将自身注册到 Eureka Server中，与Eureka,Ribbon,Hystrix等整合，同时从 Eureka 中获得了所有其它微服务的实例信息。这样的设计通过把网关和服务治理整合到一起，Spring Cloud Zuul可以获取到服务注册信息，结合Ribbon，Hystrix等更好的实现路由转发，负载均衡等功能。想了解更多的内容，可以参考下面的中英文对照翻译文档。或者查看官网文档。 Spring Cloud Zuul中英文对照翻译① Spring Cloud Zuul中英文对照翻译② Spring Cloud Zuul中英文对照翻译③","text":"摘要:最近开了《跟我学Spring Cloud》系列教程,由于最近比较忙，因此更新较慢。由于自己最近在研究基于Netty名为Janus的网关中间件分为janus-Server端和janus-console管控端，纳管Spring Cloud实现市面上网关85%以上的功能，将在2017年5月6号Spring Cloud中国社区北京技术沙龙分享。顺便抽时间把Spring Cloud Zuul相关的东西整理比较。在本篇文章中Spring Cloud的版本更换为Dalston.RELEASE，Spring Boot的版本为1.5.2.RELEASE。 Spring Cloud Zuul Spring Cloud Zuul 通过与 Spring Cloud Eureka 进行整合，将自身注册到 Eureka Server中，与Eureka,Ribbon,Hystrix等整合，同时从 Eureka 中获得了所有其它微服务的实例信息。这样的设计通过把网关和服务治理整合到一起，Spring Cloud Zuul可以获取到服务注册信息，结合Ribbon，Hystrix等更好的实现路由转发，负载均衡等功能。想了解更多的内容，可以参考下面的中英文对照翻译文档。或者查看官网文档。 Spring Cloud Zuul中英文对照翻译① Spring Cloud Zuul中英文对照翻译② Spring Cloud Zuul中英文对照翻译③ 快速搭建SC Zuul工程目录如下图所示: Code地址:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-zuul-first Spring Cloud Zuul原始的URL转发功能 由于sc-zuul-first-provider1的代码极其简单就是一个简单的服务提供者，因此不做过多介绍。下面主要介绍sc-zuul-first-zuul-no-eureka这个工程， URL路由转发功能 创建名为sc-zuul-first-zuul-no-eureka的maven工程,添加依赖，但注意的是该工程只有Zuul的依赖。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849 &lt;?xml version=\"1.0\"?&gt;&lt;project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.xujin.sc&lt;/groupId&gt; &lt;artifactId&gt;sc-zuul-first-zuul-no-eureka&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sc-zuul-first-zuul-no-eureka&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.2.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Dalston.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 说明: 对于 spring-cloud-starter-zuul 依赖，我们可以通过查看它的依赖内容了解 到：该模块中不仅包含了 Netflix Zuul 的核心依赖 zuul-core，它还包含了下面这 些网关服务需要的重要依赖。 spring-cloud-starter-hystrix：该依赖用来在网关服务中实现对微服务 转发时候的保护机制，通过线程隔离和断路器，防止微服务的故障引发 API 网关 资源无法释放，从而影响其他应用的对外服务。 spring-cloud-starter-ribbon：该依赖用来实现在网关服务进行路由转发 时候的客户端负载均衡以及请求重试。 spring-boot-starter-actuator ：该依赖用来提供常规的微服务管理端点。另外，在Spring Cloud Zuul中还特别提供了/routes 端点来返回当前的所有路由规则。 2.主入口程序代码如下，使用@EnableZuulProxy注解1234567891011121314package org.xujin.sc.zuul.first.zuul;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.zuul.EnableZuulServer;@SpringBootApplication@EnableZuulProxypublic class SpringCloudZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulApplication.class, args); &#125;&#125; 3.application.yml配置文件信息如下12345server.port=8041spring.application.name=sc-zuul-first-zuul-no-eurekazuul.routes.api-url.path=/api-url/**zuul.routes.api-url.url=http://localhost:8000/ 该配置定义了发往 API 网关服务的请求中，所有符合/api-url/**规则的访问都 将 被 路 由 转 发 到 http://localhost:8000/ 地 址 上 ， 也 就 是 说 当 我 们 访 问 http://localhost:8041/api-url/sc/order/1 可以正常的把请求的url转发到http://localhost:8000/sc/order/2 。其 中 ， 配 置 属 性 zuul.routes.api-url.path 中的 api-url 部分为路由的名字，可以任意定义， 但是一组 path 和 url 映射关系的路由名要相同。 zuul.routes.api-url.url=http://localhost:8000/ 这个配置了服务提供者sc-zuul-first-provider1的URL 4.测试依次按如下顺序,把各个服务启动。 注册中心为：sc-zuul-first-eureka-server 服务提供者为:sc-zuul-first-provider1，sc-zuul-first-provider2 启动sc-zuul-first-zuul-no-eureka 上述Server启动之后，测试Case: URL路由转发功能测试1.当注解为@EnableZuulProxy时，测试转发。通过访问网关的URL: http://localhost:8041/api-url/sc/order/1 可以正常的把请求的url转发到http://localhost:8000/sc/order/2 Tips:断点跳过之后,返回结果如下，说明当使用@EnableZuulProxy注解的时候，Zuul具有URL转发调用的功能。 2.关闭sc-zuul-first-zuul-no-eureka对应的服务，把主应用程序中的注解@EnableZuulProxy变为@EnableZuulServer,按第1步启动sc-zuul-first-zuul-no-eureka服务，测试。 Tips: 可以看到上图返回结果为200，但是空白。那为什么会这样呢？后面专门对Zuul的源码分析，请读者忽略或自行查看源码。 Spring Cloud Zuul功能 大家知道Spring Cloud的服务治理的粒度是服务应用名，而如下的配置规则硬编码配置主机名和端口，由于Spring Cloud Zuul整合了Ribbon负载均衡器等因此，下面的配置方式不推荐使用比较low。12345server.port=8041spring.application.name=sc-zuul-first-zuul-no-eurekazuul.routes.api-url.path=/api-url/**zuul.routes.api-url.url=http://localhost:8000/ Spring Cloud Zuul功能案例1.为了演示面向服务名为粒度的路由规则，新建了一个名为sc-zuul-first-zuul的工程，该工程与sc-zuul-first-zuul-no-eureka的最大的区别就是在pom.xml文件中，加入spring-cloud-starter-eureka依赖,如下注释所示。1234567891011&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zuul&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 多了eureka starter --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 2.application.yml1234567891011server: port: 8040spring: application: name: sc-zuul-first-zuuleureka: client: service-url: defaultZone: http://localhost:8761/eureka/ instance: prefer-ip-address: true 3.主应用程序代码SpringCloudZuulApplication.java12345678910111213141516171819package org.xujin.sc.zuul.first.zuul;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.zuul.EnableZuulProxy;/** * * @author xujin * @EnableZuulProxy 声明一个Zuul 代理，该代理使用Ribbon软负载均衡，还整合Hystrix实现熔断 */@SpringBootApplication@EnableZuulProxypublic class SpringCloudZuulApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudZuulApplication.class, args); &#125;&#125; 4.分别依次把sc-zuul-first-eureka-server，sc-zuul-first-zuul，sc-zuul-first-provider1，sc-zuul-first-provider2，sc-zuul-first-consumer，sc-zuul-first-hystrix-dashboard启动。 Spring Cloud Zuul功能演示1.网关的默认路由规则 说明默认情况下，Zuul会代理所有注册到Eureka Server的微服务，并且Zuul的路由规则如下： http://ZUUL_HOST:ZUUL_PORT/微服务在Eureka上的serviceId/** 会被转发到serviceId对应的微服务。 http://localhost:8040/sc-zuul-first-provider/sc/order/2 2.网关的负载均衡 http://localhost:8040/sc-zuul-first-provider/sc/order/2 通过网关访问服务提供者，负载均衡打出对应的日志 123 2017-04-30 18:35:37.502\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m3443\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[nio-8000-exec-3]\u001b[0;39m \u001b[36mo.x.s.e.f.o.controller.OrderController \u001b[0;39m \u001b[2m:\u001b[0;39m Zuul路由到服务提供者① 2017-04-30 18:34:06.764\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m3444\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[nio-8001-exec-4]\u001b[0;39m \u001b[36mo.x.s.e.f.o.controller.OrderController \u001b[0;39m \u001b[2m:\u001b[0;39m Zuul路由到服务提供者②\u001b[2m2017-04-30 18:35:37.251\u001b[0;39m \u001b[32m INFO\u001b[0;39m \u001b[35m3444\u001b[0;39m \u001b[2m---\u001b[0;39m \u001b[2m[trap-executor-0]\u001b[0;39m \u001b[36mc.n.d.s.r.aws.ConfigClusterResolver \u001b[0;39m \u001b[2m:\u001b[0;39m Resolving eureka endpoints via configuration 3.集成Hystrix http://localhost:8040/hystrix.stream Spring Cloud Zuul路由规则指定服务路由对外访问路径 123zuul: routes: sc-zuul-first-provider: /order/** 相当于把sc-zuul-first-provider映射为/order/**，访问http://localhost:8040/sc-zuul-first-provider/sc/order/2 可以等价于:http://localhost:8040/order/sc/order/2，其它路由规则，可以从官网文档中阅读尝试。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Zuul","slug":"Spring-Cloud-Zuul","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Zuul/"}]},{"title":"SC中Eureka Server的HA和安全身份验证","slug":"sc/sc-eureka-02","date":"2017-03-25T06:00:00.000Z","updated":"2017-06-17T03:15:59.000Z","comments":true,"path":"sc/sc-eureka-02/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-02/","excerpt":"","text":"什么是高可用高可用 High Availability，即高可用HA。在分布式情况下，我们经常说4个9(99.99%)或者5个9(99.999%)。举个简单例子，如果一个微服务分布式系统依赖于30个微服务，每个微服务可用性是99.99%，那么整个微服务系统的可用性就是99.99%的30次方 ≈ 99.7% ，也就是说有0.3%系统是不可用的，0.3%意味着如果Qps很高，有一亿次请求的话，那么就会有30万次失败。换算成时间大约每月有2个小时服务不稳定。特别是随着服务依赖数量的变多，微服务不稳定的概率会成指数性上升。因此要保证微服务应用的HA需要从各方面入手，下面会介绍一下如何实现Eureka Server的HA。参考工程如下所示。 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-ha Eureka Server的HAEureka Server的HA两个工程演示HA 如示例工程所示，我新建了两个Project分别为sc-eureka-ha-server1，sc-eureka-ha-server2， 我们知道在Eureka Server的Standalone模式下面，由于只有一个Eureka Server，所以我们通过配置如下信息关闭Eureka Server的自我注册和抓取注册信息，但是两个Eureka Server之间需要设置为True，相互注册相互感知对方注册信息的变化，从而实现信息同步。 1.sc-eureka-ha-server1的application.yml配置Info 如下： 123456789spring: application: name: sc-eureka-ha-server1server: port: 8761 # 指定该Eureka实例的端口eureka: client: serviceUrl: defaultZone: http://localhost:8762/eureka/ 2.sc-eureka-ha-server2的application.yml配置Info 如下 12345678910spring: application: name: sc-eureka-ha-server2 server: port: 8762 # 指定该Eureka实例的端口eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 3.主程序入口代码没什么区别如下: 1234567@EnableEurekaServer@SpringBootApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 4.分别启动sc-eureka-ha-server1和sc-eureka-ha-server2，访问http://localhost:8761/ ,http://localhost:8762/ ，如下: 5.服务提供者sc-eureka-ha-provider其它代码见工程,application.yml如下所示。 1234567891011 server: port: 8000 spring: application: name: sc-eureka-ha-provider eureka: client: service-url: defaultZone: http://localhost:8761/eureka/ tips: 把服务提供者的服务注册信息，注册到Eureka Server 01上。 启动服务提供者，见如下图所示。 片刻服务提供者的信息也同步到Eureka Server02上面 Jar方式演示HA Eureka Server的HA，其实可以通过jar的方式指定使用不同的profile配置的方式，在本地运行两个Eureka Server。只需将Eureka server的application.yml修改如下：12345678910111213141516171819202122232425spring: application: name: sc-eureka-ha-server --- spring: profiles: peer1 server: port: 8761 eureka: instance: hostname: peer1.xujin.org client: serviceUrl: defaultZone: http://peer2.xujin.org:8762/eureka/ --- spring: profiles: peer2 server: port: 8762 eureka: instance: hostname: peer2.xujin.org client: serviceUrl: defaultZone: http://peer1.xujin.org:8761/eureka/ 通过配置switcHosts或者自行配置HostName对应的IP地址,把工程打成jar之后，运行如下命令123 java -jar sc-eureka-ha-server1-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer2java -jar sc-eureka-ha-server1-0.0.1-SNAPSHOT.jar --spring.profiles.active=peer1 测试如下: 安全身份验证 如果客户端的eureka.client.serviceUrl.defaultZone参数值(即Eureka Server的地址)中包含HTTP Basic Authentication信息，如http://user:password@localhost:8761/eureka，那么客户端就会自动使用该用户名、密码信息与Eureka服务端进行验证。如果你需要更复杂的验证逻辑，你必须注册一个DiscoveryClientOptionalArgs组件，并将ClientFilter组件注入，在这里定义的逻辑会在每次客户端向服务端发起请求时执行。 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-security 访问Eureka Server安全身份验证 如工程sc-eureka-securit中的sc-eureka-security-server工程所示，在pom.xml中增加依赖如下: 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; application.yml如下 123456789101112131415161718 server: port: 8761 # 指定该Eureka实例的端口eureka: client: #表示是否将自己注册到Eureka Server上，默认为true，当前应用为Eureka Server所以无需注册 registerWithEureka: false #表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。 fetchRegistry: false #Eureka Server的访问地址，服务注册和client获取服务注册信息均通过该URL，多个服务注册地址用,隔开 serviceUrl: defaultZone: http://localhost:8761/eureka/ security: basic: enabled: true user: name: xujin password: 123 3.启动Eureka server测试，如下图所示 服务提供者注册Eureka Server安全身份验证1.服务提供者只需注册时修改application.yml 1234567891011 server: port: 8000 spring: application: name: sc-eureka-security-provider eureka: client: service-url: defaultZone: http://xujin:123@localhost:8761/eureka/ Tips:如上所示:http://用户名:密码@localhost:8761/eureka/","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"}]},{"title":"使用Spring Cloud Eureka实现服务注册与发现","slug":"sc/sc-eureka-01","date":"2017-03-23T06:00:00.000Z","updated":"2017-06-17T03:34:15.000Z","comments":true,"path":"sc/sc-eureka-01/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-01/","excerpt":"","text":"什么是服务注册与发现服务注册与发现 在服务化的早期，服务不是很多，服务的注册与发现并不是什么新鲜的名词，Nginx+内部域名服务器方式，甚至Nginx+host文件配置方式也能完成服务的注册与发现。服务上下线需要在nginx,服务器做相应的配置，一旦服务的IP端口发生变化，都需要在nginx上做相应的配置，为了解决这个问题引入服务注册中心。 服务注册,即服务在启动的时候就将服务的IP,端口,版本号等EndPoint注册到注册中心(Eueka,Zookeeper,Consul)对服务进行统一管理. 服务发现,简单的就是说，不管服务上下线，当对某个服务发起请求时，能够快速的从本地缓存或者注册中心的注册列表中，快速找到服务提供者。 服务化早期的做法示例工程说明 Tips：代码示例:https://github.com/SoftwareKing/spring-cloud-study/tree/master/sc-eureka-first Spring MVC中基于无状态的REST 工程可以参考sc-rest-demo下面的sc-rest-provider和sc-rest-consumer，具体使用如下代码所示：123456789101112131415161718192021@RestController@RequestMapping(\"/sc\")public class ConsumerController &#123; @Autowired private RestTemplate restTemplate; // 从属性文件中读取服务提供的URL @Value(\"$&#123;order.orderServiceUrl&#125;\") private String orderServiceUrl; @GetMapping(\"/consumer/&#123;id&#125;\") public OrderModel getOrderInfo(@PathVariable Long id) &#123; // this.restTemplate.getForObject(\"http://localhost:8000/sc/order/\" + // id,OrderModel.class); return this.restTemplate.getForObject(this.orderServiceUrl + \"/sc/order/\" + id, OrderModel.class); &#125;&#125; 大家注意到没，把http://localhost:8000 ,硬编码到程序中，是不是比较low。可以采用上面代码中的方式：orderServiceUrl解决。但是这样还是比较low,下面介绍一下引入Eureka实现服务注册与发现的处理。 使用Eureka实现服务的注册与发现搭建注册中心-Eureka Server 1.引入依赖123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;?xml version=\"1.0\"?&gt;&lt;project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;artifactId&gt;sc-eureka-first-server-HA01&lt;/artifactId&gt; &lt;name&gt;sc-eureka-first-server-HA01&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;!-- 引入Spring Cloud Eureka依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR5&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件--&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 在Resources目录下创建application.yml123456789101112131415server: port: 8761 # 指定该Eureka实例的端口eureka: client: #表示是否将自己注册到Eureka Server上，默认为true，当前应用为Eureka Server所以无需注册 registerWithEureka: false #表示是否从Eureka Server获取注册信息，默认为true。因为这是一个单点的Eureka Server，不需要同步其他的Eureka Server节点的数据，故而设为false。 fetchRegistry: false #Eureka Server的访问地址，服务注册和client获取服务注册信息均通过该URL，多个服务注册地址用,隔开 serviceUrl: defaultZone: http://localhost:8761/eureka/# 参考文档：http://projects.spring.io/spring-cloud/docs/1.0.3/spring-cloud.html#_standalone_mode# 参考文档：http://my.oschina.net/buwei/blog/618756 3.创建Spring Boot主应用程序启动代码12345678910111213141516171819package org.xujin.sc.eureka.server;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * Eureka Server * @author xujin */@SpringBootApplication@EnableEurekaServerpublic class SpringCloudEurekaServer &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringCloudEurekaServer.class, args); &#125;&#125; 启动Eureka server测试： 启动sc-eureka-first-server-HA01，访问http://localhost:8761/ ,如下图所示: 创建服务提供者 1.服务提供者，为了演示在这里提供一个简单的订单查询服务，如工程sc-eureka-first-provider01和sc-eureka-first-provider02所示。 2.主程序入口代码，如下所示：123456789101112131415161718192021package org.xujin.sc.eureka.first.order;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;/** * 服务提供者端，加上@EnableDiscoveryClient注解，完成服务注册。 * @author xujin * @site http://xujin.org */@SpringBootApplication@EnableDiscoveryClient// @EnableEurekaClientpublic class OrderProviderSpringBootAppliaction &#123; public static void main(String[] args) &#123; SpringApplication.run(OrderProviderSpringBootAppliaction.class, args); &#125;&#125; Tips:如果使用Eureka, 可以使用@EnableEurekaClient注解，但是推荐使用@EnableDiscoveryClient代替@EnableEurekaClient注解，因为@EnableDiscoveryClient是一个高度的抽象， 来自于spring-cloud-commons， 由于Spring Cloud选型是中立的因此抽象出该接口， 当服务注册中心选型改变为Eureka，ZK，Consul时，不需要修改原有代码中的注解。 3.服务提供者暴露的服务-OrderController.java12345678910111213@RestControllerpublic class OrderController &#123; @Autowired private OrderService orderService; @GetMapping(\"/sc/order/&#123;id&#125;\") public OrderModel findOrderById(@PathVariable Long id) &#123; OrderModel orderModel = orderService.findOrderByOrderId(id); return orderModel; &#125;&#125; 启动服务提供者，把服务注册信息，注册到Eureka Server注册中心启动sc-eureka-first-provider01,当启动其中一个服务后刷新Eureka Server会出现安全模式,如下图所示: 启动sc-eureka-first-provider02，刷新Eureka Server如下图所示。 创建服务消费者 服务消费者主要是一个简单的用户服务，用户服务查询订单服务的订单信息。 1.引入相应的依赖 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869 &lt;?xml version=\"1.0\"?&gt;&lt;project xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\" xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;org.xujin.sc&lt;/groupId&gt; &lt;artifactId&gt;sc-eureka-first-consumer&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;sc-eureka-first-consumer&lt;/name&gt; &lt;url&gt;http://maven.apache.org&lt;/url&gt; &lt;!-- 引入spring boot的依赖 --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.4.3.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-eureka&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;1.16.6&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;!-- 引入spring cloud的依赖 --&gt; &lt;dependencyManagement&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-dependencies&lt;/artifactId&gt; &lt;version&gt;Camden.SR4&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/dependencyManagement&gt; &lt;!-- 添加spring-boot的maven插件 --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 2.主程序入口代码12345678910111213141516171819202122package org.xujin.sc.eureka.user;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.client.discovery.EnableDiscoveryClient;import org.springframework.context.annotation.Bean;import org.springframework.web.client.RestTemplate;//消费者端加入服务发现注解@EnableDiscoveryClient@SpringBootApplicationpublic class UserConsumerApplication &#123; @Bean public RestTemplate restTemplate() &#123; return new RestTemplate(); &#125; public static void main(String[] args) &#123; SpringApplication.run(UserConsumerApplication.class, args); &#125;&#125; 消费者调用Controller。 12345678910111213141516171819202122232425262728@RestControllerpublic class UserController &#123; private static final Logger logger = LoggerFactory.getLogger(UserController.class); @Autowired private RestTemplate restTemplate; @Autowired private DiscoveryClient discoveryClient; // discoveryClient获取服务列表中，应用名为sc-eureka-first-provider一个服务注册信息 public String serviceUrl() &#123; List&lt;ServiceInstance&gt; list = discoveryClient .getInstances(\"sc-eureka-first-provider\"); if (list != null &amp;&amp; list.size() &gt; 0) &#123; return String.valueOf(list.get(0).getUri()); &#125; return null; &#125; @GetMapping(\"/sc/user/&#123;id&#125;\") public Order findByIdByEurekaServer(@PathVariable Long id) &#123; String providerServiceUrl = serviceUrl(); return this.restTemplate.getForObject(providerServiceUrl + \"sc/order/\" + id, Order.class); &#125;&#125; 如上述代码，所示使用discoveryClient.getInstances(&quot;sc-eureka-first-provider&quot;)获取服务名为sc-eureka-first-provider的服务注册列表信息。 测试先后启动sc-eureka-first-consumer,如没有异常，打开浏览器访问:http://localhost:8010/sc/user/2 ,debug如下所示可以看到 在刷新一下Eureka Server，如图下所示,此时安全模式关闭。 关于安全模式，在本篇文章中，暂不讨论，后面将会专写一篇文章介绍，请暂时忽略。 获取消费者获取服务端消费列表 使用EurekaClient获取服务注册信息 1234567 @Autowiredprivate EurekaClient discoveryClient;public String serviceUrl() &#123; InstanceInfo instance = discoveryClient.getNextServerFromEureka(\"STORES\", false); return instance.getHomePageUrl();&#125; 使用DiscoveryClient获取服务注册信息 12345678910 @Autowiredprivate DiscoveryClient discoveryClient;public String serviceUrl() &#123; List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"STORES\"); if (list != null &amp;&amp; list.size() &gt; 0 ) &#123; return list.get(0).getUri(); &#125; return null;&#125; 参考链接：https://github.com/spring-cloud/spring-cloud-netflix/blob/master/docs/src/main/asciidoc/spring-cloud-netflix.adoc 小结 上面这个例子使用Eureka实现了服务的注册与发现，但是有一个问题就是获取服务注册列表的方式比较low并且太方便，还有一个问题就是没有使用负载均衡（Load Balance)，这样就没法实现微服务的HA。在后面的文章将会介绍Eureka Server的HA和使用Robbin实现LB。。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"}]},{"title":"Spring Cloud Eureka中文翻译","slug":"sc/sc-fy-eureka","date":"2017-01-25T06:00:00.000Z","updated":"2017-06-17T03:34:56.000Z","comments":true,"path":"sc/sc-fy-eureka/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-fy-eureka/","excerpt":"Eureka学习文档资料： Netflix Eureka详细文档 Spring Cloud中对Eureka的介绍 Spring Cloud Eureka工程中的文档 说明：本文主要是对http://cloud.spring.io/spring-cloud-static/spring-cloud.html#_spring_cloud_netflix ,Eureka相关的内容进行翻译更新，由于工作原因可能存在时效性敬请谅解。 Spring Cloud Netflix提供了对Netflix\b开源项目的集成，使得我们可以以Spring Boot编程风格使用Netflix旗下相关框架。你只需要在程序中添加注解，就能使用成熟的Netflix组件来快速实现分布式系统的常见架构模式。这些模式包括服务发现(Eureka), 断路器(Hystrix), 智能路由(Zuul)和客户端负载均衡(Ribbon)。","text":"Eureka学习文档资料： Netflix Eureka详细文档 Spring Cloud中对Eureka的介绍 Spring Cloud Eureka工程中的文档 说明：本文主要是对http://cloud.spring.io/spring-cloud-static/spring-cloud.html#_spring_cloud_netflix ,Eureka相关的内容进行翻译更新，由于工作原因可能存在时效性敬请谅解。 Spring Cloud Netflix提供了对Netflix\b开源项目的集成，使得我们可以以Spring Boot编程风格使用Netflix旗下相关框架。你只需要在程序中添加注解，就能使用成熟的Netflix组件来快速实现分布式系统的常见架构模式。这些模式包括服务发现(Eureka), 断路器(Hystrix), 智能路由(Zuul)和客户端负载均衡(Ribbon)。 服务发现：Eureka客户端服务发现是微服务架构中的一项核心服务。如果没有该服务，我们就只能为每一个服务调用者手工配置可用服务的地址，这不仅繁琐而且非常容易出错。Eureka包括了服务端和客户端两部分。服务端可以做到高可用集群部署，每一个节点可以自动同步，有相同的服务注册信息。 向Eureka注册服务当客户端向Eureka注册自己时会提供一些元信息，如主机名、端口号、获取健康信息的url和主页等。Eureka通过心跳连接判断服务是否在线，如果心跳检测失败超过指定时间，对应的服务通常就会被移出可用服务列表。 译者注：向Eureka Server注册过的服务会每30秒向Server发送一次心跳连接, Server会根据心跳数据更新该服务的健康状态并复制到其他Server中。如果超过90秒没有收到该服务的心跳数据，则Server会将该服务移出列表。参考文档：https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance Eureka Client代码示例： 1234567891011121314151617@Configuration@ComponentScan@EnableAutoConfiguration@EnableEurekaClient@RestControllerpublic class Application &#123; @RequestMapping(\"/\") public String home() &#123; return \"Hello world\"; &#125; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; (其实就是个普通的Spring Boot应用)。 在这个例子中我们使用了@EnableEurekaClient注解，但是要在使用Eureka的前提下，你也可以使用@EnableDiscoveryClient注解达到同样的效果。除此之外需要在Eureka server上加上配置信息，如下所示： application.yml 1234eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 其中，defaultZone的作用是给没有指定Zone的客户端一个默认的Eureka地址。 译者注：客户端可以在配置文件中指定当前服务属于哪一个Zone，如果没有指定，则属于默认Zone。 默认的应用名(Service ID)、主机名和端口号分别对应配置信息中的${spring.application.name}、${spring.application.name}和${server.port}参数。 使用@EnableEurekaClient注解后当前应用会同时变成一个Eureka服务端实例(它会注册自身)和Eureka客户端(可以查询当前服务列表)，与此相关的配置都在以eureka.instance.*开头的参数下。只要你指定了spring.application.name参数，那么就可以放心的使用默认参数而不需要修改任何配置。 要查看更详细的参数，请参阅EurekaInstanceConfigBean和EurekaClientConfigBean。 Eureka Server的身份验证如果客户端的eureka.client.serviceUrl.defaultZone参数值(即Eureka Server的地址)中包含HTTP Basic Authentication信息，如[http://user:password@localhost:8761/eureka](http://user:password@localhost:8761/eureka)，那么客户端就会自动使用该用户名、密码信息与Eureka服务端进行验证。如果你需要更复杂的验证逻辑，你必须注册一个DiscoveryClientOptionalArgs组件，并将ClientFilter组件注入，在这里定义的逻辑会在每次客户端向服务端发起请求时执行。 由于Eureka的限制，Eureka不支持单节点身份验证。 状态页和健康信息指示器Eureka应用的状态页和健康信息默认的url为/info和/health，这与Spring Boot Actuator中对应的Endpoint是重复的，因此你必须进行修改： 1234eureka: instance: statusPageUrlPath: $&#123;management.context-path&#125;/info healthCheckUrlPath: $&#123;management.context-path&#125;/health 客户端通过这些URL获取数据，并根据这些数据来判断是否可以向某个服务发起请求。 使用HTTPS你可以指定EurekaInstanceConfig类中的eureka.instance.[nonSecurePortEnabled,securePortEnabled]=[false,true]属性来指定是否使用HTTPS。当配置使用HTTPS时，Eureka Server会返回以https开头的服务地址。 即使配置了使用HTTPS，Eureka的主页依然是以普通 HTTP 方式访问的。你需要手动添加一些配置来将这些页面也通过HTTPS保护起来： 12345eureka: instance: statusPageUrl: https://$&#123;eureka.hostname&#125;/info healthCheckUrl: https://$&#123;eureka.hostname&#125;/health homePageUrl: https://$&#123;eureka.hostname&#125;/ 注意，eureka,hostname是Eureka原生属性，只有新版本的Eureka才支持该属性。你也可以\b用Spring EL表达式代替：${eureka.instance.hostName} 如果你的应用前端部署了代理，并且SSL的终点是此代理服务器，那么你就需要在应用中解析forwarded请求头。如果你在配置文件中添加了X-Forwarded-*相关参数，Spring Boot中的嵌入式Tomcat会自动解析该请求头。一种表明你没有处理好forwarded请求头的迹象就是你的应用渲染出的HTML页面中链接显示的是错误的主机名和端口号。 健康检查默认情况下，Eureka通过客户端发来的心跳包来判断客户端是否在线。如果你不显式指定，客户端在心跳包中不会包含当前应用的健康数据(由Spring Boot Actuator提供)。这意味着只要客户端启动时完成了服务注册，那么该客户端在主动注销之前在Eureka中的状态会永远是UP状态。我们可以通过配置修改这一默认行为，即在客户端发送心跳包时会带上自己的健康信息。这样做的后果是只有当该服务的状态是UP时才能被访问，其它的任何状态都会导致该服务不能被调用。 1234eureka: client: healthcheck: enabled: true 如果你想对健康检查有更细粒度的控制，你可以自己实现com.netflix.appinfo.HealthCheckHandler接口。 以下内容翻译自Eureka官方手册： Eureka客户端会每隔30s向服务端发送心跳包以告知服务端当前客户端没有挂掉。对于Client来说，服务Server超过90s没有收到该Client的心跳数据，Server就会把该Client移出服务列表。最好不要修改30s的默认心跳间隔，因为Server会使用这个时间数值来判断是否出现了大面积故障。(译者：意思是比如Eureka默认2分钟收不到心跳就认为网络出了故障，你如果把这个心跳间隔改成了3分钟，那就出问题了。) Eureka元数据说明我们有必要花一些时间来了解一下Eureka的元数据，这样就可以添加一些自定义的数据以适应特定的业务场景。像主机名、IP地址、端口号、状态页url和健康检查url都是Eureka定义的标准元数据。这些元数据会被保存在Eureka Server的注册信息中，客户端会读取这些数据来向需要调用的服务直接发起连接。你可以使用以eureka.instance.metadataMap开头的参数来添加你自定义的元数据，所有客户端都会读取到该信息。通过这种方式你能给客户端自定义一些行为。 使用EurekaClient对象当添加了@EnableDiscoveryClient或@EnableEurekaClient注解后，你就可以在应用中使用EurekaClient对象来获取服务列表： 1234567@Autowiredprivate EurekaClient discoveryClient;public String serviceUrl() &#123; InstanceInfo instance = discoveryClient.getNextServerFromEureka(\"STORES\", false); return instance.getHomePageUrl();&#125; 不要在@PostConstruct或@Scheduled方法中使用EurekaClient。在ApplicationContext还没有完全启动时使用该对象会发生错误。 使用Spring的DiscoveryClient对象你没有必要直接使用Netflix原生的EurekaClient对象，在此基础上做一些封装使用起来会更方便。Spring Cloud支持Feign和Spring RestTmpelate，它们都可以使用服务的逻辑名而不是URL地址来查询服务。如果想给Ribbon手工指定服务列表，你可以将&lt;client&gt;.ribbon.listOfServers属性设为逗号分隔的物理地址或主机名, 参数中的client是服务id，即服务名。 你可以使用Spring提供的DiscoveryClient对象从而代码不会与Eureka紧耦合： 12345678910@Autowiredprivate DiscoveryClient discoveryClient;public String serviceUrl() &#123; List&lt;ServiceInstance&gt; list = discoveryClient.getInstances(\"STORES\"); if (list != null &amp;&amp; list.size() &gt; 0 ) &#123; return list.get(0).getUri(); &#125; return null;&#125; 为什么注册一个服务这么慢?服务的注册涉及到心跳连接，默认为每30秒一次。只有当Eureka服务端和客户端本地缓存中的服务元数据相同时这个服务才能被其它客户端发现，这需要3个心跳周期。你可以通过参数eureka.instance.leaseRenewalIntervalInSeconds调整这个时间间隔来加快这个过程。在生产环境中你最好使用默认值，因为Eureka内部的某些计算依赖于该时间间隔。 服务发现：Eureka服务端添加spring-cloud-starter-eureka-server，主类代码示例如下： 123456789@SpringBootApplication@EnableEurekaServerpublic class Application &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(Application.class).web(true).run(args); &#125;&#125; 服务启动后，Eureka有一个带UI的主页，注册信息可以通过/eureka/*下的URL获取到。 高可用, Zone 和 RegionEureka把所有注册信息都放在内存中，所有注册过的客户端都会向Eureka发送心跳包来保持连接。客户端会有一份本地注册信息的缓存，这样就不需要每次远程调用时都向Eureka查询注册信息。 默认情况下，Eureka服务端自身也是个客户端，所以需要指定一个Eureka Server的URL作为”伙伴”(peer)。如果你没有提供这个地址，Eureka Server也能正常启动工作，但是在日志中会有大量关于找不到peer的错误信息。 Standalone模式只要Eureka Server进程不会挂掉，这种集Server和Client于一身和心跳包的模式能让Standalone(单台)部署的Eureka Server非常容易进行灾难恢复。在 Standalone 模式中，可以通过下面的配置来关闭查找“伙伴”的行为： 1234567891011server: port: 8761eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 注意，serviceUrl中的地址的主机名要与本地主机名相同。 “伙伴”感知Eureka Server可以通过运行多个实例并相互指定为“伙伴”的方式来达到更高的高可用性。实际上这就是默认设置，你只需要指定“伙伴”的地址就可以了: 12345678910111213141516171819202122232425eureka: client: serviceUrl: defaultZone: http://peer1/eureka/,http://peer2/eureka/,http://peer3/eureka/---spring: profiles: peer1eureka: instance: hostname: peer1---spring: profiles: peer2eureka: instance: hostname: peer2---spring: profiles: peer3eureka: instance: hostname: peer3 在上面这个例子中，我们通过使用不同profile配置的方式可以在本地运行两个Eureka Server。你可以通过修改/etc/host文件，使用上述配置在本地测试伙伴感特性。 你可以同时启动多个Eureka Server, 并通过伙伴配置使之围成一圈(相邻两个Server互为伙伴)，这些Server中的注册信息都是同步的。If the peers are physically separated (inside a data centre or between multiple data centres) then the system can in principle survive split-brain type failures. 使用IP地址有些时候你可能更倾向于直接使用IP地址定义服务而不是使用主机名。把eureka.instance.preferIpAddress参数设为true时，客户端在注册时就会使用自己的ip地址而不是主机名。","categories":[{"name":"Spring Cloud翻译","slug":"Spring-Cloud翻译","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud翻译/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"}]},{"title":"爱油科技基于SpringCloud的微服务实践","slug":"sc/sc-fx1","date":"2016-11-22T06:00:00.000Z","updated":"2017-06-17T03:18:26.000Z","comments":true,"path":"sc/sc-fx1/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-fx1/","excerpt":"爱油科技基于SpringCloud的微服务实践个人简介刘思贤（微博@starlight36），爱油科技架构师、PMP。主要负责业务平台架构设计，DevOps实施和研发过程持续改进等，关注领域驱动设计与微服务、建设高效团队和工程师文化培养。 摘要本次分享主要介绍了爱油科技基于Docker和Spring Cloud将整体业务微服务化的一些实践经验，主要包括： 微服务架构的分层和框架选型 服务发现和配置管理 服务集成和服务质量保证 基于领域驱动设计 实施DevOps","text":"爱油科技基于SpringCloud的微服务实践个人简介刘思贤（微博@starlight36），爱油科技架构师、PMP。主要负责业务平台架构设计，DevOps实施和研发过程持续改进等，关注领域驱动设计与微服务、建设高效团队和工程师文化培养。 摘要本次分享主要介绍了爱油科技基于Docker和Spring Cloud将整体业务微服务化的一些实践经验，主要包括： 微服务架构的分层和框架选型 服务发现和配置管理 服务集成和服务质量保证 基于领域驱动设计 实施DevOps 从单体应用到微服务 单体应用优点 小而美，结构简单易于开发实现 部署门槛低，单个Jar包或者网站打包即可部署 可快速实现多实例部署 缺点 随着业务发展更多的需求被塞进系统，体系结构逐渐被侵蚀反应堆林立 被技术绑架，难以为特定业务选择平台或框架，尽管可能有更适宜的技术做这件事 协作困难，不同业务的团队在一个系统上进行开发相互冲突 难以扩展，为了热点业务而不得不同时扩容全部业务，或者难以继续扩容 架构拆分拆分：按行分层，按列分业务 在我们的微服务体系中，所有的服务被划分为了三个层次： 基础设施层：为所有业务提供基础设施，包括服务注册、数据库和NoSQL、对象存储、消息队列等基础设施服务，这一层通常是由成熟组件、第三方服务组成。 业务服务层：业务微服务，根据业务领域每个子域单独一个微服务，分而治之。 接入层：直接对外提供服务，例如网站、API接口等。接入层不包含复杂的业务逻辑，只做呈现和转换。 项目中我们主要关注业务服务层和接入层，对于没有足够运维力量的我们，基础设施使用云服务是省事省力的选择。 业务服务层我们给他起名叫作Epic，接入层我们起名Rune，建立之初便订立了如下原则： 业务逻辑层内所有服务完全对等，可相互调用 业务逻辑层所有服务必须是无状态的 接入层所有服务可调用业务逻辑层所有服务，但接入层内部同层服务之间不可调用 接入层不能包含业务逻辑代码 所有微服务必须运行在Docker容器里 业务逻辑层我们主要使用使用Java，接入层我们主要使用PHP或Node。后来随着团队的成长，逐步将接入层全部迁移至Node。 框架选型爱油科技作为一家成品油行业的初创型公司，需要面对非常复杂的业务场景，而且随着业务的发展，变化的可能性非常高。所以在微服务架构设计之初，我们就期望我们的微服务体系能： 不绑定到特定的框架、语言 服务最好是Restful风格 足够简单，容易落地，将来能扩展 和Docker相容性好 目前常见的微服务相关框架： Dubbo、DubboX Spring Cloud Motan Thrift、gRPC 这些常见的框架中，Dubbo几乎是唯一能被称作全栈微服务框架的“框架”，它包含了微服务所需的几乎所有内容，而DubboX作为它的增强，增加了REST支持。 它优点很多，例如： 全栈，服务治理的所有问题几乎都有现成答案 可靠，经过阿里实践检验的产品 实践多，社区有许多成功应用Dubbo的经验 不过遗憾的是： 已经停止维护 不利于裁剪使用 “过于Java”，与其他语言相容性一般 Motan是微博平台微服务框架，承载了微博平台千亿次调用业务。 优点是： 性能好，源自于微博对高并发和实时性的要求 模块化，结构简单，易于使用 与其他语言相容性好 不过： 为“短平快”业务而生，即业务简单，追求高性能高并发。 Apache Thrift、gRPC等虽然优秀，并不能算作微服务框架，自身并不包括服务发现等必要特性。 如果说微服务少不了Java，那么一定少不了Spring，如果说少不了Spring，那么微服务“官配”Spring Cloud当然是值得斟酌的选择。 优点： “不做生产者，只做搬运工” 简单方便，几乎零配置 模块化，松散耦合，按需取用 社区背靠Spring大树 不足： 轻量并非全栈 没解决RPC的问题 实践案例少 根据我们的目标，我们最终选择了Spring Cloud作为我们的微服务框架，原因有4点： 虽然Dubbo基础设施更加完善，但结构复杂，我们很难吃得下，容易出坑 基于Apache Thrift和gRPC自研，投入产出比很差 不想过早引入RPC以防滥用，Restful风格本身就是一种约束。 做选择时，Motan还没有发布 Spring CloudSpring Cloud是一个集成框架，将开源社区中的框架集成到Spring体系下，几个重要的家族项目： spring-boot，一改Java应用程序运行难、部署难，甚至无需Web容器，只依赖JRE即可 spring-cloud-netflix，集成Netflix优秀的组件Eureka、Hystrix、Ribbon、Zuul，提供服务发现、限流、客户端负载均衡和API网关等特性支持 spring-cloud-config，微服务配置管理 spring-cloud-consul，集成Consul支持 服务发现和配置管理Spring Cloud Netflix提供了Eureka服务注册的集成支持，不过没选它是因为： 更适合纯Java平台的服务注册和发现 仍然需要其他分布式KV服务做后端，没解决我们的核心问题 Docker作为支撑平台的重要技术之一，Consul几乎也是我们的必选服务。因此我们觉得一事不烦二主，理所应当的Consul成为我们的服务注册中心。 Consul的优势： 使用Raft一致性算法，能保证分布式集群内各节点状态一致 提供服务注册、服务发现、服务状态检查 支持HTTP、DNS等协议 提供分布式一致性KV存储 也就是说，Consul可以一次性解决我们对服务注册发现、配置管理的需求，而且长期来看也更适合跟不同平台的系统，包括和Docker调度系统进行整合。 最初打算自己开发一个Consul和Spring Cloud整合的组件，不过幸运的是，我们做出这个决定的时候，spring-cloud-consul刚刚发布了，我们可以拿来即用，这节约了很多的工作量。 因此借助Consul和spring-cloud-consul，我们实现了 服务注册，引用了srping-cloud-consul的项目可以自动注册服务，也可以通过HTTP接口手动注册，Docker容器也可以自动注册 服务健康状态检查，Consul可以自动维护健康的服务列表 异构系统可以直接通过Consul的HTTP接口拉取并监视服务列表，或者直接使用DNS解析服务 通过分布式一致性KV存储进行微服务的配置下发 为一些业务提供选主和分布式锁服务 当然也踩到了一些坑： spring-cloud-consul服务注册时不能正确选判本地ip地址。对于我们的环境来说，无论是在服务器上，还是Docker容器里，都有多个网络接口同时存在，而spring-cloud-consul在注册服务时，需要先选判本地服务的IP地址，判断逻辑是以第一个非本地地址为准，常常错判。因此在容器中我们利用entrypoint脚本获取再通过环境变量强制指定。 12345678910111213141516171819202122#!/usr/bin/env bashset -e# If service runs as Rancher service, auto set advertise ip address# from Rancher metadata service.if [ -n \"$RUN_IN_RANCHER\" ]; then echo \"Waiting for ip address...\" # Waiting for ip address sleep 5 RANCHER_MS_BASE=http://rancher-metadata/2015-12-19 PRIMARY_IP=`curl -sSL $RANCHER_MS_BASE/self/container/primary_ip` SERVICE_INDEX=`curl -sSL $RANCHER_MS_BASE/self/container/service_index` if [ -n \"$PRIMARY_IP\" ]; then export SPRING_CLOUD_CONSUL_DISCOVERY_HOSTNAME=$PRIMARY_IP fi echo \"Starting service #$&#123;SERVICE_INDEX-1&#125; at $PRIMARY_IP.\"fiexec \"$@\" 我们的容器运行在Rancher中，所以可以利用Rancher的metadata服务来获取容器的IP地址，再通过SPRING_CLOUD_CONSUL_DISCOVERY_HOSTNAME环境变量来设置服务发现的注册地址。基于其他容器调度平台也会很相似。 另外一些服务中内置了定时调度任务等，多实例启动时需要单节点运行调度任务。通过Consul的分布式锁服务，我们可以让获取到锁的节点启用调度任务，没获取到的节点等待获取锁。 服务集成为了方便开发人员使用，微服务框架应当简单容易使用。对于很多微服务框架和RPC框架来说，都提供了很好的机制。在Spring Cloud中通过OpenFeign实现微服务之间的快速集成： 服务方声明一个Restful的服务接口，和普通的Spring MVC控制器几乎别无二致： 1234567891011121314@RestController@RequestMapping(\"/users\")public class UserResource &#123; @RequestMapping(value = \"&#123;id&#125;\", method = RequestMethod.GET, produces = \"application/json\") public UserRepresentation findOne(@PathVariable(\"id\") String id) &#123; User user = this.userRepository.findByUserId(new UserId(id)); if (user == null || user.getDeleted()) &#123; throw new NotFoundException(\"指定ID的用户不存在或者已被删除。\"); &#125; return new UserRepresentation(user); &#125;&#125; 客户方使用一个微服务接口，只需要定义一个接口： 1234567@FeignClient(\"epic-member-microservice\")public interface UserClient &#123; @Override @RequestMapping(value = \"/users/&#123;id&#125;\", method = RequestMethod.GET, produces = \"application/json\") User findOne(@PathVariable(\"id\") String id);&#125; 在需要使用UserClient的Bean中，直接注入UserClient类型即可。事实上，UserClient和相关VO类，可以直接作为公共接口封装在公共项目中，供任意需要使用的微服务引用，服务方Restful Controller直接实现这一接口即可。 OpenFeign提供了这种简单的方式来使用Restful服务，这大大降低了进行接口调用的复杂程度。 对于错误的处理，我们使用HTTP状态码作为错误标识，并做了如下规定： 4xx用来表示由于客户方参数错误、状态不正确、没有权限、操作冲突等种种原因导致的业务错误。 5xx用来表示由于服务方系统异常、无法服务等原因服务不可用的错误。 对于服务器端，只需要在一个异常类上添加注解，即可指定该异常的HTTP响应状态码，例如： 123456789101112131415@ResponseStatus(HttpStatus.NOT_FOUND)public class NotFoundException extends RuntimeException &#123; public NotFoundException() &#123; super(\"查找的资源不存在或者已被删除。\"); &#125; public NotFoundException(String message) &#123; super(message); &#125; public NotFoundException(String message, Throwable cause) &#123; super(message, cause); &#125;&#125; 对于客户端我们实现了自己的FeignClientExceptionErrorDecoder来将请求异常转换为对于的异常类，示例如下： 123456789101112131415161718192021222324252627@Componentpublic class FeignClientExceptionErrorDecoder implements ErrorDecoder &#123; private final ErrorDecoder delegate = new ErrorDecoder.Default(); @Override public Exception decode(String methodKey, Response response) &#123; // Only decode 4xx errors. if (response.status() &gt;= 500) &#123; return delegate.decode(methodKey, response); &#125; // Response content type must be json if (response.headers().getOrDefault(\"Content-Type\", Lists.newArrayList()).stream() .filter(s -&gt; s.toLowerCase().contains(\"json\")).count() &gt; 0) &#123; try &#123; String body = Util.toString(response.body().asReader()); // 转换并返回异常对象 ... &#125; catch (IOException ex) &#123; throw new RuntimeException(\"Failed to process response body.\", ex); &#125; &#125; return delegate.decode(methodKey, response); &#125;&#125; 需要注意的是，decode方法返回的4xx状态码异常应当是HystrixBadRequestException的子类对象，原因在于，我们把4xx异常视作业务异常，而不是由于故障导致的异常，所以不应当被Hystrix计算为失败请求，并引发断路器动作，这一点非常重要。 在UserClient.findOne方法的调用代码中，即可直接捕获相应的异常了： 12345try &#123; User user = this.userClient.findOne(new UserId(id));&#125; catch(NotFoundException ex) &#123; ...&#125; 通过OpenFeign，我们大大降低了Restful接口进行服务集成的难度，几乎做到了无额外工作量的服务集成。 服务质量保证微服务架构下，由于调用需要跨系统进行远程操作，各微服务独立运维，所以在设计架构时还必须考虑伸缩性和容错性，具体地说主要包括以下几点要求： 服务实例可以平滑地加入、移除 流量可以均匀地分布在不同的实例上 接口应当资源隔离，防止因为个别接口调用时间过长导致线程池被占满而导致整个服务不可用 能支持接口降级并隔离故障节点，防止集群雪崩 服务能进行平滑升级 Spring Cloud中内置的spring-cloud-netflix的其他组件为我们提供了很好的解决方案： Hystrix - 实现了断路器模式，帮助控流和降级，防止集群雪崩，就像汽车的避震器 Ribbon - 提供了客户端负载均衡器 Zuul - API网关模式，帮助实现接口的路由、认证等 下面主要介绍一下，各个组件在进行服务质量保证中是如何发挥作用的。 ConsulConsul中注册了一致性的可用的服务列表，并通过健康检查保证这些实例都是存活的，服务注册和检查的过程如下： 服务启动完成，服务端口开始监听时，spring-cloud-consul通过Consul接口发起服务注册，将服务的/health作为健康检查端点； Consul每隔5秒访问/health，检查当前微服务是否为UP状态； /health将会收集微服务内各个仪表收集上来的状态数据，主要包括数据库、消息队列是否连通等； 如果为UP状态，则微服务实例被标记为健康可用，否则被标记成失败； 当服务关闭时，先从Consul中取消服务注册，再优雅停机。 这样能够保证Consul中列出的所有微服务状态都是健康可用的，各个微服务会监视微服务实例列表，自动同步更新他们。 HystrixHystrix提供了断路器模式的实现，主要在三个方面可以说明： 图片来自Hystrix项目文档 首先Hystrix提供了降级方法，断路器开启时，操作请求会快速失败不再向后投递，直接调用fallback方法来返回操作；当操作失败、被拒或者超时后，也会直接调用fallback方法返回操作。这可以保证在系统过载时，能有后备方案来返回一个操作，或者优雅的提示错误信息。断路器的存在能让故障业务被隔离，防止过载的流量涌入打死后端数据库等。 然后是基于请求数据统计的断路开关，在Hystrix中维护一个请求统计了列表（默认最多10条），列表中的每一项是一个桶。每个桶记录了在这个桶的时间范围内（默认是1秒），请求的成功数、失败数、超时数、被拒数。其中当失败请求的比例高于某一值时，将会触发断路器工作。 最后是不同的请求命令（HystrixCommand）可以使用彼此隔离的资源池，不会发生相互的挤占。在Hystrix中提供了两种隔离机制，包括线程池和信号量。线程池模式下，通过线程池的大小来限制同时占用资源的请求命令数目；信号量模式下通过控制进入临界区的操作数目来达到限流的目的。 这里包括了Hystrix的一些重要参数的配置项： 参数 说明 circuitBreaker.requestVolumeThreshold 至少在一个统计窗口内有多少个请求后，才执行断路器的开关，默认20 circuitBreaker.sleepWindowInMilliseconds 断路器触发后多久后才进行下一次判定，默认5000毫秒 circuitBreaker.errorThresholdPercentage 一个统计窗口内百分之多少的请求失败才触发熔断，默认是50% execution.isolation.strategy 运行隔离策略，支持Thread，Semaphore，前者通过线程池来控制同时运行的命令，后者通过信号来控制，默认是Thread execution.isolation.thread.interruptOnTimeout 命令执行的超时时间，默认1000毫秒 coreSize 线程池大小，默认10 keepAliveTimeMinutes 线程存活时间，默认为1分钟 maxQueueSize 最大队列长度，-1使用SynchronousQueue，默认-1。 queueSizeRejectionThreshold 允许队列堆积的最大数量 RibbonRibbon使用Consul提供的服务实例列表，可以通过服务名选取一个后端服务实例连接，并保证后端流量均匀分布。spring-cloud-netflix整合了OpenFeign、Hystrix和Ribbon的负载均衡器，整个调用过程如下（返回值路径已经省略）： 在这个过程中，各个组件扮演的角色如下： Feign作为客户端工厂，负责生成客户端对象，请求和应答的编解码 Hystrix提供限流、断路器、降级、数据统计 Ribbon提供负载均衡器 Feign负责提供客户端接口收调用，把发起请求操作（包括编码、解码和请求数据）封装成一个Hystrix命令，这个命令包裹的请求对象，会被Ribbon的负载均衡器处理，按照负载均衡策略选择一个主机，然后交给请求对象绑定的HTTP客户端对象发请求，响应成功或者不成功的结果，返回给Hystrix。 spring-cloud-netflix中默认使用了Ribbon的ZoneAwareLoadBalancer负载均衡器，它的负载均衡策略的核心指标是平均活跃请求数（Average Active Requests）。ZoneAwareLoadBalancer会拉取所有当前可用的服务器列表，然后将目前由于种种原因（比如网络异常）响应过慢的实例暂时从可用服务实例列表中移除，这样的机制可以保证故障实例被隔离，以免继续向其发送流量导致集群状态进一步恶化。不过由于目前spring-cloud-consul还不支持通过consul来指定服务实例的所在区，我们正在努力将这一功能完善。除了选区策略外，Ribbon中还提供了其他的负载均衡器，也可以自定义合适的负载均衡器。 总的来看，spring-cloud-netflix和Ribbon中提供了基本的负载均衡策略，对于我们来说已经足够用了。但实践中，如果需要进行灰度发布或者需要进行流量压测，目前来看还很难直接实现。而这些特性在Dubbo则开箱即用。 ZuulZuul为使用Java语言的接入层服务提供API网关服务，既可以根据配置反向代理指定的接口，也可以根据服务发现自动配置。Zuul提供了类似于iptables的处理机制，来帮助我们实现验证权鉴、日志等，请求工作流如下所示： 图片来自Zuul官方文档。 使用Zuul进行反向代理时，同样会走与OpenFeign类似的请求过程，确保API的调用过程也能通过Hystrix、Ribbon提供的降级、控流机制。 Hystrix DashboardHystrix会统计每个请求操作的情况来帮助控制断路器，这些数据是可以暴露出来供监控系统热点。Hystrix Dashboard可以将当前接口调用的情况以图形形式展示出来： 图片来自Hystrix Dashboard官方示例 Hystrix Dashboard既可以集成在其他项目中，也可以独立运行。我们直接使用Docker启动一个Hystrix Dashboard服务即可： 1docker run --rm -ti -p 7979:7979 kennedyoliveira/hystrix-dashboard 为了实现能对整个微服务集群的接口调用情况汇总，可以使用spring-cloud-netflix-turbine来将整个集群的调用情况汇集起来，供Hystrix Dashboard展示。 日志监控微服务的日志直接输出到标准输出/标准错误中，再由Docker通过syslog日志驱动将日志写入至节点机器机的rsyslog中。rsyslog在本地暂存并转发至日志中心节点的Logstash中，既归档存储，又通过ElasticSearch进行索引，日志可以通过Kibana展示报表。 在rsyslog的日志收集时，需要将容器信息和镜像信息加入到tag中，通过Docker启动参数来进行配置： 1--log-driver syslog --log-opt tag=&quot;&#123;&#123;.ImageName&#125;&#125;/&#123;&#123;.Name&#125;&#125;/&#123;&#123;.ID&#125;&#125;&quot; 不过rsyslog默认只允许tag不超过32个字符，这显然是不够用的，所以我们自定义了日志模板： 1template (name=&quot;LongTagForwardFormat&quot; type=&quot;string&quot; string=&quot;&lt;%PRI%&gt;%TIMESTAMP:::date-rfc3339% %HOSTNAME% %syslogtag%%msg:::sp-if-no-1st-sp%%msg%&quot;) 在实际的使用过程中发现，当主机内存负载比较高时，rsyslog会发生日志无法收集的情况，报日志数据文件损坏。后来在Redhat官方找到了相关的问题，确认是rsyslog中的一个Bug导致的，当开启日志压缩时会出现这个问题，我们选择暂时把它禁用掉。 领域驱动设计我们使用领域驱动设计（DDD）的方法来构建微服务，因为微服务架构和DDD有一种天然的契合。把所有业务划分成若干个子领域，有强内在关联关系的领域（界限上下文）应当被放在一起作为一个微服务。最后形成了界限上下文-工作团队-微服务一一对应的关系： 身份与访问 - 团队A - 成员微服务 商品与促销 - 团队B - 商品微服务 订单交易 - 团队C - 交易微服务 … 微服务设计在设计单个微服务（Epic层的微服务）时，我们这样做： 使用OOD方法对业务进行领域建模，领域模型应当是充血模型 领域服务帮助完成多个领域对象协作 事件驱动，提供领域事件，供内部或者其他微服务使用 依赖倒置，在适配器接口中实现和框架、组件、SDK的整合 这给我们带来了显著的好处： 服务开发时关注于业务，边界合理清晰 容易直接对领域模型进行单元测试 不依赖特定组件或者平台 事务问题从单体应用迁移到微服务架构时，不得不面临的问题之一就是事务。在单体应用时代，所有业务共享同一个数据库，一次请求操作可放置在同一个数据库事务中；在微服务架构下，这件事变得非常困难。然而事务问题不可避免，非常关键。 解决事务问题时，最先想到的解决方法通常是分布式事务。分布式事务在传统系统中应用的比较广泛，主要基于两阶段提交的方式实现。然而分布式事务在微服务架构中可行性并不高，主要基于这些考虑： 分布式事务需要事务管理器，对于不同语言平台来说，几乎没有有一致的实现来进行事务管理； 并非所有的持久化基施都提供完整ACID的事务，比如现在广泛使用的NoSQL； 分布式事务存在性能问题。 根据CAP理论，分布式系统不可兼得一致性、可用性、分区容错性（可靠性）三者，对于微服务架构来讲，我们通常会保证可用性、容错性，牺牲一部分一致性，追求最终一致性。所以对于微服务架构来说，使用分布式事务来解决事务问题无论是从成本还是收益上来看，都不划算。 对微服务系统来说解决事务问题，CQRS+Event Sourcing是更好的选择。 CQRS是命令和查询职责分离的缩写。CQRS的核心观点是，把操作分为修改状态的命令（Command），和返回数据的查询（Query），前者对应于“写”的操作，不能返回数据，后者对应于“读”的操作，不造成任何影响，由此领域模型被一分为二，分而治之。 Event Sourcing通常被翻译成事件溯源，简单的来说就是某一对象的当前状态，是由一系列的事件叠加后产生的，存储这些事件即可通过重放获得对象在任一时间节点上的状态。 通过CQRS+Event Sourcing，我们很容易获得最终一致性，例如对于一个跨系统的交易过程而言： 用户在交易微服务提交下单命令，产生领域事件PlaceOrderEvent，订单状态PENDING； 支付微服务收到领域事件进行扣款，扣款成功产生领域事件PaidEvent； 交易微服务收到领域事件PaidEvent，将订单标记为CREATED； 若支付微服务发现额度不足扣款失败，产生领域事件InsufficientEvent，交易微服务消费将订单标记为CANCELED。 我们只要保证领域事件能被持久化，那么即使出现网络延迟或部分系统失效，我们也能保证最终一致性。 实践上，我们利用Spring从4.2版本开始支持的自定义应用事件机制将本地事务和事件投递结合起来进行： 领域内业务过程会产生领域事件，通过Spring的应用事件机制进行应用内投递； 监听相应的领域事件，在事务提交前投递至消息队列； 以上全都没有异常发生，则本地事务提交，如果出现异常，本地事务回滚。 一些小经验 使用Spring Configured实现非Spring Bean的依赖注入（自己new的对象也可以注入了，对充血模型非常有用） 使用Swagger UI实现自文档的微服务，写好接口即有文档，即可调试 DevOps到目前为止我们已经有数十个微服务运行于线上了，微服务数目甚至多过了团队人数。如果没有DevOps支持，运维这些微服务将是一场灾难。我们使用Docker镜像作为微服务交付的标准件： Gitlab管理团队项目代码 Gitlab-CI提供构建打包，大家提交的项目都要构建并跑通测试 使用Rancher作为Docker调度平台，Merge后RC分支自动部署 测试通过后统一上线发布 由于时间所限，这里就不展开赘述了。 永不完美基于spring-cloud-consul的配置管理仍然需要完善，对于大规模应用的环境中，配置的版本控制、灰度、回滚等非常重要。SpringCloud提供了一个核，但是具体的使用还要结合场景、需求和环境等，再做一些工作。 对于非JVM语言的微服务和基于SpringCloud的微服务如何协同治理，这一问题仍然值得探索。包括像与Docker编排平台，特别是与Mesos协同进行伸缩的服务治理，还需要更多的实践来支持。 总结 是否选用微服务架构，应当根据业务实际情况进行判断，切勿跟风为了微服务而微服务； 目前来看还没有微服务全栈框架，Spring Cloud也未必是最优方案，技术选型还是应当务实； 微服务架构下，对于业务的理解拆分、领域建模等提出了更高的要求，相比框架，它们才是微服务架构的基石； DevOps是微服务实践中的重要一环，不容小视。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"},{"name":"实践分享","slug":"实践分享","permalink":"http://blog.springcloud.cn/tags/实践分享/"}]},{"title":"Spring Cloud Eureka服务下线(Cancel)源码分析","slug":"sc/sc-eureka-cancle","date":"2016-11-19T06:00:00.000Z","updated":"2017-06-17T03:08:12.000Z","comments":true,"path":"sc/sc-eureka-cancle/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-cancle/","excerpt":"Cancel(服务下线)概述在Service Provider服务shut down的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务。 服务提供者端源码分析 在eureka-client-1.4.1中的com.netflix.discovery.DiscoveryClient中shutdown()的867行。","text":"Cancel(服务下线)概述在Service Provider服务shut down的时候，需要及时通知Eureka Server把自己剔除，从而避免客户端调用已经下线的服务。 服务提供者端源码分析 在eureka-client-1.4.1中的com.netflix.discovery.DiscoveryClient中shutdown()的867行。 123456789101112131415161718192021222324252627282930313233/** * Shuts down Eureka Client. Also sends a deregistration request to the * eureka server. */ @PreDestroy @Override public synchronized void shutdown() &#123; if (isShutdown.compareAndSet(false, true)) &#123; logger.info(\"Shutting down DiscoveryClient ...\"); if (statusChangeListener != null &amp;&amp; applicationInfoManager != null) &#123; applicationInfoManager.unregisterStatusChangeListener(statusChangeListener.getId()); &#125; cancelScheduledTasks(); // If APPINFO was registered if (applicationInfoManager != null &amp;&amp; clientConfig.shouldRegisterWithEureka()) &#123; applicationInfoManager.setInstanceStatus(InstanceStatus.DOWN); //调用下线接口 unregister(); &#125; if (eurekaTransport != null) &#123; eurekaTransport.shutdown(); &#125; heartbeatStalenessMonitor.shutdown(); registryStalenessMonitor.shutdown(); logger.info(\"Completed shut down of DiscoveryClient\"); &#125; &#125; Tips @PreDestroy注解或shutdown()的方法是服务下线的入口 在eureka-client-1.4.1中的com.netflix.discovery.DiscoveryClient中unregister（）的897行12345678910111213141516 /** * unregister w/ the eureka service. */ void unregister() &#123; // It can be null if shouldRegisterWithEureka == false if(eurekaTransport != null &amp;&amp; eurekaTransport.registrationClient != null) &#123; try &#123; logger.info(\"Unregistering ...\"); //发送服务下线请求 EurekaHttpResponse&lt;Void&gt; httpResponse = eurekaTransport.registrationClient.cancel(instanceInfo.getAppName(), instanceInfo.getId()); logger.info(PREFIX + appPathIdentifier + \" - deregister status: \" + httpResponse.getStatusCode()); &#125; catch (Exception e) &#123; logger.error(PREFIX + appPathIdentifier + \" - de-registration failed\" + e.getMessage(), e); &#125; &#125;&#125; Eureka Server服务下线实现细节 在com.netflix.eureka.resources.InstanceResource中的280行中的cancelLease()方法 123456789101112131415@DELETEpublic Response cancelLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) &#123; //调用cancel boolean isSuccess = registry.cancel(app.getName(), id, \"true\".equals(isReplication)); if (isSuccess) &#123; logger.debug(\"Found (Cancel): \" + app.getName() + \" - \" + id); return Response.ok().build(); &#125; else &#123; logger.info(\"Not Found (Cancel): \" + app.getName() + \" - \" + id); return Response.status(Status.NOT_FOUND).build(); &#125;&#125; 在org.springframework.cloud.netflix.eureka.server.InstanceRegistry中的95行的cancel()方法， 123456@Overridepublic boolean cancel(String appName, String serverId, boolean isReplication) &#123; handleCancelation(appName, serverId, isReplication); //调用父类中的cancel return super.cancel(appName, serverId, isReplication);&#125; 在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的376行 123456789101112131415161718 @Override public boolean cancel(final String appName, final String id, final boolean isReplication) &#123; if (super.cancel(appName, id, isReplication)) &#123; //服务下线成功后，同步更新信息到其它Eureka Server节点 replicateToPeers(Action.Cancel, appName, id, null, null, isReplication); synchronized (lock) &#123; if (this.expectedNumberOfRenewsPerMin &gt; 0) &#123; // Since the client wants to cancel it, reduce the threshold (1 for 30 seconds, 2 for a minute) this.expectedNumberOfRenewsPerMin = this.expectedNumberOfRenewsPerMin - 2; this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfRenewsPerMin * serverConfig.getRenewalPercentThreshold()); &#125; &#125; return true; &#125; return false;&#125; 4.在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的618行，主要接口实现方式和register基本一致：首先更新自身Eureka Server中服务的状态，再同步到其它Eureka Server中。12345678910111213141516171819202122232425private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) &#123; Stopwatch tracer = action.getTimer().start(); try &#123; if (isReplication) &#123; numberOfReplicationsLastMin.increment(); &#125; // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) &#123; return; &#125; // 同步把服务信息同步到其它的Eureka Server中 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) &#123; // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) &#123; continue; &#125; //根据action做相应操作的同步 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); &#125; &#125; finally &#123; tracer.stop(); &#125; &#125; 至此，Eureka服务续约源码分析结束，大家有兴趣可自行阅读。 源码分析链接 其它源码分析链接: Spring Cloud中@EnableEurekaClient源码分析: http://blog.xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://blog.xujin.org/sc/sc-eureka-register/ Spring Cloud Eureka服务续约(Renew)源码分析 http://blog.xujin.org/sc/sc-eureka-renew/","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"},{"name":"Spring Cloud 源码分析","slug":"Spring-Cloud-源码分析","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-源码分析/"}]},{"title":"Spring Cloud Eureka服务续约(Renew)源码分析","slug":"sc/sc-eureka-renew","date":"2016-11-13T06:00:00.000Z","updated":"2017-06-17T03:26:16.000Z","comments":true,"path":"sc/sc-eureka-renew/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-renew/","excerpt":"Renew(服务续约)概述Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。目的是隔一段时间Service Provider调用接口，告诉Eureka Server它还活着没挂，不要把它T了。通俗的说就是它们两之间的心跳检测，避免服务提供者被剔除掉。请参考:Spring Cloud Eureka名词解释","text":"Renew(服务续约)概述Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。目的是隔一段时间Service Provider调用接口，告诉Eureka Server它还活着没挂，不要把它T了。通俗的说就是它们两之间的心跳检测，避免服务提供者被剔除掉。请参考:Spring Cloud Eureka名词解释 服务续约配置 Renew操作会在Service Provider定时发起，用来通知Eureka Server自己还活着。 这里有两个比较重要的配置需要如下，可以在Run之前配置。1eureka.instance.leaseRenewalIntervalInSeconds Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。1eureka.instance.leaseExpirationDurationInSeconds 服务失效时间。默认是90秒，也就是如果Eureka Server在90秒内没有接收到来自Service Provider的Renew操作，就会把Service Provider剔除。 Renew源码分析服务提供者实现细节 服务提供者发发起服务续约的时序图，如下图所示,大家先直观的看一下时序图，等阅读完源码再回顾一下。 在com.netflix.discovery.DiscoveryClient.initScheduledTasks()中的1272行，TimedSupervisorTask会定时发起服务续约，代码如下所示:123456789101112// Heartbeat timer scheduler.schedule( new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); 2.在com.netflix.discovery.DiscoveryClient中的1393行，有一个HeartbeatThread线程发起续约操作123456789 private class HeartbeatThread implements Runnable &#123; public void run() &#123; //调用eureka-client中的renew if (renew()) &#123; lastSuccessfulHeartbeatTimestamp = System.currentTimeMillis(); &#125; &#125;&#125; renew()调用eureka-client-1.4.11.jarcom.netflix.discovery.DiscoveryClient中829行renew()发起PUT Reset请求，调用com.netflix.eureka.resources.InstanceResource中的renewLease()续约。12345678910111213141516171819/** * Renew with the eureka service by making the appropriate REST call */ boolean renew() &#123; EurekaHttpResponse&lt;InstanceInfo&gt; httpResponse; try &#123; httpResponse = eurekaTransport.registrationClient.sendHeartBeat(instanceInfo.getAppName(), instanceInfo.getId(), instanceInfo, null); logger.debug(\"&#123;&#125; - Heartbeat status: &#123;&#125;\", PREFIX + appPathIdentifier, httpResponse.getStatusCode()); if (httpResponse.getStatusCode() == 404) &#123; REREGISTER_COUNTER.increment(); logger.info(\"&#123;&#125; - Re-registering apps/&#123;&#125;\", PREFIX + appPathIdentifier, instanceInfo.getAppName()); return register(); &#125; return httpResponse.getStatusCode() == 200; &#125; catch (Throwable e) &#123; logger.error(\"&#123;&#125; - was unable to send heartbeat!\", PREFIX + appPathIdentifier, e); return false; &#125; &#125; Netflix中的Eureka Core实现细节 NetFlix中Eureka Core中的服务续约时序图，如下图所示。 打开com.netflix.eureka.resources.InstanceResource中的106行的renewLease()方法，代码如下: 123456789101112private final PeerAwareInstanceRegistry registry@PUTpublic Response renewLease( @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication, @QueryParam(\"overriddenstatus\") String overriddenStatus, @QueryParam(\"status\") String status, @QueryParam(\"lastDirtyTimestamp\") String lastDirtyTimestamp) &#123; boolean isFromReplicaNode = \"true\".equals(isReplication); //调用 boolean isSuccess = registry.renew(app.getName(), id, isFromReplicaNode); //其余省略&#125; 点开registry.renew(app.getName(), id, isFromReplicaNode);我们可以看到，调用了org.springframework.cloud.netflix.eureka.server.InstanceRegistry中的renew（）方法，代码如下: 1234567891011121314151617181920212223 @Override public boolean renew(final String appName, final String serverId, boolean isReplication) &#123; log(\"renew \" + appName + \" serverId \" + serverId + \", isReplication &#123;&#125;\" + isReplication); List&lt;Application&gt; applications = getSortedApplications(); for (Application input : applications) &#123; if (input.getName().equals(appName)) &#123; InstanceInfo instance = null; for (InstanceInfo info : input.getInstances()) &#123; if (info.getHostName().equals(serverId)) &#123; instance = info; break; &#125; &#125; publishEvent(new EurekaInstanceRenewedEvent(this, appName, serverId, instance, isReplication)); break; &#125; &#125; //调用com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的renew方法 return super.renew(appName, serverId, isReplication);&#125; 3.从super.renew()看到调用了父类中的com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中420行的renew()方法，代码如下:123456789 public boolean renew(final String appName, final String id, final boolean isReplication) &#123; //服务续约成功， if (super.renew(appName, id, isReplication)) &#123; //然后replicateToPeers同步其它Eureka Server中的数据 replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication); return true; &#125; return false;&#125; 3.1 从上面代码中super.renew(appName, id, isReplication)可以看出调用的是com.netflix.eureka.registry.AbstractInstanceRegistry中345行的renew()方法，代码如下所示12345678910111213141516171819202122232425262728293031323334353637383940public boolean renew(String appName, String id, boolean isReplication) &#123; RENEW.increment(isReplication); Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(appName); Lease&lt;InstanceInfo&gt; leaseToRenew = null; if (gMap != null) &#123; leaseToRenew = gMap.get(id); &#125; if (leaseToRenew == null) &#123; RENEW_NOT_FOUND.increment(isReplication); logger.warn(\"DS: Registry: lease doesn't exist, registering resource: &#123;&#125; - &#123;&#125;\", appName, id); return false; &#125; else &#123; InstanceInfo instanceInfo = leaseToRenew.getHolder(); if (instanceInfo != null) &#123; // touchASGCache(instanceInfo.getASGName()); InstanceStatus overriddenInstanceStatus = this.getOverriddenInstanceStatus( instanceInfo, leaseToRenew, isReplication); if (overriddenInstanceStatus == InstanceStatus.UNKNOWN) &#123; logger.info(\"Instance status UNKNOWN possibly due to deleted override for instance &#123;&#125;\" + \"; re-register required\", instanceInfo.getId()); RENEW_NOT_FOUND.increment(isReplication); return false; &#125; if (!instanceInfo.getStatus().equals(overriddenInstanceStatus)) &#123; Object[] args = &#123; instanceInfo.getStatus().name(), instanceInfo.getOverriddenStatus().name(), instanceInfo.getId() &#125;; logger.info( \"The instance status &#123;&#125; is different from overridden instance status &#123;&#125; for instance &#123;&#125;. \" + \"Hence setting the status to overridden status\", args); instanceInfo.setStatus(overriddenInstanceStatus); &#125; &#125; renewsLastMin.increment(); leaseToRenew.renew(); return true; &#125; &#125; 其中 leaseToRenew.renew()是调用com.netflix.eureka.lease.Lease中的62行的renew()方法123456789/** * Renew the lease, use renewal duration if it was specified by the * associated &#123;@link T&#125; during registration, otherwise default duration is * &#123;@link #DEFAULT_DURATION_IN_SECS&#125;. */public void renew() &#123; lastUpdateTimestamp = System.currentTimeMillis() + duration;&#125; 3.2 replicateToPeers(Action.Heartbeat, appName, id, null, null, isReplication);调用自身的replicateToPeers()方法，在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl中的618行，主要接口实现方式和register基本一致：首先更新自身Eureka Server中服务的状态，再同步到其它Eureka Server中。12345678910111213141516171819202122232425private void replicateToPeers(Action action, String appName, String id, InstanceInfo info /* optional */, InstanceStatus newStatus /* optional */, boolean isReplication) &#123; Stopwatch tracer = action.getTimer().start(); try &#123; if (isReplication) &#123; numberOfReplicationsLastMin.increment(); &#125; // If it is a replication already, do not replicate again as this will create a poison replication if (peerEurekaNodes == Collections.EMPTY_LIST || isReplication) &#123; return; &#125; // 同步把续约信息同步到其它的Eureka Server中 for (final PeerEurekaNode node : peerEurekaNodes.getPeerEurekaNodes()) &#123; // If the url represents this host, do not replicate to yourself. if (peerEurekaNodes.isThisMyUrl(node.getServiceUrl())) &#123; continue; &#125; //根据action做相应操作的同步 replicateInstanceActionsToPeers(action, appName, id, info, newStatus, node); &#125; &#125; finally &#123; tracer.stop(); &#125; &#125; 至此，Eureka服务续约源码分析结束，大家有兴趣可自行阅读。 源码分析链接 其它源码分析链接: Spring Cloud中@EnableEurekaClient源码分析: http://blog.xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://blog.xujin.org/sc/sc-eureka-register/","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"},{"name":"Spring Cloud 源码分析","slug":"Spring-Cloud-源码分析","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-源码分析/"}]},{"title":"Spring Cloud中@EnableEurekaClient源码分析","slug":"sc/sc-enableEurekaClient-annonation","date":"2016-11-06T06:00:00.000Z","updated":"2017-06-17T03:02:45.000Z","comments":true,"path":"sc/sc-enableEurekaClient-annonation/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-enableEurekaClient-annonation/","excerpt":"NetFlix Eureka client简介NetFlix Eureka clientEureka client 负责与Eureka Server 配合向外提供注册与发现服务接口。首先看下eureka client是怎么定义，Netflix的 eureka client的行为在LookupService中定义，Lookup service for finding active instances，定义了，从outline中能看到起“规定”了如下几个最基本的方法。服务发现必须实现的基本类：com.netflix.discovery.shared.LookupService，可以自行查看源码。 Eureka client与Spring Cloud类关系 Eureka client与Spring Cloud Eureka Client类图，如下所示:在上图中，我加了前缀，带有S的是Spring Cloud封装的，带有N是NetFlix原生的。","text":"NetFlix Eureka client简介NetFlix Eureka clientEureka client 负责与Eureka Server 配合向外提供注册与发现服务接口。首先看下eureka client是怎么定义，Netflix的 eureka client的行为在LookupService中定义，Lookup service for finding active instances，定义了，从outline中能看到起“规定”了如下几个最基本的方法。服务发现必须实现的基本类：com.netflix.discovery.shared.LookupService，可以自行查看源码。 Eureka client与Spring Cloud类关系 Eureka client与Spring Cloud Eureka Client类图，如下所示:在上图中，我加了前缀，带有S的是Spring Cloud封装的，带有N是NetFlix原生的。 org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient中49行的eurekaClient就是com.netflix.discovery.EurekaClient，代码如下所示:12345678@RequiredArgsConstructorpublic class EurekaDiscoveryClient implements DiscoveryClient &#123; public static final String DESCRIPTION = \"Spring Cloud Eureka Discovery Client\"; private final EurekaInstanceConfig config; // Netflix中的Eureka Client private final EurekaClient eurekaClient; //其余省略&#125; Tips:org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient实现了DiscoveryClient，并依赖于com.netflix.discovery.EurekaClient 点开com.netflix.discovery.EurekaClient查看代码，可以看出EurekaClient继承了LookupService并实现了EurekaClient接口。 1234@ImplementedBy(DiscoveryClient.class)public interface EurekaClient extends LookupService &#123; //其余省略&#125; com.netflix.discovery.DiscoveryClient是netflix使用的客户端，从其class的注释可以看到他主要做这几件事情：a) Registering the instance with Eureka Serverb) Renewalof the lease with Eureka Serverc) Cancellation of the lease from Eureka Server during shutdown 其中com.netflix.discovery.DiscoveryClient实现了com.netflix.discovery.EurekaClient,而spring Cloud中的org.springframework.cloud.netflix.eureka.EurekaDiscoveryClient，依赖于com.netflix.discovery.EurekaClient，因此Spring Cloud与NetFlix的关系由此联系到一起。12345678@Singletonpublic class DiscoveryClient implements EurekaClient &#123; private static final Logger logger = LoggerFactory.getLogger(DiscoveryClient.class); // Constants public static final String HTTP_X_DISCOVERY_ALLOW_REDIRECT = \"X-Discovery-AllowRedirect\"; //其余省略&#125; @EnableEurekaClient注解入口分析 在上面小节中，理清了NetFlix Eureka与Spring cloud中类的依赖关系，下面将以@EnableEurekaClient为入口，分析主要调用链中的类和方法。 @EnableEurekaClient使用 用过spring cloud的同学都知道，使用@EnableEurekaClient就能简单的开启Eureka Client中的功能，如下代码所示。123456789@EnableEurekaClient@SpringBootApplicationpublic class CloudEurekaClientApplication &#123; public static void main(String[] args) &#123; new SpringApplicationBuilder(CloudEurekaClientApplication.class).web(true).run(args); &#125;&#125; 通过@EnableEurekaClient这个简单的注解，在spring cloud应用启动的时候，就可以把EurekaDiscoveryClient注入，继而使用NetFlix提供的Eureka client。 打开EnableEurekaClient这个类，可以看到这个自定义的annotation @EnableEurekaClient里面没有内容。它的作用就是开启Eureka discovery的配置，正是通过这个标记，autoconfiguration就可以加载相关的Eureka类。那我们看下它是怎么做到的。 12345678@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@EnableDiscoveryClientpublic @interface EnableEurekaClient &#123;&#125; 在上述代码中，我们看到，EnableEurekaClient上面加入了另外一个注解@EnableDiscoveryClient，看看这个注解的代码如下所示: 123456789101112/** * Annotation to enable a DiscoveryClient implementation. * @author Spencer Gibb */@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@Import(EnableDiscoveryClientImportSelector.class)public @interface EnableDiscoveryClient &#123;&#125; 这个注解import了EnableDiscoveryClientImportSelector.class这样一个类，其实就是通过这个类来加载需要用到的bean。点开EnableDiscoveryClientImportSelector类，如下代码: 12345678910111213141516@Order(Ordered.LOWEST_PRECEDENCE - 100)public class EnableDiscoveryClientImportSelector extends SpringFactoryImportSelector&lt;EnableDiscoveryClient&gt; &#123; @Override protected boolean isEnabled() &#123; return new RelaxedPropertyResolver(getEnvironment()).getProperty( \"spring.cloud.discovery.enabled\", Boolean.class, Boolean.TRUE); &#125; @Override protected boolean hasDefaultFactory() &#123; return true; &#125;&#125; 看到这里有覆盖了父类SpringFactoryImportSelector的一个方法isEnabled，注意，默认是TRUE，也就是只要import了这个配置，就会enable。 在其父类org.springframework.cloud.commons.util.SpringFactoryImportSelector的String[] selectImports(AnnotationMetadata metadata)方法中正是根据这个标记类判定是否加载如下定义的类。在源码第59行，局部代码如下所示。1234567891011121314151617181920212223242526272829@Override public String[] selectImports(AnnotationMetadata metadata) &#123; if (!isEnabled()) &#123; return new String[0]; &#125; AnnotationAttributes attributes = AnnotationAttributes.fromMap( metadata.getAnnotationAttributes(this.annotationClass.getName(), true)); Assert.notNull(attributes, \"No \" + getSimpleName() + \" attributes found. Is \" + metadata.getClassName() + \" annotated with @\" + getSimpleName() + \"?\"); // Find all possible auto configuration classes, filtering duplicates List&lt;String&gt; factories = new ArrayList&lt;&gt;(new LinkedHashSet&lt;&gt;(SpringFactoriesLoader .loadFactoryNames(this.annotationClass, this.beanClassLoader))); if (factories.isEmpty() &amp;&amp; !hasDefaultFactory()) &#123; throw new IllegalStateException(\"Annotation @\" + getSimpleName() + \" found, but there are no implementations. Did you forget to include a starter?\"); &#125; if (factories.size() &gt; 1) &#123; // there should only ever be one DiscoveryClient, but there might be more than // one factory log.warn(\"More than one implementation \" + \"of @\" + getSimpleName() + \" (now relying on @Conditionals to pick one): \" + factories); &#125; return factories.toArray(new String[factories.size()]); &#125; 在源码中70-71行，即在org.springframework.core.io.support.SpringFactoriesLoader 中的109行的loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader)方法12345678910111213141516171819 public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); List&lt;String&gt; result = new ArrayList&lt;String&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); Properties properties = PropertiesLoaderUtils.loadProperties(new UrlResource(url)); String factoryClassNames = properties.getProperty(factoryClassName); result.addAll(Arrays.asList(StringUtils.commaDelimitedListToStringArray(factoryClassNames))); &#125; return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException(\"Unable to load [\" + factoryClass.getName() + \"] factories from location [\" + FACTORIES_RESOURCE_LOCATION + \"]\", ex); &#125;&#125; 实际调用loadFactoryNames其实加载META-INF/spring.factories下的class。12345 /*** The location to look for factories.* &lt;p&gt;Can be present in multiple JAR files. */ public static final String FACTORIES_RESOURCE_LOCATION = \"META-INF/spring.factories\"; 而在spring-cloud-netflix-eureka-client\\src\\main\\resources\\META-INF\\spring.factories中配置，用于加载一系列配置信息和Dependences Bean可以看到EnableAutoConfiguration的包含了EurekaClientConfigServerAutoConfiguration。1234567891011org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration,\\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceAutoConfiguration,\\org.springframework.cloud.netflix.eureka.EurekaClientAutoConfiguration,\\org.springframework.cloud.netflix.ribbon.eureka.RibbonEurekaAutoConfigurationorg.springframework.cloud.bootstrap.BootstrapConfiguration=\\org.springframework.cloud.netflix.eureka.config.EurekaDiscoveryClientConfigServiceBootstrapConfigurationorg.springframework.cloud.client.discovery.EnableDiscoveryClient=\\org.springframework.cloud.netflix.eureka.EurekaDiscoveryClientConfiguration 打开org.springframework.cloud.netflix.eureka.config.EurekaClientConfigServerAutoConfiguration可以看到EurekaClientAutoConfiguration具体的注入信息。 具体@EnableEurekaClien注解开启之后，服务启动后，是服务怎么注册的请参考，下面链接：http://blog.xujin.org/sc/sc-eureka-register/ 其它源码分析链接 Spring Cloud中@EnableEurekaClient源码分析: http://blog.xujin.org/sc/sc-enableEurekaClient-annonation/ Spring Cloud Eureka服务注册源码分析： http://blog.xujin.org/sc/sc-eureka-register/ Spring Cloud Eureka服务续约(Renew)源码分析 http://blog.xujin.org/sc/sc-eureka-renew/ Spring Cloud Eureka服务下线(Cancel)源码分析 http://blog.xujin.org/sc/sc-eureka-cancle/","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"},{"name":"Spring Cloud 源码分析","slug":"Spring-Cloud-源码分析","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-源码分析/"}]},{"title":"Spring Cloud Eureka服务注册源码分析","slug":"sc/sc-eureka-register","date":"2016-11-01T06:00:00.000Z","updated":"2017-06-17T03:19:51.000Z","comments":true,"path":"sc/sc-eureka-register/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-register/","excerpt":"摘要:在上一篇中，介绍了Eureka的相关的知识，解释了Eureka为什么适合做服务发现和注册。接下来，在本篇文章将通过源码分析的方式，看一下Eureka是怎么work的。本章主要介绍Eureka的服务注册。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出Eureka Client的定时任务调用Eureka Server的Reset接口，而Eureka接收到调用请求后会处理服务的注册以及Eureka Server中的数据同步的问题。 服务注册 服务注册，想必大家并不陌生，就是服务提供者启动的时候，把自己提供的服务信息，例如 服务名，IP，端口号，版本号等信息注册到注册中心，比如注册到ZK中。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出服务注册可以认为是Eureka client自己完成，不需要服务本身来关心。 Eureka Client的定时任务调用Eureka Server的提供接口实现思路其实也挺简单，在com.netflix.discovery.DiscoveryClient启动的时候，会初始化一个定时任务，定时的把本地的服务配置信息，即需要注册到远端的服务信息自动刷新到注册服务器上。首先看一下Eureka的代码，在spring-cloud-netflix-eureka-server工程中可以找到这个依赖eureka-client-1.4.11.jar查看代码可以看到，com.netflix.discovery.DiscoveryClient.java中的1240行可以看到Initializes all scheduled tasks，在1277行，可以看到InstanceInfoReplicator定时任务。","text":"摘要:在上一篇中，介绍了Eureka的相关的知识，解释了Eureka为什么适合做服务发现和注册。接下来，在本篇文章将通过源码分析的方式，看一下Eureka是怎么work的。本章主要介绍Eureka的服务注册。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出Eureka Client的定时任务调用Eureka Server的Reset接口，而Eureka接收到调用请求后会处理服务的注册以及Eureka Server中的数据同步的问题。 服务注册 服务注册，想必大家并不陌生，就是服务提供者启动的时候，把自己提供的服务信息，例如 服务名，IP，端口号，版本号等信息注册到注册中心，比如注册到ZK中。那eureka client如何将本地服务的注册信息发送到远端的注册服务器eureka server上。通过下面的源码分析，看出服务注册可以认为是Eureka client自己完成，不需要服务本身来关心。 Eureka Client的定时任务调用Eureka Server的提供接口实现思路其实也挺简单，在com.netflix.discovery.DiscoveryClient启动的时候，会初始化一个定时任务，定时的把本地的服务配置信息，即需要注册到远端的服务信息自动刷新到注册服务器上。首先看一下Eureka的代码，在spring-cloud-netflix-eureka-server工程中可以找到这个依赖eureka-client-1.4.11.jar查看代码可以看到，com.netflix.discovery.DiscoveryClient.java中的1240行可以看到Initializes all scheduled tasks，在1277行，可以看到InstanceInfoReplicator定时任务。 在DiscoveryClient中初始化一个InstanceInfoReplicator，其实里面封装了以定时任务。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475/** * Initializes all scheduled tasks. */ private void initScheduledTasks() &#123; if (clientConfig.shouldFetchRegistry()) &#123; // registry cache refresh timer int registryFetchIntervalSeconds = clientConfig.getRegistryFetchIntervalSeconds(); int expBackOffBound = clientConfig.getCacheRefreshExecutorExponentialBackOffBound(); scheduler.schedule( new TimedSupervisorTask( \"cacheRefresh\", scheduler, cacheRefreshExecutor, registryFetchIntervalSeconds, TimeUnit.SECONDS, expBackOffBound, new CacheRefreshThread() ), registryFetchIntervalSeconds, TimeUnit.SECONDS); &#125; if (clientConfig.shouldRegisterWithEureka()) &#123; int renewalIntervalInSecs = instanceInfo.getLeaseInfo().getRenewalIntervalInSecs(); int expBackOffBound = clientConfig.getHeartbeatExecutorExponentialBackOffBound(); logger.info(\"Starting heartbeat executor: \" + \"renew interval is: \" + renewalIntervalInSecs); // Heartbeat timer scheduler.schedule( new TimedSupervisorTask( \"heartbeat\", scheduler, heartbeatExecutor, renewalIntervalInSecs, TimeUnit.SECONDS, expBackOffBound, new HeartbeatThread() ), renewalIntervalInSecs, TimeUnit.SECONDS); // InstanceInfo replicator /**************************封装了定时任务**********************************/ instanceInfoReplicator = new InstanceInfoReplicator( this, instanceInfo, clientConfig.getInstanceInfoReplicationIntervalSeconds(), 2); // burstSize statusChangeListener = new ApplicationInfoManager.StatusChangeListener() &#123; @Override public String getId() &#123; return \"statusChangeListener\"; &#125; @Override public void notify(StatusChangeEvent statusChangeEvent) &#123; if (InstanceStatus.DOWN == statusChangeEvent.getStatus() || InstanceStatus.DOWN == statusChangeEvent.getPreviousStatus()) &#123; // log at warn level if DOWN was involved logger.warn(\"Saw local status change event &#123;&#125;\", statusChangeEvent); &#125; else &#123; logger.info(\"Saw local status change event &#123;&#125;\", statusChangeEvent); &#125; instanceInfoReplicator.onDemandUpdate(); &#125; &#125;; if (clientConfig.shouldOnDemandUpdateStatusChange()) &#123; applicationInfoManager.registerStatusChangeListener(statusChangeListener); &#125; //点击可以查看start方法 instanceInfoReplicator.start(clientConfig.getInitialInstanceInfoReplicationIntervalSeconds()); &#125; else &#123; logger.info(\"Not registering with Eureka server per configuration\"); &#125; &#125; 2.以initialDelayMs为间隔调用。1234567public void start(int initialDelayMs) &#123; if (started.compareAndSet(false, true)) &#123; instanceInfo.setIsDirty(); // for initial register Future next = scheduler.schedule(this, initialDelayMs, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); &#125;&#125; 3.ScheduledExecutorService的task的具体业务定义在com.netflix.discovery.InstanceInfoReplicator.run()中，也就是InstanceInfoReplicator中的98-113行，可以看到调用了了client的register方法。1234567891011121314151617 public void run() &#123; try &#123; discoveryClient.refreshInstanceInfo(); Long dirtyTimestamp = instanceInfo.isDirtyWithTime(); if (dirtyTimestamp != null) &#123; //客户端发送hhtp注册请求的真正入口 discoveryClient.register(); instanceInfo.unsetIsDirty(dirtyTimestamp); &#125; &#125; catch (Throwable t) &#123; logger.warn(\"There was a problem with the instance info replicator\", t); &#125; finally &#123; Future next = scheduler.schedule(this, replicationIntervalSeconds, TimeUnit.SECONDS); scheduledPeriodicRef.set(next); &#125;&#125; 4.com.netflix.discovery.DiscoveryClient中的 register()方法，大概在811行。123456789101112131415161718/** * Register with the eureka service by making the appropriate REST call. */boolean register() throws Throwable &#123; logger.info(PREFIX + appPathIdentifier + \": registering service...\"); EurekaHttpResponse&lt;Void&gt; httpResponse; try &#123; //Eureka Client客户端，调用Eureka服务端的入口 httpResponse = eurekaTransport.registrationClient.register(instanceInfo); &#125; catch (Exception e) &#123; logger.warn(\"&#123;&#125; - registration failed &#123;&#125;\", PREFIX + appPathIdentifier, e.getMessage(), e); throw e; &#125; if (logger.isInfoEnabled()) &#123; logger.info(\"&#123;&#125; - registration status: &#123;&#125;\", PREFIX + appPathIdentifier, httpResponse.getStatusCode()); &#125; return httpResponse.getStatusCode() == 204;&#125; Eureka server端接到请求后的处理打开spring-cloud-netflix-eureka-server工程或spring-cloud-netflix-eureka-client过程，找到相应的maven依赖jar，如下图所示 1.Eureka server服务端请求入口ApplicationResource.java文件中第183行，如下所示，可以看出Eureka是通过http post的方式去服务注册1234567891011121314151617181920212223242526272829303132333435363738394041424344@POST @Consumes(&#123;\"application/json\", \"application/xml\"&#125;) public Response addInstance(InstanceInfo info, @HeaderParam(PeerEurekaNode.HEADER_REPLICATION) String isReplication) &#123; logger.debug(\"Registering instance &#123;&#125; (replication=&#123;&#125;)\", info.getId(), isReplication); // validate that the instanceinfo contains all the necessary required fields if (isBlank(info.getId())) &#123; return Response.status(400).entity(\"Missing instanceId\").build(); &#125; else if (isBlank(info.getHostName())) &#123; return Response.status(400).entity(\"Missing hostname\").build(); &#125; else if (isBlank(info.getAppName())) &#123; return Response.status(400).entity(\"Missing appName\").build(); &#125; else if (!appName.equals(info.getAppName())) &#123; return Response.status(400).entity(\"Mismatched appName, expecting \" + appName + \" but was \" + info.getAppName()).build(); &#125; else if (info.getDataCenterInfo() == null) &#123; return Response.status(400).entity(\"Missing dataCenterInfo\").build(); &#125; else if (info.getDataCenterInfo().getName() == null) &#123; return Response.status(400).entity(\"Missing dataCenterInfo Name\").build(); &#125; // handle cases where clients may be registering with bad DataCenterInfo with missing data DataCenterInfo dataCenterInfo = info.getDataCenterInfo(); if (dataCenterInfo instanceof UniqueIdentifier) &#123; String dataCenterInfoId = ((UniqueIdentifier) dataCenterInfo).getId(); if (isBlank(dataCenterInfoId)) &#123; boolean experimental = \"true\".equalsIgnoreCase(serverConfig.getExperimental(\"registration.validation.dataCenterInfoId\")); if (experimental) &#123; String entity = \"DataCenterInfo of type \" + dataCenterInfo.getClass() + \" must contain a valid id\"; return Response.status(400).entity(entity).build(); &#125; else if (dataCenterInfo instanceof AmazonInfo) &#123; AmazonInfo amazonInfo = (AmazonInfo) dataCenterInfo; String effectiveId = amazonInfo.get(AmazonInfo.MetaDataKey.instanceId); if (effectiveId == null) &#123; amazonInfo.getMetadata().put(AmazonInfo.MetaDataKey.instanceId.getName(), info.getId()); &#125; &#125; else &#123; logger.warn(\"Registering DataCenterInfo of type &#123;&#125; without an appropriate id\", dataCenterInfo.getClass()); &#125; &#125; &#125; //InstanceRegistry.java文件中的88行的405行register方法 registry.register(info, \"true\".equals(isReplication)); return Response.status(204).build(); // 204 to be backwards compatible &#125; 2.如下图所示可以看到，从ApplicationResource.java怎么进入到PeerAwareInstanceRegistryImpl中的register方法InstanceRegistry.java文件中的88行，可以看到调用PeerAwareInstanceRegistryImpl中的405行register方法123456@Overridepublic void register(final InstanceInfo info, final boolean isReplication) &#123; handleRegistration(info, resolveInstanceLeaseDuration(info), isReplication); //调用PeerAwareInstanceRegistryImpl中的405行register方法 super.register(info, isReplication); &#125; 3.PeerAwareInstanceRegistryImpl中的405行register方法，代码如下所示。阅读方法上面的注释，就知道该方法是注册服务信息并把Eureka Server中的配置信息同步。执行注册的动作在com.netflix.eureka.registry.PeerAwareInstanceRegistryImpl.register(InstanceInfo info, boolean isReplication)中，具体代码如下所示： 12345678910111213141516171819202122/** * Registers the information about the &#123;@link InstanceInfo&#125; and replicates * this information to all peer eureka nodes. If this is replication event * from other replica nodes then it is not replicated. * * @param info * the &#123;@link InstanceInfo&#125; to be registered and replicated. * @param isReplication * true if this is a replication event from other replica nodes, * false otherwise. */ @Override public void register(final InstanceInfo info, final boolean isReplication) &#123; int leaseDuration = Lease.DEFAULT_DURATION_IN_SECS; if (info.getLeaseInfo() != null &amp;&amp; info.getLeaseInfo().getDurationInSecs() &gt; 0) &#123; leaseDuration = info.getLeaseInfo().getDurationInSecs(); &#125; //调用父类方法注册 super.register(info, leaseDuration, isReplication); // 同步Eureka中的服务信息 replicateToPeers(Action.Register, info.getAppName(), info.getId(), info, null, isReplication); &#125; 4.AbstractInstanceRegistry.java中192行，可以看到Eureka真正的服务注册实现的代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586/** * Registers a new instance with a given duration. * * @see com.netflix.eureka.lease.LeaseManager#register(java.lang.Object, int, boolean) */ public void register(InstanceInfo registrant, int leaseDuration, boolean isReplication) &#123; try &#123; read.lock(); Map&lt;String, Lease&lt;InstanceInfo&gt;&gt; gMap = registry.get(registrant.getAppName()); REGISTER.increment(isReplication); if (gMap == null) &#123; final ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt; gNewMap = new ConcurrentHashMap&lt;String, Lease&lt;InstanceInfo&gt;&gt;(); gMap = registry.putIfAbsent(registrant.getAppName(), gNewMap); if (gMap == null) &#123; gMap = gNewMap; &#125; &#125; Lease&lt;InstanceInfo&gt; existingLease = gMap.get(registrant.getId()); // Retain the last dirty timestamp without overwriting it, if there is already a lease if (existingLease != null &amp;&amp; (existingLease.getHolder() != null)) &#123; Long existingLastDirtyTimestamp = existingLease.getHolder().getLastDirtyTimestamp(); Long registrationLastDirtyTimestamp = registrant.getLastDirtyTimestamp(); logger.debug(\"Existing lease found (existing=&#123;&#125;, provided=&#123;&#125;\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); if (existingLastDirtyTimestamp &gt; registrationLastDirtyTimestamp) &#123; logger.warn(\"There is an existing lease and the existing lease's dirty timestamp &#123;&#125; is greater\" + \" than the one that is being registered &#123;&#125;\", existingLastDirtyTimestamp, registrationLastDirtyTimestamp); logger.warn(\"Using the existing instanceInfo instead of the new instanceInfo as the registrant\"); registrant = existingLease.getHolder(); &#125; &#125; else &#123; // The lease does not exist and hence it is a new registration synchronized (lock) &#123; if (this.expectedNumberOfRenewsPerMin &gt; 0) &#123; // Since the client wants to cancel it, reduce the threshold // (1 // for 30 seconds, 2 for a minute) this.expectedNumberOfRenewsPerMin = this.expectedNumberOfRenewsPerMin + 2; this.numberOfRenewsPerMinThreshold = (int) (this.expectedNumberOfRenewsPerMin * serverConfig.getRenewalPercentThreshold()); &#125; &#125; logger.debug(\"No previous lease information found; it is new registration\"); &#125; Lease&lt;InstanceInfo&gt; lease = new Lease&lt;InstanceInfo&gt;(registrant, leaseDuration); if (existingLease != null) &#123; lease.setServiceUpTimestamp(existingLease.getServiceUpTimestamp()); &#125; gMap.put(registrant.getId(), lease); synchronized (recentRegisteredQueue) &#123; recentRegisteredQueue.add(new Pair&lt;Long, String&gt;( System.currentTimeMillis(), registrant.getAppName() + \"(\" + registrant.getId() + \")\")); &#125; // This is where the initial state transfer of overridden status happens if (!InstanceStatus.UNKNOWN.equals(registrant.getOverriddenStatus())) &#123; logger.debug(\"Found overridden status &#123;&#125; for instance &#123;&#125;. Checking to see if needs to be add to the \" + \"overrides\", registrant.getOverriddenStatus(), registrant.getId()); if (!overriddenInstanceStatusMap.containsKey(registrant.getId())) &#123; logger.info(\"Not found overridden id &#123;&#125; and hence adding it\", registrant.getId()); overriddenInstanceStatusMap.put(registrant.getId(), registrant.getOverriddenStatus()); &#125; &#125; InstanceStatus overriddenStatusFromMap = overriddenInstanceStatusMap.get(registrant.getId()); if (overriddenStatusFromMap != null) &#123; logger.info(\"Storing overridden status &#123;&#125; from map\", overriddenStatusFromMap); registrant.setOverriddenStatus(overriddenStatusFromMap); &#125; // Set the status based on the overridden status rules InstanceStatus overriddenInstanceStatus = getOverriddenInstanceStatus(registrant, existingLease, isReplication); registrant.setStatusWithoutDirty(overriddenInstanceStatus); // If the lease is registered with UP status, set lease service up timestamp if (InstanceStatus.UP.equals(registrant.getStatus())) &#123; lease.serviceUp(); &#125; registrant.setActionType(ActionType.ADDED); recentlyChangedQueue.add(new RecentlyChangedItem(lease)); registrant.setLastUpdatedTimestamp(); invalidateCache(registrant.getAppName(), registrant.getVIPAddress(), registrant.getSecureVipAddress()); logger.info(\"Registered instance &#123;&#125;/&#123;&#125; with status &#123;&#125; (replication=&#123;&#125;)\", registrant.getAppName(), registrant.getId(), registrant.getStatus(), isReplication); &#125; finally &#123; read.unlock(); &#125; &#125; 说明:注册信息其实就是存储在一个 ConcurrentHashMap","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"},{"name":"Spring Cloud 源码分析","slug":"Spring-Cloud-源码分析","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-源码分析/"}]},{"title":"Spring Cloud Netflix之Eureka下篇原理","slug":"sc/sc-eureka-mid","date":"2016-10-25T06:00:00.000Z","updated":"2017-06-17T03:26:44.000Z","comments":true,"path":"sc/sc-eureka-mid/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-eureka-mid/","excerpt":"","text":"概述名词解释 Renew:我的理解是续约，为什么叫续约呢？Renew（服务续约）操作由Service Provider定期调用，类似于heartbeat。目的是隔一段时间Service Provider调用接口，告诉Eureka Server它还活着没挂，不要把它踢掉。通俗的说就是它们两之间的心跳检测，避免服务提供者被剔除掉。 Cancel（服务下线）一般在Service Provider挂了或shut down的时候调用，用来把自身的服务从Eureka Server中删除，以防客户端调用到不存在的服务。 Fetch Registries(获取注册信息)，Fetch Registries由Service Consumer(服务消费者)调用，用来获取Eureka Server上注册的服务info。 Eviction(剔除)Eviction（失效服务剔除）用来定期在Eureka Server检测失效的服务，检测标准就是超过一定时间没有Renew的服务。回顾Eureka架构图Eureka架构图Eureka架构图如下图所示，github地址:https://github.com/netflix/eurekadocument地址:https://github.com/Netflix/eureka/wiki/Eureka-at-a-glance&ensp; 从图中我们可以看出，Eureka 组件分为两部分：Eureka server和 Eureka client。而客户端又分为 Application Service 客户端和 Application Client 客户端两种。Eureka 的工作机制每个 region 都有自己的 Eureka 服务器集群，每个 zone 至少要有一个 Eureka 服务器以应对 zone 瘫痪。&ensp; Application Service 在启动时注册到 Eureka 服务器，之后每 30 秒钟发送心跳以更新自身状态,即Renew(续约)。如果该客户端没能发送心跳更新，它将在 90 秒之后被其注册的 Eureka 服务器剔除，即Eviction(剔除)。来自任意 zone 的 Application Client 可以获取这些注册信息(每隔 30 秒查看一次)并依此定位到在任何区域可以给自己提供服务的提供者(即Fetch Registries)，进而进行远程调用。 服务提供者本身携带的Eureka Client既能服务注册，服务续约，也能通过client定位服务和调用其它的服务。 服务注册服务注册 服务注册源码分析，请参考:http://blog.xujin.org/sc/sc-eureka-register/ Renew(服务续约)服务续约 Renew操作会在Service Provider端定期发起，用来通知Eureka Server自己还活着。 这里有两个比较重要的配置需要注意一下：1eureka.instance.leaseRenewalIntervalInSeconds Renew频率。默认是30秒，也就是每30秒会向Eureka Server发起Renew操作。1eureka.instance.leaseExpirationDurationInSeconds 服务失效时间。默认是90秒，也就是如果Eureka Server在90秒内没有接收到来自Service Provider的Renew操作，就会把Service Provider剔除。","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Eureka/"}]},{"title":"Spring Cloud Netflix之Eureka上篇","slug":"sc/sc-netflix-eureka","date":"2016-10-23T06:00:00.000Z","updated":"2017-06-17T03:25:26.000Z","comments":true,"path":"sc/sc-netflix-eureka/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-netflix-eureka/","excerpt":"前言:Spring Cloud NetFlix这个项目对NetFlix中一些久经考验靠谱的服务发现，熔断，网关，智能路由，以及负载均衡等做了封装，并通过注解的或简单配置的方式提供给Spring Cloud用户用。本文主要介绍 Spring Cloud中的Eureka组件。由于Spring Cloud做技术选型时中立的，因此Spring Cloud也提供了Spring Cloud Zookeeper,Spring Cloud Consul用于服务治理或服务发现供大家选择使用，另外我还发现Spring Cloud etcd这个项目，也可以用于服务注册和发现","text":"前言:Spring Cloud NetFlix这个项目对NetFlix中一些久经考验靠谱的服务发现，熔断，网关，智能路由，以及负载均衡等做了封装，并通过注解的或简单配置的方式提供给Spring Cloud用户用。本文主要介绍 Spring Cloud中的Eureka组件。由于Spring Cloud做技术选型时中立的，因此Spring Cloud也提供了Spring Cloud Zookeeper,Spring Cloud Consul用于服务治理或服务发现供大家选择使用，另外我还发现Spring Cloud etcd这个项目，也可以用于服务注册和发现 什么是 Spring Cloud Netflix ?其官方文档中对自己的定义是如下，官网连接,Github地址 This project provides Netflix OSS integrations for Spring Boot apps through autoconfiguration and binding to the Spring Environment and other Spring programming model idioms. With a few simple annotations you can quickly enable and configure the common patterns inside your application and build large distributed systems with battle-tested Netflix components. The patterns provided include Service Discovery (Eureka), Circuit Breaker (Hystrix), Intelligent Routing (Zuul) and Client Side Load Balancing (Ribbon). Spring Cloud Netflix这个项目对于Spring Boot应用来说，它集成了NetFlix OSS的一些组件，只需通过注解配置和Spring环境的通用简单的使用注解，你可以快速的启用和配置这些久经测试考验的NetFlix的组件于你的应用和用于构建分布式系统中。这些组件包含的功能有服务发现（Eureka），熔断器（Hystrix），智能路由(Zuul)以及客户端的负载均衡器（Ribbon） 简单的来说，Spring Cloud NetFlix这个项目对NetFlix中一些久经考验靠谱的服务发现，熔断，网关，智能路由，以及负载均衡等做了封装，并通过注解的或简单配置的方式提供给Spring Cloud用户用。 什么是 Eureka?官网定义是: Eureka is a REST (Representational State Transfer) based service that is primarily used in the AWS cloud for locating services for the purpose of load balancing and failover of middle-tier servers. We call this service, the Eureka Server. Eureka also comes with a Java-based client component,the Eureka Client, which makes interactions with the service much easier. The client also has a built-in load balancer that does basic round-robin load balancing. 简单来说Eureka就是Netflix开源的一款提供服务注册和发现的产品，并且提供了相应的Java客户端。 为什么要选择 Eureka?那么为什么我们在项目中使用了Eureka呢？主要原因如下: 它提供了完整的Service Registry和Service Discovery实现 首先是提供了完整的实现，并且也经受住了Netflix的生产环境考验，使用比较方便只需通过注解或简单配置的方式即可。 和Spring Cloud无缝集成 Spring Cloud对Eureka做了无缝集成，提供了一套完善的解决方案，所以使用起来非常方便。 另外，Eureka支持嵌入到应用自身的容器中启动，应用启动完之后，既充当了Eureka的角色，同时也是服务的提供者。这样就极大的提高了服务的可用性。 开源 开源代码，方便学习掌握其源码并驾驭它。 参考阅读：为什么不应该使用ZooKeeper做服务发现英文链接:Eureka! Why You Shouldn’t Use ZooKeeper for Service Discovery:http://www.knewton.com/tech/blog/2014/12/eureka-shouldnt-use-zookeeper-service-discovery/中文链接:http://blog.csdn.net/jenny8080/article/details/52448403Eureka vs. Zookeeper：https://groups.google.com/forum/#%21topic/eureka_netflix/LXKWoD14RFY 进一步了解 EurekaEureka基本架构图 上图简要描述了Eureka的基本架构，由3个角色组成： Eureka Server 提供服务注册和发现 Service Provider 服务提供者，服务启动的时候会将自己的服务信息注册到Eureka Service Consumer 服务消费者，从Eureka中获取已注的服务信息，用于调用服务生产者 需要注意一点是：一个Service Provider既可以是Service Consumer，也可以是Service Provider。 集群模式下的Eureka 上图更进一步的展示了3个角色之间的交互。 Service Provider会向Eureka Server做Register（服务注册）、Renew（服务续约）、Cancel（服务下线）等操作。 Eureka Server之间会做注册服务的同步，从而保证状态一致 Service Consumer会向Eureka Server获取注册服务列表，并消费服务","categories":[{"name":"Spring Cloud Eureka","slug":"Spring-Cloud-Eureka","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Eureka/"}],"tags":[{"name":"Spring Cloud Netflix","slug":"Spring-Cloud-Netflix","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Netflix/"},{"name":"Eureka","slug":"Eureka","permalink":"http://blog.springcloud.cn/tags/Eureka/"}]},{"title":"Spring Cloud Sleuth-全链路监控调研","slug":"sc/sc-sleuth","date":"2016-10-21T06:00:00.000Z","updated":"2017-06-17T03:24:59.000Z","comments":true,"path":"sc/sc-sleuth/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-sleuth/","excerpt":"前言:做过软件开发的都知道，对系统进行全链路的监控是非常有必要的。在单体应用中，传统的方式是软件开发者，通过自定义日志的level，日志文件的方式记录单体应用的运行日志。从而排查线上系统出现运行过慢，出现故障，异常等问题，但是在微服务架构或分布式系统中，一个系统被拆分成了A、B、C、D、E等多个服务，而每个服务可能又有多个实例组成集群，采用上诉定位问题的方式就行不通了，你充其量就知道某个服务是应用的瓶颈，但中间发生了什么你完全不知道。而且问题的查询，因为有海量各种各样的日志等文件，导致追溯定位问题等极其不方便。因此需要全链路监控系统的收集，上报，对海量日志实时计算生成，监控告警，视图报表，帮助开发人员快速定位问题。 服务追踪分析一个由微服务构成的应用系统由N个服务实例组成，通过REST请求或者RPC协议等来通讯完成一个业务流程的调用。对于入口的一个调用可能需要有多个后台服务协同完成，链路上任何一个调用超时或出错都可能造成前端请求的失败。服务的调用链也会越来越长，并形成一个树形的调用链。如下图所示:","text":"前言:做过软件开发的都知道，对系统进行全链路的监控是非常有必要的。在单体应用中，传统的方式是软件开发者，通过自定义日志的level，日志文件的方式记录单体应用的运行日志。从而排查线上系统出现运行过慢，出现故障，异常等问题，但是在微服务架构或分布式系统中，一个系统被拆分成了A、B、C、D、E等多个服务，而每个服务可能又有多个实例组成集群，采用上诉定位问题的方式就行不通了，你充其量就知道某个服务是应用的瓶颈，但中间发生了什么你完全不知道。而且问题的查询，因为有海量各种各样的日志等文件，导致追溯定位问题等极其不方便。因此需要全链路监控系统的收集，上报，对海量日志实时计算生成，监控告警，视图报表，帮助开发人员快速定位问题。 服务追踪分析一个由微服务构成的应用系统由N个服务实例组成，通过REST请求或者RPC协议等来通讯完成一个业务流程的调用。对于入口的一个调用可能需要有多个后台服务协同完成，链路上任何一个调用超时或出错都可能造成前端请求的失败。服务的调用链也会越来越长，并形成一个树形的调用链。如下图所示:但是随着服务的增多，对调用链的分析也会越来越负责。设想你在负责下面这个系统，其中每个小点都是一个微服务，他们之间的调用关系形成了复杂的网络。如下图所示: 通过该图，可以看出错综复杂的调用网路图。针对服务化应用全链路追踪的问题，Google发表了Dapper论文，介绍了他们如何进行服务追踪分析。其基本思路是在服务调用的请求和响应中加入ID，标明上下游请求的关系。利用这些信息，可以可视化地分析服务调用链路和服务间的依赖关系。 什么是 Spring Cloud Sleuth ?Spring Cloud Sleuth为Spring Cloud提供了分布式追踪方案，为了更好的理解这个领域中的一些概念，建议先自行搜索学习一下Google Dapper相关的论文，http://research.google.com/pubs/pub36356.html，github Code连接:Spring Cloud Sleuth Code。官方文档地址:http://cloud.spring.io/spring-cloud-sleuth/spring-cloud-sleuth.html. 其官方文档中对自己的定义是如下： Spring Cloud Sleuth implements a distributed tracing solution for Spring Cloud, borrowing heavily from Dapper, Zipkin and HTrace. For most users Sleuth should be invisible, and all your interactions with external systems should be instrumented automatically. You can capture data simply in logs, or by sending it to a remote collector service. 简单来说，Spring Cloud Sleuth就是APM(Application Performance Monitor),全链路监控的APM的一部分，如果要完整的使用该组件需要自己定制化或者和开源的系统集成，例如:ZipKin。 APM（Application Performance Monitor）这个领域最近异常火热。国外该领域知名公司包括New Relic，Appdynamics，Splunk。其中New Relic已经成功IPO，估值超过20亿美元。国内外的个大互联网公司也都有类似大名鼎鼎的APM产品，例如淘宝鹰眼Eagle Eyes，点评的CAT，微博的Watchman，twitter的Zipkin。他们的产品虽未像专业APM公司的产品这样功能强大，但结合各自公司的业务特点，这些产品在支撑业务系统的高性能和稳定性方面，发挥了显著的作用。 Spring Cloud Sleuth和Zipkin对应Dpper的开源实现是Zipkin，支持多种语言包括JavaScript，Python，Java, Scala, Ruby, C#, Go等。其中Java由多种不同的库来支持。 SpringCloudSleuth 借用了 Dapper 的术语 Span 基本工作单元，例如，在一个新建的span中发送一个RPC等同于发送一个回应请求给RPC，span通过一个64位ID唯一标识，trace以另一个64位ID表示，span还有其他数据信息，比如摘要、时间戳事件、关键值注释(tags)、span的ID、以及进度ID(通常是IP地址) span在不断的启动和停止，同时记录了时间信息，当你创建了一个span，你必须在未来的某个时刻停止它。 Trace 一系列spans组成的一个树状结构，例如，如果你要在分布式中大数据存储中使用，Trace将会由一个请求执行调用链形成。 Annotation 用来及时记录一个事件的存在，一些核心annotations用来定义一个请求的开始和结束。cs：Client Sent - 客户端发起一个请求，这个annotion描述了这个span的开始 sr：Server Received - 服务端获得请求并准备开始处理它，如果将其sr减去cs时间戳便可得到网络延迟ss：Server Sent - 注解表明请求处理的完成(当请求返回客户端)，如果ss减去sr时间戳便可得到服务端需要的处理请求时间 cr：Client Received - 表明span的结束，客户端成功接收到服务端的回复，如果cr减去cs时间戳便可得到客户端从服务端获取回复的所有所需时间将Span和Trace在一个系统中使用Zipkin注解的过程图形化，如下图所示:","categories":[{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud-Sleuth/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud/"},{"name":"Spring Cloud Sleuth","slug":"Spring-Cloud-Sleuth","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Sleuth/"},{"name":"全链路监控","slug":"全链路监控","permalink":"http://blog.springcloud.cn/tags/全链路监控/"},{"name":"微服务","slug":"微服务","permalink":"http://blog.springcloud.cn/tags/微服务/"}]},{"title":"什么是Spring Cloud Config？","slug":"sc/sc-config","date":"2016-10-19T06:00:00.000Z","updated":"2017-06-17T03:22:24.000Z","comments":true,"path":"sc/sc-config/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-config/","excerpt":"什么是 Spring Cloud Config ?其官方文档中对自己的定义是如下，官网连接:Spring Cloud Config。 Spring Cloud Config provides server and client-side support for externalized configuration in a distributed system.With the Config Server you have a central place to manage external properties for applications across all environments. 简单来说，Spring Cloud Config就是我们通常意义上的配置中心 - 把应用原本放在本地文件的配置抽取出来放在中心服务器，从而能够提供更好的管理、发布能力。","text":"什么是 Spring Cloud Config ?其官方文档中对自己的定义是如下，官网连接:Spring Cloud Config。 Spring Cloud Config provides server and client-side support for externalized configuration in a distributed system.With the Config Server you have a central place to manage external properties for applications across all environments. 简单来说，Spring Cloud Config就是我们通常意义上的配置中心 - 把应用原本放在本地文件的配置抽取出来放在中心服务器，从而能够提供更好的管理、发布能力。 另外，Spring Cloud Config提供基于以下3个维度的配置管理： 应用 这个比较好理解，每个配置都是属于某一个应用的 环境 每个配置都是区分环境的，如dev, test, prod等 版本 这个可能是一般的配置中心所缺乏的，就是对同一份配置的不同版本管理，比如:可以通过Git进行版本控制。 Spring Cloud Config提供版本的支持，也就是说对于一个应用的不同部署实例，可以从服务端获取到不同版本的配置，这对于一些特殊场景如：灰度发布，A/B测试等提供了很好的支持。 为什么会诞生Spring Cloud Config? 配置中心目前现状:不管是开源的(百度的disconf)，还是一些公司自己闭源投入使用的产品已经不少了，那为什么还会诞生Spring Cloud Config呢？ 在我看来，Spring Cloud Config在以下几方面还是有比较独特的优势，如下： 基于应用、环境、版本三个维度管理 这个在前面提过了，主要是有版本的支持 配置存储支持Git 这个就比较有特色了，后端基于Git存储，一方面程序员非常熟悉，另一方面在部署上会非常简单，而且借助于Git，天生就能非常好的支持版本 当然，它还支持其它的存储如本地文件、SVN等 和Spring无缝集成 它无缝支持Spring里面Environment和PropertySource的接口 所以对于已有的Spring应用程序的迁移成本非常低，在配置获取的接口上是完全一致的 Spring Cloud Config 入门例子上述节点主要介绍了Spring cloud的相关理论，大家对Spring Cloud Config有了一个初步的认识，接下来例子让大家感受一下Spring cloud config的魅力。 Overview 上图简要描述了一个普通Spring Cloud Config应用的场景。其中主要有以下几个组件： Config Client Client很好理解，就是使用了Spring Cloud Config的应用 Spring Cloud Config提供了基于Spring的客户端，应用只要在代码中引入Spring Cloud Config Client的jar包即可工作 Config Server Config Server是需要独立部署的一个web应用，它负责把git上的配置返回给客户端 Remote Git Repository 远程Git仓库，一般而言，我们会把配置放在一个远程仓库，通过现成的git客户端来管理配置 Local Git Repostiory Config Server的本地Git仓库 Config Server接到来自客户端的配置获取请求后，会先把远程仓库的配置clone到本地的临时目录，然后从临时目录读取配置并返回","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud Config","slug":"Spring-Cloud-Config","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud-Config/"}]},{"title":"Spring Cloud微服务框架主要子项目和RPC框架的对比","slug":"sc/sc-introduce","date":"2016-10-18T02:00:00.000Z","updated":"2017-06-17T03:23:26.000Z","comments":true,"path":"sc/sc-introduce/","link":"","permalink":"http://blog.springcloud.cn/sc/sc-introduce/","excerpt":"","text":"什么是Spring Cloud？ Spring Cloud是一个相对比较新的微服务框架，今年(2016)才推出1.0的release版本. 虽然Spring Cloud时间最短, 但是相比Dubbo等RPC框架, Spring Cloud提供的全套的分布式系统解决方案。spring cloud 为开发者提供了在分布式系统（配置管理，服务发现，熔断，路由，微代理，控制总线，一次性token，全居琐，leader选举，分布式session，集群状态）中快速构建的工具，使用Spring Cloud的开发者可以快速的启动服务或构建应用．它们将在任何分布式环境中工作，包括开发人员自己的笔记本电脑，裸物理机的数据中心，和像Cloud Foundry云管理平台。下面是官方对Spring Cloud定义和解释。 Spring Cloud provides tools for developers to quickly build some of the common patterns in distributed systems (e.g. configuration management, service discovery, circuit breakers, intelligent routing, micro-proxy, control bus, one-time tokens, global locks, leadership election, distributed sessions, cluster state). Coordination of distributed systems leads to boiler plate patterns, and using Spring Cloud developers can quickly stand up services and applications that implement those patterns. They will work well in any distributed environment, including the developer’s own laptop, bare metal data centres, and managed platforms such as Cloud Foundry. Spring Cloud主要项目 Spring Cloud 侧重于提供良好的开箱即用的功能，以便支持典型的开发场景和扩展支持。下面主要Spring Cloud项目在微服务框架中的主要子项目，具体的子项目源码分析，以及实现细节，将会在后面的文章中介绍。 Spring Cloud Config—配置中心 Spring Cloud Config就是我们通常意义上的配置中心 - 把应用原本放在本地文件的配置抽取出来放在中心服务器，从而能够提供更好的管理、发布。 在RPC服务治理框架中，一般都会开发一个配置中心和ZK配合使用，用于管理分布式应用中的配置信息。比如熔断的阀值，负载均衡的策略等。 Spring Cloud Netflix–注册中心，服务发现，LB Spring Cloud Netflix通过Eureka Server实现服务注册中心(包括服务注册，服务发现)，通过Ribbon实现软负载均衡(load balance,简称LB) 在RPC框架中，例如：dubboX，HSF，OSP(唯品会的RPC框架)等RPC框架，都会通过ZK等实现服务注册，服务发现。当服务启动时，会将服务的IP地址，端口，服务命名，版本号等信息注册到ZK中，同时ZK Node会监听变化，接收最新的服务注册信息到client端或Proxy端。至于LB，都会有自己的实现算法，熔断等都有自己的实现方式。 Hystrix 熔断，包含在服务治理中。 Spring Cloud Sleuth Spring Cloud Sleuth为Spring Cloud提供了分布式追踪方案。全链路监控系统。 APM（Application Performance Monitor）这个领域最近异常火热。国外该领域知名公司包括New Relic，Appdynamics，Splunk。其中New Relic已经成功IPO，估值超过20亿美元。 １．国内外的个大互联网公司也都有类似大名鼎鼎的APM产品，例如淘宝鹰眼Eagle Eyes，点评的CAT，微博的Watchman，twitter的Zipkin。他们的产品虽未像专业APM公司的产品这样功能强大，但结合各自公司的业务特点，这些产品在支撑业务系统的高性能和稳定性方面，发挥了显著的作用。 ２．众所周知，中大型互联网公司的后台业务系统由众多分布式组件构成，这些组件由web类型组件，RPC服务化类型组件，缓存组件，消息组件和数据库组件。一个通过浏览器或移动客户端的前端请求到达后台系统后，会经过很多个业务组件和系统组件，并且留下足迹和相关日志信息。但这些分散在每个业务组件和主机下的日志信息不利于问题排查和定位问题的Root Cause。这种监控场景正是应用性能监控系统的用武之地，应用性能监控系统收集，汇总并分析日志信息达到有效监控系统性能和问题的效果． ３．在唯品会体系中，Mercury提供的主要功能包括： 定位慢调用：包括慢Web服务（包括Restful Web服务），慢OSP服务，慢SQL 定位错误：包括4XX，5XX，OSP Error 定位异常：包括Error Exception，Fatal Exception 展现依赖和拓扑：域拓扑，服务拓扑，trace拓扑 Trace调用链：将端到端的调用，以及附加在这次调用的上下文信息，异常日志信息，每一个调用点的耗时都呈现给用户 应用告警：根据运维设定的告警规则，扫描指标数据，如违反告警规则，则将告警信息上报到唯品会中央告警平台 dubbo与Spring Cloud的比较 1.dubbo出自于阿里，Spring cloud出自于Spring社区,基于Spring boot提供一套完整的微服务解决方案。dubbo或者dubbox是RPC框 架，功能是Spring Cloud功能的一个子集。 2.dubbo是RPC服务治理框架，和Spring Cloud一样具备服务注册、发现、路由、负载均衡等能力。但是没有配置中心，完整的好用全链路监 控，需要采用开源的解决方案定制或者自研。Spring cloud的配置中心，全链路监控等组件。从目前来看，Spring Cloud国内中小型企业用的比较多，大型企业可能需要对其需要的组件进行定制化处理。 3.Spring cloud基于注解的服务发现，服务治理等功能具有代码侵入性，dubbo没有代码侵入性，业务开发人员不需要通过注解的方式去关注框架级别的处理。从中间件或者做基础架构的角度来看，其实服务治理等功能对普通的业务程序员应该是透明的，业务程序员不需要关注服务治理框架的使用，专注于业务代码即可。 因此大型企业可能需要对Spring cloud进行定制化处理。更多比较信息，可以参考下面的连接。 http://blog.didispace.com/microservice-framework/","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud/"}]},{"title":"关于SpringCloud中国社区以及国内使用情况","slug":"sc/springcloud","date":"2016-10-03T06:00:00.000Z","updated":"2017-06-17T03:01:01.000Z","comments":true,"path":"sc/springcloud/","link":"","permalink":"http://blog.springcloud.cn/sc/springcloud/","excerpt":"Spring Cloud中国社区起源 其实当Spring Cloud项目刚在github上出现的时候，我就一直在关注其项目发展，到了2015年8月，由于个人兴趣研究Spring Cloud项目，由于国内相关文档较少，当时就想建立一个中国社区，于是就先把域名注册了，选中域名为springcloud.cn。 为什么要发起Spring Cloud中国社区 Spring Cloud发展到2016年，国内关注的人越来越多，但是相应学习交流的平台和材料比较分散，不利于学习交流，因此Spring Cloud中国社区应运而生。 Spring Cloud中国社区是国内首个Spring Cloud构建微服务架构的交流社区。我们致力于为Spring Boot或Spring Cloud技术人员提供分享和交流的平台，推动Spring Cloud在中国的普及和应用。 欢迎CTO、架构师、开发者等，在这里学习与交流使用Spring Cloud的实战经验。 目前QQ群人数:7000+,微信群:2000+. 扫描下面二维码或者微信搜索SpringCloud，关注社区公众号 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 Spring Cloud中国社区官网:http://springcloud.cn Spring Cloud中国社区论坛:http://springcloud.cn Spring Cloud中国社区文档:http://docs.springcloud.cn spring cloud目前国内使用情况 中国联通子公司http://flp.baidu.com/feedland/video/?entry=box_searchbox_feed&amp;id=144115189637730162&amp;from=timeline&amp;isappinstalled=0","text":"Spring Cloud中国社区起源 其实当Spring Cloud项目刚在github上出现的时候，我就一直在关注其项目发展，到了2015年8月，由于个人兴趣研究Spring Cloud项目，由于国内相关文档较少，当时就想建立一个中国社区，于是就先把域名注册了，选中域名为springcloud.cn。 为什么要发起Spring Cloud中国社区 Spring Cloud发展到2016年，国内关注的人越来越多，但是相应学习交流的平台和材料比较分散，不利于学习交流，因此Spring Cloud中国社区应运而生。 Spring Cloud中国社区是国内首个Spring Cloud构建微服务架构的交流社区。我们致力于为Spring Boot或Spring Cloud技术人员提供分享和交流的平台，推动Spring Cloud在中国的普及和应用。 欢迎CTO、架构师、开发者等，在这里学习与交流使用Spring Cloud的实战经验。 目前QQ群人数:7000+,微信群:2000+. 扫描下面二维码或者微信搜索SpringCloud，关注社区公众号 Spring Cloud中国社区QQ群①:415028731 Spring cloud中国社区QQ群②:530321604 Spring Cloud中国社区官网:http://springcloud.cn Spring Cloud中国社区论坛:http://springcloud.cn Spring Cloud中国社区文档:http://docs.springcloud.cn spring cloud目前国内使用情况 中国联通子公司http://flp.baidu.com/feedland/video/?entry=box_searchbox_feed&amp;id=144115189637730162&amp;from=timeline&amp;isappinstalled=0 上海米么金服 指点无限（北京）科技有限公司 易保软件 目前在定制开发中 http://www.ebaotech.com/cn/ 广州简法网络 深圳睿云智合科技有限公司 持续交付产品基于Spring Cloud研发 http://www.wise2c.com 猪八戒网 上海云首科技有限公司 华为 整合netty进来用rpc 包括nerflix那套东西 需要注意的是sleuth traceid的传递需要自己写。tps在物理机上能突破20w 东软 南京云帐房网络科技有限公司 四众互联(北京)网络科技有限公司 深圳摩令技术科技有限公司 广州万表网 视觉中国 上海秦苍信息科技有限公司-买单侠 爱油科技(大连)有限公司爱油科技基于SpringCloud的微服务实践 广发银行 卖货郎(http://www.51mhl.com/） 拍拍贷 甘肃电信 新浪商品部 春秋航空 冰鉴科技 万达网络科技集团-共享商业平台-共享供应链中心 网易乐得技术团队 饿了么某技术团队 高阳捷迅信息科技–话费中心业务平台–凭证查询及收单系统数据在统计之中，会一直持续更新，敬请期待！ 捐赠社区发展捐赠社区 如果你觉得，Spring Cloud中国社区还可以，为了更好的发展，你可以捐赠社区，点击下面的打赏捐赠，捐赠的钱将用于社区发展和线下meeting up。","categories":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/categories/Spring-Cloud/"}],"tags":[{"name":"Spring Cloud","slug":"Spring-Cloud","permalink":"http://blog.springcloud.cn/tags/Spring-Cloud/"}]}]}